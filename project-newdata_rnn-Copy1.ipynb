{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from time import time\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from keras.optimizers import SGD, Adam, Nadam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout, Input, Dense,Lambda, BatchNormalization\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Model,Sequential, load_model\n",
    "from keras import backend as K\n",
    "from keras.layers import Embedding, LSTM, concatenate\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Metricas ##########\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.exp(K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)))\n",
    "\n",
    "def coeff_determination_simple(y_true, y_pred):\n",
    "    SS_res =  np.sum(np.square( y_true - y_pred )) \n",
    "    SS_tot = np.sum(np.square( y_true - np.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "###################### New MEthods ##########\n",
    "def load_csv_data(url, drop_columns=[]):\n",
    "    \n",
    "    #READ data\n",
    "    print(\"Loading data\")\n",
    "    df = pd.read_csv(url)\n",
    "    print(\"Removing columns\",drop_columns)\n",
    "    df = df.drop(columns=drop_columns)\n",
    "    return df\n",
    "\n",
    "def log_targets(y_train, y_val, y_test):\n",
    "    \"\"\" Transform to log scale \"\"\"\n",
    "    y_train_log = np.log(y_train)\n",
    "    y_val_log = np.log(y_val)\n",
    "    y_test_log = np.log(y_test)\n",
    "\n",
    "    y_train_log_min = np.min(y_train_log)\n",
    "    y_train_min = np.min(y_train)\n",
    "\n",
    "    y_train_log_max = np.max(y_train_log)\n",
    "    y_train_max = np.max(y_train)\n",
    "\n",
    "    print(\"targets min:{} max: {}\".format(y_train_min, y_train_max))\n",
    "    print(\"targets in log scale min:{} max: {}\".format(y_train_log_min, y_train_log_max))\n",
    "    return y_train_log, y_val_log, y_test_log\n",
    "\n",
    "def normalize_xdata(x_train, x_val, x_test):\n",
    "    #Standarización del target\n",
    "    scaler = StandardScaler()\n",
    "    x_train_std = scaler.fit_transform(x_train)\n",
    "    x_val_std = scaler.transform(x_val)\n",
    "    x_test_std = scaler.transform(x_test)\n",
    "    return scaler, x_train_std, x_val_std, x_test_std\n",
    "\n",
    "def normalize_target(train, val, test):\n",
    "    \"\"\"\n",
    "    Normalize data using StandardScaler.\n",
    "    \n",
    "    return scaler object; values of train,val and test sets standarized. \n",
    "    \"\"\"\n",
    "    #Standarización del target\n",
    "    scaler = StandardScaler()\n",
    "    y_train_log_std = scaler.fit_transform(train)\n",
    "    y_val_log_std = scaler.transform(val)\n",
    "    y_test_log_std = scaler.transform(test)\n",
    "    return scaler, y_train_log_std, y_val_log_std, y_test_log_std\n",
    "\n",
    "def get_metrics(model, scaler, x_data, y_true_data, label_set=\"Data\"):\n",
    "    y_pred = np.exp(scaler.inverse_transform(model.predict(x_data).reshape(-1, 1)))\n",
    "    rmseval = np.sqrt(mean_squared_error(y_true_data, y_pred))\n",
    "    r2val = r2_score(y_true_data, y_pred)\n",
    "    print(\"RMSE \"+label_set, rmseval)\n",
    "    print(\"R2 SCORE \"+label_set, r2val)\n",
    "    return rmseval, r2val\n",
    "\n",
    "def plot_history(history, metrics_list, start_at_epoch=0):\n",
    "    for metric in metrics_list:\n",
    "        plt.plot(history.history[metric][start_at_epoch:],label=metric)\n",
    "    plt.legend()\n",
    "    plt.title(\"Metrics by epochs(Start from epoch:{})\".format(start_at_epoch))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove columns with same values: Index(['path*', 'pathN*', 'path+', 'pathN+', 'notoneof', 'tolist', 'multi',\n",
      "       'top', 'assign', 'sequence'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['triple', 'bgp', 'join', 'leftjoin', 'union', 'filter', 'graph',\n",
       "       'extend', 'minus', 'order', 'project', 'distinct', 'reduced', 'group',\n",
       "       'slice', 'treesize', 'id', 'time', 'pcs0', 'pcs1', 'pcs2', 'pcs3',\n",
       "       'pcs4', 'pcs5', 'pcs6', 'pcs7', 'pcs8', 'pcs9', 'pcs10', 'pcs11',\n",
       "       'pcs12', 'pcs13', 'pcs14', 'pcs15', 'pcs16', 'pcs17', 'pcs18', 'pcs19',\n",
       "       'pcs20', 'pcs21', 'pcs22', 'pcs23', 'pcs24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load new data\n",
    "data_rnn =  pd.read_csv(\"models_newdata/datasetlsq_output_recurrentfeat.csv\", delimiter=\"ᶶ\")\n",
    "data_rnn = data_rnn.drop(columns=\"Unnamed: 3\")\n",
    "\n",
    "#Data from files\n",
    "data_algebra = pd.read_csv(\"/home/dcasals/graph-edit-distance/data/algebra_features.txt\")\n",
    "data_medoids = pd.read_csv(\"/home/dcasals/graph-edit-distance/data/vectors_medoids.csv\")\n",
    "result = data_algebra.merge(data_medoids, left_on='query_id', right_on='id')\n",
    "result = result.drop(columns=[\"query_id\",\"Unnamed: 27_x\", \"Unnamed: 27_y\"])\n",
    "\n",
    "nunique = result.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "print(\"Remove columns with same values: {}\".format(cols_to_drop))\n",
    "result = result.drop(cols_to_drop, axis=1)\n",
    "new_cols = list(result.columns[:-25]) + ['pcs'+str(i) for i in list(range(0,25))]\n",
    "result.columns = new_cols\n",
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[['id','triple', 'bgp', 'join', 'leftjoin', 'union', 'filter', 'project',\n",
    "       'distinct', 'treesize', 'time','pcs0', 'pcs1', 'pcs2', 'pcs3', 'pcs4', 'pcs5',\n",
    "       'pcs6', 'pcs7', 'pcs8', 'pcs9', 'pcs10', 'pcs11', 'pcs12', 'pcs13',\n",
    "       'pcs14', 'pcs15', 'pcs16', 'pcs17', 'pcs18', 'pcs19', 'pcs20', 'pcs21',\n",
    "       'pcs22', 'pcs23', 'pcs24']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tpfs</th>\n",
       "      <th>execTime</th>\n",
       "      <th>triple</th>\n",
       "      <th>bgp</th>\n",
       "      <th>join</th>\n",
       "      <th>leftjoin</th>\n",
       "      <th>union</th>\n",
       "      <th>filter</th>\n",
       "      <th>project</th>\n",
       "      <th>...</th>\n",
       "      <th>pcs15</th>\n",
       "      <th>pcs16</th>\n",
       "      <th>pcs17</th>\n",
       "      <th>pcs18</th>\n",
       "      <th>pcs19</th>\n",
       "      <th>pcs20</th>\n",
       "      <th>pcs21</th>\n",
       "      <th>pcs22</th>\n",
       "      <th>pcs23</th>\n",
       "      <th>pcs24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://lsq.aksw.org/res/DBpedia-q113812</td>\n",
       "      <td>2,http://www.w3.org/2000/01/rdf-schema#label,1...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://lsq.aksw.org/res/DBpedia-q113813</td>\n",
       "      <td>9,http://dbpedia.org/property/pushpinMap,</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://lsq.aksw.org/res/DBpedia-q113814</td>\n",
       "      <td>9,http://dbpedia.org/property/reference,</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://lsq.aksw.org/res/DBpedia-q113815</td>\n",
       "      <td>9,http://www.w3.org/2000/01/rdf-schema#label,9...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://lsq.aksw.org/res/DBpedia-q113817</td>\n",
       "      <td>9,http://www.w3.org/1999/02/22-rdf-syntax-ns#t...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16956</th>\n",
       "      <td>http://lsq.aksw.org/res/DBpedia-q1014063</td>\n",
       "      <td>1,http://www.w3.org/2000/01/rdf-schema#label,</td>\n",
       "      <td>55527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16957</th>\n",
       "      <td>http://lsq.aksw.org/res/DBpedia-q1085454</td>\n",
       "      <td>1,http://dbpedia.org/property/label,</td>\n",
       "      <td>16592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16958</th>\n",
       "      <td>http://lsq.aksw.org/res/LGD-q5773</td>\n",
       "      <td>4,http://www.w3.org/1999/02/22-rdf-syntax-ns#t...</td>\n",
       "      <td>3434</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16959</th>\n",
       "      <td>http://lsq.aksw.org/res/LGD-q5960</td>\n",
       "      <td>4,http://www.w3.org/1999/02/22-rdf-syntax-ns#t...</td>\n",
       "      <td>3140</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16960</th>\n",
       "      <td>http://lsq.aksw.org/res/LGD-q6094</td>\n",
       "      <td>4,http://www.w3.org/1999/02/22-rdf-syntax-ns#t...</td>\n",
       "      <td>2882</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16961 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0       http://lsq.aksw.org/res/DBpedia-q113812   \n",
       "1       http://lsq.aksw.org/res/DBpedia-q113813   \n",
       "2       http://lsq.aksw.org/res/DBpedia-q113814   \n",
       "3       http://lsq.aksw.org/res/DBpedia-q113815   \n",
       "4       http://lsq.aksw.org/res/DBpedia-q113817   \n",
       "...                                         ...   \n",
       "16956  http://lsq.aksw.org/res/DBpedia-q1014063   \n",
       "16957  http://lsq.aksw.org/res/DBpedia-q1085454   \n",
       "16958         http://lsq.aksw.org/res/LGD-q5773   \n",
       "16959         http://lsq.aksw.org/res/LGD-q5960   \n",
       "16960         http://lsq.aksw.org/res/LGD-q6094   \n",
       "\n",
       "                                                    tpfs  execTime  triple  \\\n",
       "0      2,http://www.w3.org/2000/01/rdf-schema#label,1...         4     2.0   \n",
       "1              9,http://dbpedia.org/property/pushpinMap,         2     1.0   \n",
       "2               9,http://dbpedia.org/property/reference,         2     1.0   \n",
       "3      9,http://www.w3.org/2000/01/rdf-schema#label,9...         4     3.0   \n",
       "4      9,http://www.w3.org/1999/02/22-rdf-syntax-ns#t...         2     1.0   \n",
       "...                                                  ...       ...     ...   \n",
       "16956      1,http://www.w3.org/2000/01/rdf-schema#label,     55527     1.0   \n",
       "16957               1,http://dbpedia.org/property/label,     16592     1.0   \n",
       "16958  4,http://www.w3.org/1999/02/22-rdf-syntax-ns#t...      3434     6.0   \n",
       "16959  4,http://www.w3.org/1999/02/22-rdf-syntax-ns#t...      3140     6.0   \n",
       "16960  4,http://www.w3.org/1999/02/22-rdf-syntax-ns#t...      2882     6.0   \n",
       "\n",
       "       bgp  join  leftjoin  union  filter  project  ...     pcs15     pcs16  \\\n",
       "0      1.0   0.0       0.0    0.0     0.0      0.0  ...  0.400000  0.166667   \n",
       "1      1.0   0.0       0.0    0.0     0.0      1.0  ...  0.666667  0.133333   \n",
       "2      1.0   0.0       0.0    0.0     0.0      1.0  ...  0.666667  0.133333   \n",
       "3      2.0   0.0       1.0    0.0     0.0      1.0  ...  0.333333  0.200000   \n",
       "4      1.0   0.0       0.0    0.0     0.0      1.0  ...  0.666667  0.142857   \n",
       "...    ...   ...       ...    ...     ...      ...  ...       ...       ...   \n",
       "16956  1.0   0.0       0.0    0.0     0.0      1.0  ...  0.666667  0.142857   \n",
       "16957  1.0   0.0       0.0    0.0     0.0      1.0  ...  0.666667  0.133333   \n",
       "16958  6.0   0.0       3.0    2.0     0.0      1.0  ...  0.153846  0.333333   \n",
       "16959  6.0   0.0       3.0    2.0     0.0      1.0  ...  0.153846  0.333333   \n",
       "16960  6.0   0.0       3.0    2.0     0.0      1.0  ...  0.153846  0.333333   \n",
       "\n",
       "          pcs17     pcs18     pcs19     pcs20     pcs21     pcs22     pcs23  \\\n",
       "0      0.333333  0.500000  0.400000  0.285714  0.200000  0.333333  0.200000   \n",
       "1      0.222222  0.400000  0.666667  0.222222  0.166667  0.222222  0.153846   \n",
       "2      0.222222  0.400000  0.666667  0.222222  0.166667  0.222222  0.153846   \n",
       "3      0.333333  0.333333  0.285714  0.400000  0.200000  0.333333  0.200000   \n",
       "4      0.250000  0.400000  0.666667  0.250000  0.181818  0.250000  0.166667   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "16956  0.250000  0.400000  0.666667  0.222222  0.166667  0.250000  0.166667   \n",
       "16957  0.222222  0.400000  0.666667  0.222222  0.166667  0.222222  0.153846   \n",
       "16958  0.333333  0.166667  0.153846  0.250000  0.200000  0.333333  1.000000   \n",
       "16959  0.333333  0.166667  0.153846  0.250000  0.200000  0.333333  1.000000   \n",
       "16960  0.333333  0.166667  0.153846  0.250000  0.200000  0.333333  1.000000   \n",
       "\n",
       "          pcs24  \n",
       "0      0.200000  \n",
       "1      0.153846  \n",
       "2      0.153846  \n",
       "3      0.200000  \n",
       "4      0.166667  \n",
       "...         ...  \n",
       "16956  0.166667  \n",
       "16957  0.153846  \n",
       "16958  1.000000  \n",
       "16959  1.000000  \n",
       "16960  1.000000  \n",
       "\n",
       "[16961 rows x 38 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rnn = data_rnn.merge(result, left_on='id', right_on='id')\n",
    "data_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def procesar_tpfs_odd(x):\n",
    "    \"\"\"Get odd elements from a list \"\"\"\n",
    "    lista = []\n",
    "    for a in x.split(\",\")[::2]:\n",
    "        if a != \"\":\n",
    "            if a.isdigit():\n",
    "                lista.append(int(a))\n",
    "            else:\n",
    "                lista.append(0)\n",
    "#     print(lista)\n",
    "    return lista\n",
    "def procesar_tpfs_even(x):\n",
    "    \"\"\"Get even elements from a list \"\"\"\n",
    "    lista  = [a for a in x.split(\",\")[1::2] if a != \"\"]\n",
    "#     print(lista)\n",
    "    return lista\n",
    "def uri_2_index_seq(x,uri2Index):\n",
    "    \"\"\"transform uris to sequences\"\"\"\n",
    "    lista  = [uri2Index[a] for a in x]\n",
    "#     print(lista)\n",
    "    return lista\n",
    "def get_embedding_matrix_zero(index_dict, EMBEDDING_DIM):\n",
    "    '''\n",
    "        Generamos la matriz de embeddings, de dimensiones: \n",
    "          - (Tamano_vocabulario + 1) x Dimesion_embedding DecodeInput\n",
    "    '''\n",
    "    embedding_matrix = np.zeros((len(index_dict) + 1, EMBEDDING_DIM))\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_RNN(num_pred_words, embedd_dim, embedd_type_dim, embedd_input_matrix, embedding_types_matrix, lstm_units, lstm_types_units):\n",
    "    dropout = 0.25\n",
    "    lstm_pred_input = Input(shape=(None,),name='lstm_pred_input')\n",
    "    lstm_pred_embedd = Embedding(num_pred_words + 1 ,embedd_dim, weights=[embedd_input_matrix], trainable=True)(lstm_pred_input)\n",
    "    lstm_pred_out = LSTM(lstm_units, name='lstm_pred_out')(lstm_pred_embedd)\n",
    "\n",
    "    # Salida Auxiliar del modelo recurrente de predicados\n",
    "#     aux_recurrent_pred_output = Dense(1, activation='linear', name='aux_recurrent_pred_output')(lstm_pred_out)\n",
    "    \n",
    "    lstm_type_input = Input(shape=(None,),name='lstm_type_input')\n",
    "    lstm_type_embedd = Embedding(10 , embedd_type_dim, weights=[embedding_types_matrix], trainable=True)(lstm_type_input)\n",
    "    lstm_type_out = LSTM(lstm_units, name='lstm_type_out')(lstm_type_embedd)\n",
    "\n",
    "#     Salida Auxiliar del modelo recurrente de predicados\n",
    "#     aux_recurrent_type_output = Dense(1, activation='linear', name='aux_recurrent_type_output')(lstm_type_out)\n",
    "    \n",
    "    dense_input = Input(shape=(34,), name='dense_input')    \n",
    "\n",
    "    # We stack a deep densely-connected network on top\n",
    "    x = Dense(260, activation='relu')(dense_input)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(300, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(240, activation='relu')(x)\n",
    "    x = concatenate([lstm_type_out,lstm_pred_out, x])\n",
    "#     x = concatenate([lstm_type_out, x])\n",
    "\n",
    "    # And finally we add the main logistic regression layer\n",
    "    main_output = Dense(1, activation='linear', name='main_output')(x)\n",
    "    \n",
    "    #Build model\n",
    "    model = Model(inputs=[lstm_type_input, lstm_pred_input, dense_input,], outputs=[main_output])\n",
    "#     model = Model(inputs=[lstm_type_input, dense_input,], outputs=[main_output])\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file='model.png')\n",
    "    return model\n",
    "\n",
    "def build_RNN3(num_pred_words, embedd_dim, embedd_type_dim, embedd_input_matrix, embedding_types_matrix, lstm_units, lstm_types_units):\n",
    "    dropout = 0.25\n",
    "    lstm_pred_input = Input(shape=(None,),name='lstm_pred_input')\n",
    "    lstm_pred_embedd = Embedding(num_pred_words + 1 ,embedd_dim, weights=[embedd_input_matrix], trainable=True)(lstm_pred_input)\n",
    "    lstm_pred_out = LSTM(lstm_units, name='lstm_pred_out')(lstm_pred_embedd)\n",
    "\n",
    "    # Salida Auxiliar del modelo recurrente de predicados\n",
    "#     aux_recurrent_pred_output = Dense(1, activation='linear', name='aux_recurrent_pred_output')(lstm_pred_out)\n",
    "    \n",
    "#     lstm_type_input = Input(shape=(None,),name='lstm_type_input')\n",
    "#     lstm_type_embedd = Embedding(10 , embedd_type_dim, weights=[embedding_types_matrix], trainable=True)(lstm_type_input)\n",
    "#     lstm_type_out = LSTM(lstm_units, name='lstm_type_out')(lstm_type_embedd)\n",
    "\n",
    "#     Salida Auxiliar del modelo recurrente de predicados\n",
    "#     aux_recurrent_type_output = Dense(1, activation='linear', name='aux_recurrent_type_output')(lstm_type_out)\n",
    "    \n",
    "    dense_input = Input(shape=(34,), name='dense_input')    \n",
    "\n",
    "    # We stack a deep densely-connected network on top\n",
    "    x = Dense(260, activation='relu')(dense_input)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(300, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(240, activation='relu')(x)\n",
    "    x = concatenate([lstm_pred_out, x])\n",
    "#     x = concatenate([lstm_type_out, x])\n",
    "\n",
    "    # And finally we add the main logistic regression layer\n",
    "    main_output = Dense(1, activation='linear', name='main_output')(x)\n",
    "    \n",
    "    #Build model\n",
    "    model = Model(inputs=[lstm_pred_input, dense_input,], outputs=[main_output])\n",
    "#     model = Model(inputs=[lstm_type_input, dense_input,], outputs=[main_output])\n",
    "#     from keras.utils import plot_model\n",
    "#     a = plot_model(model, to_file='model.png')\n",
    "    return model\n",
    "\n",
    "def build_RNN2(num_pred_words, embedd_dim, embedd_type_dim, embedd_input_matrix,embedding_types_matrix, lstm_units, lstm_types_units):\n",
    "    dropout = 0.25\n",
    "    lstm_pred_input = Input(shape=(None,),name='lstm_pred_input')\n",
    "    lstm_pred_embedd = Embedding(num_pred_words + 1 ,embedd_dim, weights=[embedd_input_matrix], trainable=True)(lstm_pred_input)\n",
    "    lstm_pred_out = LSTM(lstm_units, name='lstm_pred_out')(lstm_pred_embedd)\n",
    "\n",
    "    # Salida Auxiliar del modelo recurrente de predicados\n",
    "#     aux_recurrent_pred_output = Dense(1, activation='linear', name='aux_recurrent_pred_output')(lstm_pred_out)\n",
    "    \n",
    "    lstm_type_input = Input(shape=(None,),name='lstm_type_input')\n",
    "    lstm_type_embedd = Embedding(10 , embedd_type_dim, weights=[embedding_types_matrix], trainable=True)(lstm_type_input)\n",
    "    lstm_type_out = LSTM(lstm_units, name='lstm_type_out')(lstm_type_embedd)\n",
    "\n",
    "#     Salida Auxiliar del modelo recurrente de predicados\n",
    "#     aux_recurrent_type_output = Dense(1, activation='linear', name='aux_recurrent_type_output')(lstm_type_out)\n",
    "    \n",
    "    dense_input = Input(shape=(34,), name='dense_input')    \n",
    "\n",
    "    # We stack a deep densely-connected network on top\n",
    "    x = Dense(260, activation='relu')(dense_input)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(300, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(240, activation='relu')(x)\n",
    "    x = concatenate([lstm_type_out, lstm_pred_out])\n",
    "\n",
    "    # And finally we add the main logistic regression layer\n",
    "    main_output = Dense(1, activation='linear', name='main_output')(x)\n",
    "    \n",
    "    #Build model\n",
    "    model = Model(inputs=[lstm_type_input, lstm_pred_input,], outputs=[main_output])\n",
    "#     model = Model(inputs=[lstm_type_input, dense_input,], outputs=[main_output])\n",
    "    return model\n",
    "\n",
    "def build_ANN2():\n",
    "    dropout = 0.25\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(260, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(240, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "#     model = Model(inputs=[lstm_type_input, dense_input,], outputs=[main_output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_data(data):\n",
    "    data = data[data['time'] < 15000]\n",
    "    tpfs_structure = data['tpfs'].apply(lambda x: procesar_tpfs_odd(x))\n",
    "    tpfs_predicate = data['tpfs'].apply(lambda x: procesar_tpfs_even(x))\n",
    "    dense_data = data[['triple', 'bgp', 'join', 'leftjoin', 'union', 'filter', 'project',\n",
    "       'distinct', 'treesize','pcs0', 'pcs1', 'pcs2', 'pcs3', 'pcs4', 'pcs5',\n",
    "       'pcs6', 'pcs7', 'pcs8', 'pcs9', 'pcs10', 'pcs11', 'pcs12', 'pcs13',\n",
    "       'pcs14', 'pcs15', 'pcs16', 'pcs17', 'pcs18', 'pcs19', 'pcs20', 'pcs21',\n",
    "       'pcs22', 'pcs23', 'pcs24']]\n",
    "    targets = data[['time']]\n",
    "    print(\"columnas: {}\".format(dense_data.columns))\n",
    "    return dense_data.values , tpfs_structure, tpfs_predicate, targets.values\n",
    "\n",
    "def preprocesar_lstm_data(lstm_pred_data, lstm_type_data, EMBEDDING_DIM_PRED = 200, EMBEDDING_DIM_TYPES=10):\n",
    "    #create indexes\n",
    "    index = 1\n",
    "    uri2Index = {}\n",
    "    index2Uri = {}\n",
    "\n",
    "    for lista in  lstm_pred_data.values:\n",
    "        for val in lista:\n",
    "            if val not in uri2Index:\n",
    "                uri2Index[val] = index\n",
    "                index2Uri[index] = val\n",
    "                index +=1\n",
    "    tpfs_pred_index = lstm_pred_data.apply(lambda x: uri_2_index_seq(x, uri2Index))\n",
    "    \n",
    "    #Max Len\n",
    "    max_length = np.max(tpfs_pred_index.apply(lambda x: len(x)))\n",
    "    paded_tpf_pred_data = np.array(pad_sequences(tpfs_pred_index.values.tolist(), maxlen=15, padding='post'))\n",
    "    paded_tpf_types_data = np.array(pad_sequences(lstm_type_data.values.tolist(), maxlen=15, padding='post'))\n",
    "    \n",
    "    #Embedding Matrix\n",
    "    \n",
    "    emb_matrix_pred = get_embedding_matrix_zero(uri2Index, EMBEDDING_DIM_PRED)\n",
    "    emb_matrix_types = np.zeros((9 + 1, EMBEDDING_DIM_TYPES))\n",
    "    num_pred_words = len(uri2Index)\n",
    "    \n",
    "    return paded_tpf_pred_data, paded_tpf_types_data, num_pred_words, emb_matrix_pred, emb_matrix_types, uri2Index, index2Uri\n",
    "\n",
    "def split_by_index(data, train_indexes, val_indexes, test_indexes):\n",
    "    x_train = data[train_indexes]\n",
    "    x_val   = data[val_indexes]\n",
    "    x_test  = data[test_indexes]\n",
    "    return x_train, x_val, x_test\n",
    "    \n",
    "# lstm_type],scalery, y_train_log_std, y_val_log_std, y_test_log_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columnas: Index(['triple', 'bgp', 'join', 'leftjoin', 'union', 'filter', 'project',\n",
      "       'distinct', 'treesize', 'pcs0', 'pcs1', 'pcs2', 'pcs3', 'pcs4', 'pcs5',\n",
      "       'pcs6', 'pcs7', 'pcs8', 'pcs9', 'pcs10', 'pcs11', 'pcs12', 'pcs13',\n",
      "       'pcs14', 'pcs15', 'pcs16', 'pcs17', 'pcs18', 'pcs19', 'pcs20', 'pcs21',\n",
      "       'pcs22', 'pcs23', 'pcs24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dense_data, lstm_type_data, lstm_pred_data,  targets = separar_data(data_rnn)\n",
    "EMBEDDING_DIM_PRED = 100\n",
    "EMBEDDING_DIM_TYPES = 10\n",
    "pad_pred_data, pad_types_data, num_pred_words, emb_matrix_pred, emb_matrix_types, uri2Index, index2Uri = preprocesar_lstm_data(lstm_pred_data, lstm_type_data, EMBEDDING_DIM_PRED, EMBEDDING_DIM_TYPES)\n",
    "\n",
    "#We split the train indexes, and val indexes to half for get test_data\n",
    "all_indexes = list(range(dense_data.shape[0]))\n",
    "train_indexes, temp_indexes = train_test_split(all_indexes, test_size=0.3)\n",
    "test_indexes, val_indexes = train_test_split(temp_indexes, test_size=0.5)\n",
    "\n",
    "x_train, x_val, x_test = split_by_index(dense_data, train_indexes, val_indexes, test_indexes)\n",
    "y_train, y_val, y_test = split_by_index(targets, train_indexes, val_indexes, test_indexes)\n",
    "\n",
    "x_train_lstm_pred, x_val_lstm_pred, x_test_lstm_pred  = split_by_index(pad_pred_data, train_indexes, val_indexes, test_indexes)\n",
    "x_train_lstm_type, x_val_lstm_type, x_test_lstm_type = split_by_index(pad_types_data, train_indexes, val_indexes, test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets min:1 max: 14908\n",
      "targets in log scale min:0.0 max: 9.60965326059915\n",
      "Shapes Train (11759, 34) (11759, 15) (11759, 15)\n",
      "Shapes VAL (2520, 34) (2520, 15) (2520, 15)\n",
      "Shapes TEST (2520, 34) (2520, 15) (2520, 15)\n"
     ]
    }
   ],
   "source": [
    "#Log and Normalize\n",
    "y_train_log, y_val_log, y_test_log = log_targets(y_train, y_val, y_test)\n",
    "scalery, y_train_log_std, y_val_log_std, y_test_log_std = normalize_target(y_train_log, y_val_log, y_test_log)\n",
    "\n",
    "scalerx, x_train, x_val, x_test = normalize_xdata(x_train, x_val, x_test)\n",
    "\n",
    "print(\"Shapes Train\", x_train.shape,x_train_lstm_pred.shape, x_train_lstm_type.shape)\n",
    "print(\"Shapes VAL\", x_val.shape, x_val_lstm_pred.shape, x_val_lstm_type.shape)\n",
    "print(\"Shapes TEST\", x_test.shape, x_test_lstm_pred.shape, x_test_lstm_type.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "uniq_uris = {}\n",
    "uniq_uris['OTHER'] = 0\n",
    "for element in lstm_pred_data:\n",
    "    for item in element:\n",
    "        if item not in uniq_uris:\n",
    "            uniq_uris[item] = index\n",
    "            index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4018              [http://dbpedia.org/property/distanceMi]\n",
       "11411    [http://www.w3.org/1999/02/22-rdf-syntax-ns#ty...\n",
       "11407    [http://www.w3.org/1999/02/22-rdf-syntax-ns#ty...\n",
       "5216                [http://dbpedia.org/property/redirect]\n",
       "1892     [http://www.w3.org/2003/01/geo/wgs84_pos#geome...\n",
       "                               ...                        \n",
       "3716     [http://www.w3.org/2000/01/rdf-schema#label, h...\n",
       "6613     [http://www.w3.org/2000/01/rdf-schema#label, h...\n",
       "3023                    [http://dbpedia.org/property/area]\n",
       "4918                                                    []\n",
       "3119     [http://www.w3.org/1999/02/22-rdf-syntax-ns#type]\n",
       "Name: tpfs, Length: 11759, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pred_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "a1= to_categorical(uniq_uris['http://www.w3.org/2000/01/rdf-schema#label'],num_classes=len(uniq_uris))\n",
    "a2 =to_categorical(uniq_uris['OTHER'],num_classes=len(uniq_uris))\n",
    "a1+a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_added(x):\n",
    "    data = np.zeros(len(uniq_uris))\n",
    "    for item in x:\n",
    "        if(item not in uniq_uris):\n",
    "            dat_item = to_categorical(uniq_uris['OTHER'],num_classes=len(uniq_uris))\n",
    "        else:\n",
    "            dat_item = to_categorical(uniq_uris[item],num_classes=len(uniq_uris))\n",
    "        data = data + dat_item\n",
    "    return data\n",
    "predicates_col = lstm_pred_data.apply(lambda x: categorical_added(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatx(x_train,x_train_pred_type):\n",
    "    a = np.zeros((x_train_pred_type.shape[0],len(x_train_pred_type[0])))\n",
    "    for i in range(a.shape[0]):\n",
    "        for j in range(len(x_train_pred_type[0])):\n",
    "            a[i,j] = x_train_pred_type[i][j]\n",
    "    return np.concatenate((x_train,a),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pred_type, x_val_pred_type, x_test_pred_type = split_by_index(predicates_col.values, train_indexes, val_indexes, test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = creatx(x_train,x_train_pred_type)\n",
    "x_val2 = creatx(x_val,x_val_pred_type)\n",
    "x_test2 = creatx(x_test,x_test_pred_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn_ann(model, x_train, y_train, x_val, y_val,optimizer=None):\n",
    "    callbacks_best = [EarlyStopping(monitor='val_loss', patience=20),\n",
    "                          ModelCheckpoint(filepath='models_newdata/bestm_mixed.hdf5',\n",
    "                                          monitor='val_loss', save_best_only=True\n",
    "                                         )]\n",
    "    if optimizer is None:\n",
    "        optimizer=Adam(learning_rate=0.00015)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=[coeff_determination, rmse])\n",
    "    t0=time()\n",
    "    epochs = 550\n",
    "    print(\"before train: Init time: {}\".format(round(t0,3)))\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=120,\n",
    "                    validation_data=( x_val, y_val),\n",
    "                    callbacks=callbacks_best,\n",
    "                    verbose=True\n",
    "                     )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "def build_train_ann(x_train, y_train, x_val, y_val, n1, n2, n3, epochs, optimizer, dropout, verbose=False):\n",
    "    \n",
    "    callbacks_best = [EarlyStopping(monitor='val_loss', patience=20),\n",
    "                      ModelCheckpoint(filepath='models_newdata/bestm_newdata.h5'.format(n1,n2,n3),\n",
    "                                      monitor='val_loss', save_best_only=True\n",
    "                                     )]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n1, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n2, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n3, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae', coeff_determination, rmse])\n",
    "    t0=time()\n",
    "    print(\"before train: Init time: {}\".format(round(t0,3)))\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=120,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=callbacks_best,\n",
    "                    verbose=verbose\n",
    "                     )\n",
    "    t1=time()\n",
    "    print(\"after train, finish time: {}\".format(round(t1,3)))\n",
    "    print(\"training time {}\",format(round(t1-t0, 3)))\n",
    "    print(model.summary())\n",
    "\n",
    "    return model, history, round(t1-t0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13379, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMBEDDING_DIM_PRED = 100\n",
    "# EMBEDDING_DIM_TYPES = 10\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train: Init time: 1585678587.93\n",
      "Train on 11759 samples, validate on 2520 samples\n",
      "Epoch 1/550\n",
      "11759/11759 [==============================] - 7s 577us/step - loss: 0.4750 - coeff_determination: 0.5197 - rmse: 1.9086 - val_loss: 0.2786 - val_coeff_determination: 0.7195 - val_rmse: 1.5581\n",
      "Epoch 2/550\n",
      "11759/11759 [==============================] - 5s 430us/step - loss: 0.3266 - coeff_determination: 0.6709 - rmse: 1.6615 - val_loss: 0.2338 - val_coeff_determination: 0.7644 - val_rmse: 1.4793\n",
      "Epoch 3/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.2218 - coeff_determination: 0.7759 - rmse: 1.4859 - val_loss: 0.1775 - val_coeff_determination: 0.8212 - val_rmse: 1.3944\n",
      "Epoch 4/550\n",
      "11759/11759 [==============================] - 5s 437us/step - loss: 0.1817 - coeff_determination: 0.8165 - rmse: 1.4153 - val_loss: 0.1653 - val_coeff_determination: 0.8335 - val_rmse: 1.3736\n",
      "Epoch 5/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1647 - coeff_determination: 0.8339 - rmse: 1.3859 - val_loss: 0.1609 - val_coeff_determination: 0.8379 - val_rmse: 1.3731\n",
      "Epoch 6/550\n",
      "11759/11759 [==============================] - 5s 445us/step - loss: 0.1565 - coeff_determination: 0.8416 - rmse: 1.3744 - val_loss: 0.1602 - val_coeff_determination: 0.8386 - val_rmse: 1.3727\n",
      "Epoch 7/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1472 - coeff_determination: 0.8514 - rmse: 1.3536 - val_loss: 0.1567 - val_coeff_determination: 0.8421 - val_rmse: 1.3595\n",
      "Epoch 8/550\n",
      "11759/11759 [==============================] - 5s 429us/step - loss: 0.1433 - coeff_determination: 0.8555 - rmse: 1.3475 - val_loss: 0.1564 - val_coeff_determination: 0.8423 - val_rmse: 1.3602\n",
      "Epoch 9/550\n",
      "11759/11759 [==============================] - 5s 437us/step - loss: 0.1406 - coeff_determination: 0.8583 - rmse: 1.3413 - val_loss: 0.1543 - val_coeff_determination: 0.8445 - val_rmse: 1.3516\n",
      "Epoch 10/550\n",
      "11759/11759 [==============================] - 5s 431us/step - loss: 0.1379 - coeff_determination: 0.8606 - rmse: 1.3341 - val_loss: 0.1552 - val_coeff_determination: 0.8436 - val_rmse: 1.3550\n",
      "Epoch 11/550\n",
      "11759/11759 [==============================] - 5s 433us/step - loss: 0.1370 - coeff_determination: 0.8619 - rmse: 1.3324 - val_loss: 0.1502 - val_coeff_determination: 0.8487 - val_rmse: 1.3450\n",
      "Epoch 12/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1358 - coeff_determination: 0.8631 - rmse: 1.3312 - val_loss: 0.1516 - val_coeff_determination: 0.8472 - val_rmse: 1.3486\n",
      "Epoch 13/550\n",
      "11759/11759 [==============================] - 5s 432us/step - loss: 0.1343 - coeff_determination: 0.8644 - rmse: 1.3251 - val_loss: 0.1495 - val_coeff_determination: 0.8493 - val_rmse: 1.3527\n",
      "Epoch 14/550\n",
      "11759/11759 [==============================] - 5s 435us/step - loss: 0.1334 - coeff_determination: 0.8653 - rmse: 1.3249 - val_loss: 0.1480 - val_coeff_determination: 0.8508 - val_rmse: 1.3464\n",
      "Epoch 15/550\n",
      "11759/11759 [==============================] - 5s 435us/step - loss: 0.1300 - coeff_determination: 0.8689 - rmse: 1.3176 - val_loss: 0.1489 - val_coeff_determination: 0.8500 - val_rmse: 1.3508\n",
      "Epoch 16/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1313 - coeff_determination: 0.8674 - rmse: 1.3196 - val_loss: 0.1467 - val_coeff_determination: 0.8522 - val_rmse: 1.3444\n",
      "Epoch 17/550\n",
      "11759/11759 [==============================] - 5s 437us/step - loss: 0.1290 - coeff_determination: 0.8700 - rmse: 1.3161 - val_loss: 0.1468 - val_coeff_determination: 0.8521 - val_rmse: 1.3431\n",
      "Epoch 18/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1293 - coeff_determination: 0.8696 - rmse: 1.3175 - val_loss: 0.1502 - val_coeff_determination: 0.8486 - val_rmse: 1.3478\n",
      "Epoch 19/550\n",
      "11759/11759 [==============================] - 5s 433us/step - loss: 0.1284 - coeff_determination: 0.8706 - rmse: 1.3136 - val_loss: 0.1465 - val_coeff_determination: 0.8524 - val_rmse: 1.3360\n",
      "Epoch 20/550\n",
      "11759/11759 [==============================] - 5s 424us/step - loss: 0.1260 - coeff_determination: 0.8730 - rmse: 1.3078 - val_loss: 0.1447 - val_coeff_determination: 0.8541 - val_rmse: 1.3350\n",
      "Epoch 21/550\n",
      "11759/11759 [==============================] - 5s 436us/step - loss: 0.1260 - coeff_determination: 0.8731 - rmse: 1.3090 - val_loss: 0.1452 - val_coeff_determination: 0.8536 - val_rmse: 1.3362\n",
      "Epoch 22/550\n",
      "11759/11759 [==============================] - 5s 440us/step - loss: 0.1241 - coeff_determination: 0.8747 - rmse: 1.3044 - val_loss: 0.1429 - val_coeff_determination: 0.8560 - val_rmse: 1.3307\n",
      "Epoch 23/550\n",
      "11759/11759 [==============================] - 5s 444us/step - loss: 0.1236 - coeff_determination: 0.8755 - rmse: 1.3044 - val_loss: 0.1423 - val_coeff_determination: 0.8566 - val_rmse: 1.3262\n",
      "Epoch 24/550\n",
      "11759/11759 [==============================] - 5s 440us/step - loss: 0.1237 - coeff_determination: 0.8753 - rmse: 1.3036 - val_loss: 0.1447 - val_coeff_determination: 0.8541 - val_rmse: 1.3383\n",
      "Epoch 25/550\n",
      "11759/11759 [==============================] - 5s 435us/step - loss: 0.1240 - coeff_determination: 0.8749 - rmse: 1.3037 - val_loss: 0.1431 - val_coeff_determination: 0.8557 - val_rmse: 1.3357\n",
      "Epoch 26/550\n",
      "11759/11759 [==============================] - 5s 437us/step - loss: 0.1229 - coeff_determination: 0.8758 - rmse: 1.3016 - val_loss: 0.1437 - val_coeff_determination: 0.8551 - val_rmse: 1.3390\n",
      "Epoch 27/550\n",
      "11759/11759 [==============================] - 5s 431us/step - loss: 0.1228 - coeff_determination: 0.8763 - rmse: 1.3026 - val_loss: 0.1423 - val_coeff_determination: 0.8566 - val_rmse: 1.3288\n",
      "Epoch 28/550\n",
      "11759/11759 [==============================] - 5s 437us/step - loss: 0.1210 - coeff_determination: 0.8780 - rmse: 1.2993 - val_loss: 0.1438 - val_coeff_determination: 0.8551 - val_rmse: 1.3350\n",
      "Epoch 29/550\n",
      "11759/11759 [==============================] - 5s 433us/step - loss: 0.1221 - coeff_determination: 0.8767 - rmse: 1.3017 - val_loss: 0.1400 - val_coeff_determination: 0.8589 - val_rmse: 1.3325\n",
      "Epoch 30/550\n",
      "11759/11759 [==============================] - 5s 431us/step - loss: 0.1192 - coeff_determination: 0.8797 - rmse: 1.2948 - val_loss: 0.1415 - val_coeff_determination: 0.8574 - val_rmse: 1.3325\n",
      "Epoch 31/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1210 - coeff_determination: 0.8778 - rmse: 1.2996 - val_loss: 0.1385 - val_coeff_determination: 0.8604 - val_rmse: 1.3283\n",
      "Epoch 32/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1197 - coeff_determination: 0.8796 - rmse: 1.2965 - val_loss: 0.1382 - val_coeff_determination: 0.8607 - val_rmse: 1.3285\n",
      "Epoch 33/550\n",
      "11759/11759 [==============================] - 5s 439us/step - loss: 0.1181 - coeff_determination: 0.8807 - rmse: 1.2926 - val_loss: 0.1364 - val_coeff_determination: 0.8624 - val_rmse: 1.3209\n",
      "Epoch 34/550\n",
      "11759/11759 [==============================] - 5s 439us/step - loss: 0.1195 - coeff_determination: 0.8792 - rmse: 1.2954 - val_loss: 0.1383 - val_coeff_determination: 0.8606 - val_rmse: 1.3308\n",
      "Epoch 35/550\n",
      "11759/11759 [==============================] - 5s 441us/step - loss: 0.1175 - coeff_determination: 0.8817 - rmse: 1.2914 - val_loss: 0.1355 - val_coeff_determination: 0.8634 - val_rmse: 1.3217\n",
      "Epoch 36/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1164 - coeff_determination: 0.8824 - rmse: 1.2901 - val_loss: 0.1392 - val_coeff_determination: 0.8597 - val_rmse: 1.3292\n",
      "Epoch 37/550\n",
      "11759/11759 [==============================] - 5s 432us/step - loss: 0.1158 - coeff_determination: 0.8833 - rmse: 1.2887 - val_loss: 0.1358 - val_coeff_determination: 0.8631 - val_rmse: 1.3234\n",
      "Epoch 38/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1164 - coeff_determination: 0.8828 - rmse: 1.2897 - val_loss: 0.1359 - val_coeff_determination: 0.8630 - val_rmse: 1.3251\n",
      "Epoch 39/550\n",
      "11759/11759 [==============================] - 5s 436us/step - loss: 0.1158 - coeff_determination: 0.8834 - rmse: 1.2882 - val_loss: 0.1392 - val_coeff_determination: 0.8597 - val_rmse: 1.3389\n",
      "Epoch 40/550\n",
      "11759/11759 [==============================] - 5s 437us/step - loss: 0.1145 - coeff_determination: 0.8848 - rmse: 1.2877 - val_loss: 0.1333 - val_coeff_determination: 0.8656 - val_rmse: 1.3171\n",
      "Epoch 41/550\n",
      "11759/11759 [==============================] - 5s 436us/step - loss: 0.1142 - coeff_determination: 0.8849 - rmse: 1.2855 - val_loss: 0.1348 - val_coeff_determination: 0.8641 - val_rmse: 1.3263\n",
      "Epoch 42/550\n",
      "11759/11759 [==============================] - 5s 432us/step - loss: 0.1130 - coeff_determination: 0.8862 - rmse: 1.2839 - val_loss: 0.1334 - val_coeff_determination: 0.8655 - val_rmse: 1.3206\n",
      "Epoch 43/550\n",
      "11759/11759 [==============================] - 5s 440us/step - loss: 0.1133 - coeff_determination: 0.8856 - rmse: 1.2854 - val_loss: 0.1329 - val_coeff_determination: 0.8660 - val_rmse: 1.3196\n",
      "Epoch 44/550\n",
      "11759/11759 [==============================] - 5s 435us/step - loss: 0.1153 - coeff_determination: 0.8835 - rmse: 1.2887 - val_loss: 0.1326 - val_coeff_determination: 0.8663 - val_rmse: 1.3181\n",
      "Epoch 45/550\n",
      "11759/11759 [==============================] - 5s 433us/step - loss: 0.1130 - coeff_determination: 0.8861 - rmse: 1.2827 - val_loss: 0.1331 - val_coeff_determination: 0.8658 - val_rmse: 1.3212\n",
      "Epoch 46/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1111 - coeff_determination: 0.8882 - rmse: 1.2807 - val_loss: 0.1358 - val_coeff_determination: 0.8631 - val_rmse: 1.3253\n",
      "Epoch 47/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1129 - coeff_determination: 0.8859 - rmse: 1.2829 - val_loss: 0.1324 - val_coeff_determination: 0.8665 - val_rmse: 1.3234\n",
      "Epoch 48/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1128 - coeff_determination: 0.8863 - rmse: 1.2836 - val_loss: 0.1329 - val_coeff_determination: 0.8661 - val_rmse: 1.3252\n",
      "Epoch 49/550\n",
      "11759/11759 [==============================] - 5s 435us/step - loss: 0.1101 - coeff_determination: 0.8891 - rmse: 1.2780 - val_loss: 0.1297 - val_coeff_determination: 0.8692 - val_rmse: 1.3129\n",
      "Epoch 50/550\n",
      "11759/11759 [==============================] - 5s 430us/step - loss: 0.1096 - coeff_determination: 0.8892 - rmse: 1.2771 - val_loss: 0.1336 - val_coeff_determination: 0.8653 - val_rmse: 1.3258\n",
      "Epoch 51/550\n",
      "11759/11759 [==============================] - 5s 431us/step - loss: 0.1103 - coeff_determination: 0.8888 - rmse: 1.2775 - val_loss: 0.1332 - val_coeff_determination: 0.8657 - val_rmse: 1.3200\n",
      "Epoch 52/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1097 - coeff_determination: 0.8892 - rmse: 1.2773 - val_loss: 0.1313 - val_coeff_determination: 0.8676 - val_rmse: 1.3207\n",
      "Epoch 53/550\n",
      "11759/11759 [==============================] - 5s 440us/step - loss: 0.1077 - coeff_determination: 0.8913 - rmse: 1.2719 - val_loss: 0.1304 - val_coeff_determination: 0.8685 - val_rmse: 1.3137\n",
      "Epoch 54/550\n",
      "11759/11759 [==============================] - 5s 440us/step - loss: 0.1088 - coeff_determination: 0.8903 - rmse: 1.2756 - val_loss: 0.1305 - val_coeff_determination: 0.8684 - val_rmse: 1.3197\n",
      "Epoch 55/550\n",
      "11759/11759 [==============================] - 5s 445us/step - loss: 0.1089 - coeff_determination: 0.8902 - rmse: 1.2759 - val_loss: 0.1314 - val_coeff_determination: 0.8675 - val_rmse: 1.3149\n",
      "Epoch 56/550\n",
      "11759/11759 [==============================] - 5s 432us/step - loss: 0.1072 - coeff_determination: 0.8921 - rmse: 1.2719 - val_loss: 0.1304 - val_coeff_determination: 0.8684 - val_rmse: 1.3171\n",
      "Epoch 57/550\n",
      "11759/11759 [==============================] - 5s 439us/step - loss: 0.1072 - coeff_determination: 0.8918 - rmse: 1.2718 - val_loss: 0.1325 - val_coeff_determination: 0.8663 - val_rmse: 1.3182\n",
      "Epoch 58/550\n",
      "11759/11759 [==============================] - 5s 432us/step - loss: 0.1083 - coeff_determination: 0.8909 - rmse: 1.2736 - val_loss: 0.1289 - val_coeff_determination: 0.8700 - val_rmse: 1.3120\n",
      "Epoch 59/550\n",
      "11759/11759 [==============================] - 5s 431us/step - loss: 0.1064 - coeff_determination: 0.8927 - rmse: 1.2699 - val_loss: 0.1310 - val_coeff_determination: 0.8679 - val_rmse: 1.3154\n",
      "Epoch 60/550\n",
      "11759/11759 [==============================] - 5s 433us/step - loss: 0.1058 - coeff_determination: 0.8931 - rmse: 1.2695 - val_loss: 0.1310 - val_coeff_determination: 0.8678 - val_rmse: 1.3152\n",
      "Epoch 61/550\n",
      "11759/11759 [==============================] - 5s 436us/step - loss: 0.1091 - coeff_determination: 0.8897 - rmse: 1.2766 - val_loss: 0.1300 - val_coeff_determination: 0.8688 - val_rmse: 1.3173\n",
      "Epoch 62/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1047 - coeff_determination: 0.8942 - rmse: 1.2680 - val_loss: 0.1294 - val_coeff_determination: 0.8695 - val_rmse: 1.3100\n",
      "Epoch 63/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1046 - coeff_determination: 0.8944 - rmse: 1.2668 - val_loss: 0.1347 - val_coeff_determination: 0.8642 - val_rmse: 1.3269\n",
      "Epoch 64/550\n",
      "11759/11759 [==============================] - 5s 433us/step - loss: 0.1057 - coeff_determination: 0.8932 - rmse: 1.2699 - val_loss: 0.1294 - val_coeff_determination: 0.8694 - val_rmse: 1.3160\n",
      "Epoch 65/550\n",
      "11759/11759 [==============================] - 5s 431us/step - loss: 0.1056 - coeff_determination: 0.8936 - rmse: 1.2696 - val_loss: 0.1291 - val_coeff_determination: 0.8698 - val_rmse: 1.3148\n",
      "Epoch 66/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1059 - coeff_determination: 0.8928 - rmse: 1.2687 - val_loss: 0.1338 - val_coeff_determination: 0.8651 - val_rmse: 1.3318\n",
      "Epoch 67/550\n",
      "11759/11759 [==============================] - 5s 440us/step - loss: 0.1050 - coeff_determination: 0.8939 - rmse: 1.2681 - val_loss: 0.1303 - val_coeff_determination: 0.8686 - val_rmse: 1.3140\n",
      "Epoch 68/550\n",
      "11759/11759 [==============================] - 5s 436us/step - loss: 0.1045 - coeff_determination: 0.8944 - rmse: 1.2664 - val_loss: 0.1306 - val_coeff_determination: 0.8682 - val_rmse: 1.3114\n",
      "Epoch 69/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1055 - coeff_determination: 0.8933 - rmse: 1.2695 - val_loss: 0.1322 - val_coeff_determination: 0.8667 - val_rmse: 1.3224\n",
      "Epoch 70/550\n",
      "11759/11759 [==============================] - 5s 439us/step - loss: 0.1043 - coeff_determination: 0.8949 - rmse: 1.2669 - val_loss: 0.1285 - val_coeff_determination: 0.8703 - val_rmse: 1.3097\n",
      "Epoch 71/550\n",
      "11759/11759 [==============================] - 5s 432us/step - loss: 0.1048 - coeff_determination: 0.8945 - rmse: 1.2655 - val_loss: 0.1309 - val_coeff_determination: 0.8680 - val_rmse: 1.3193\n",
      "Epoch 72/550\n",
      "11759/11759 [==============================] - 5s 432us/step - loss: 0.1037 - coeff_determination: 0.8952 - rmse: 1.2648 - val_loss: 0.1292 - val_coeff_determination: 0.8696 - val_rmse: 1.3151\n",
      "Epoch 73/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1033 - coeff_determination: 0.8959 - rmse: 1.2634 - val_loss: 0.1289 - val_coeff_determination: 0.8700 - val_rmse: 1.3144\n",
      "Epoch 74/550\n",
      "11759/11759 [==============================] - 5s 440us/step - loss: 0.1020 - coeff_determination: 0.8969 - rmse: 1.2610 - val_loss: 0.1294 - val_coeff_determination: 0.8694 - val_rmse: 1.3138\n",
      "Epoch 75/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1030 - coeff_determination: 0.8963 - rmse: 1.2629 - val_loss: 0.1299 - val_coeff_determination: 0.8690 - val_rmse: 1.3128\n",
      "Epoch 76/550\n",
      "11759/11759 [==============================] - 5s 441us/step - loss: 0.1032 - coeff_determination: 0.8959 - rmse: 1.2642 - val_loss: 0.1320 - val_coeff_determination: 0.8669 - val_rmse: 1.3240\n",
      "Epoch 77/550\n",
      "11759/11759 [==============================] - 5s 439us/step - loss: 0.1023 - coeff_determination: 0.8971 - rmse: 1.2614 - val_loss: 0.1275 - val_coeff_determination: 0.8713 - val_rmse: 1.3064\n",
      "Epoch 78/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1024 - coeff_determination: 0.8968 - rmse: 1.2617 - val_loss: 0.1295 - val_coeff_determination: 0.8693 - val_rmse: 1.3160\n",
      "Epoch 79/550\n",
      "11759/11759 [==============================] - 5s 428us/step - loss: 0.1019 - coeff_determination: 0.8971 - rmse: 1.2603 - val_loss: 0.1288 - val_coeff_determination: 0.8700 - val_rmse: 1.3137\n",
      "Epoch 80/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1026 - coeff_determination: 0.8963 - rmse: 1.2634 - val_loss: 0.1285 - val_coeff_determination: 0.8703 - val_rmse: 1.3082\n",
      "Epoch 81/550\n",
      "11759/11759 [==============================] - 5s 432us/step - loss: 0.1025 - coeff_determination: 0.8964 - rmse: 1.2618 - val_loss: 0.1304 - val_coeff_determination: 0.8684 - val_rmse: 1.3169\n",
      "Epoch 82/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1022 - coeff_determination: 0.8971 - rmse: 1.2606 - val_loss: 0.1289 - val_coeff_determination: 0.8699 - val_rmse: 1.3063\n",
      "Epoch 83/550\n",
      "11759/11759 [==============================] - 5s 431us/step - loss: 0.1016 - coeff_determination: 0.8975 - rmse: 1.2608 - val_loss: 0.1289 - val_coeff_determination: 0.8699 - val_rmse: 1.3058\n",
      "Epoch 84/550\n",
      "11759/11759 [==============================] - 5s 435us/step - loss: 0.1013 - coeff_determination: 0.8979 - rmse: 1.2584 - val_loss: 0.1299 - val_coeff_determination: 0.8689 - val_rmse: 1.3141\n",
      "Epoch 85/550\n",
      "11759/11759 [==============================] - 5s 438us/step - loss: 0.1028 - coeff_determination: 0.8962 - rmse: 1.2633 - val_loss: 0.1303 - val_coeff_determination: 0.8685 - val_rmse: 1.3111\n",
      "Epoch 86/550\n",
      "11759/11759 [==============================] - 5s 428us/step - loss: 0.1015 - coeff_determination: 0.8974 - rmse: 1.2599 - val_loss: 0.1311 - val_coeff_determination: 0.8677 - val_rmse: 1.3185\n",
      "Epoch 87/550\n",
      "11759/11759 [==============================] - 5s 437us/step - loss: 0.1013 - coeff_determination: 0.8979 - rmse: 1.2589 - val_loss: 0.1315 - val_coeff_determination: 0.8673 - val_rmse: 1.3182\n",
      "Epoch 88/550\n",
      "11759/11759 [==============================] - 5s 436us/step - loss: 0.1019 - coeff_determination: 0.8973 - rmse: 1.2602 - val_loss: 0.1292 - val_coeff_determination: 0.8696 - val_rmse: 1.3057\n",
      "Epoch 89/550\n",
      "11759/11759 [==============================] - 5s 431us/step - loss: 0.1010 - coeff_determination: 0.8982 - rmse: 1.2581 - val_loss: 0.1302 - val_coeff_determination: 0.8687 - val_rmse: 1.3178\n",
      "Epoch 90/550\n",
      "11759/11759 [==============================] - 5s 436us/step - loss: 0.0998 - coeff_determination: 0.8991 - rmse: 1.2558 - val_loss: 0.1294 - val_coeff_determination: 0.8694 - val_rmse: 1.3084\n",
      "Epoch 91/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1017 - coeff_determination: 0.8972 - rmse: 1.2594 - val_loss: 0.1281 - val_coeff_determination: 0.8707 - val_rmse: 1.3050\n",
      "Epoch 92/550\n",
      "11759/11759 [==============================] - 5s 442us/step - loss: 0.1006 - coeff_determination: 0.8985 - rmse: 1.2575 - val_loss: 0.1278 - val_coeff_determination: 0.8710 - val_rmse: 1.3063\n",
      "Epoch 93/550\n",
      "11759/11759 [==============================] - 5s 437us/step - loss: 0.0999 - coeff_determination: 0.8991 - rmse: 1.2561 - val_loss: 0.1300 - val_coeff_determination: 0.8688 - val_rmse: 1.3110\n",
      "Epoch 94/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.1007 - coeff_determination: 0.8983 - rmse: 1.2573 - val_loss: 0.1301 - val_coeff_determination: 0.8687 - val_rmse: 1.3120\n",
      "Epoch 95/550\n",
      "11759/11759 [==============================] - 5s 432us/step - loss: 0.0998 - coeff_determination: 0.8994 - rmse: 1.2557 - val_loss: 0.1290 - val_coeff_determination: 0.8698 - val_rmse: 1.3091\n",
      "Epoch 96/550\n",
      "11759/11759 [==============================] - 5s 439us/step - loss: 0.0985 - coeff_determination: 0.9004 - rmse: 1.2532 - val_loss: 0.1304 - val_coeff_determination: 0.8683 - val_rmse: 1.3096\n",
      "Epoch 97/550\n",
      "11759/11759 [==============================] - 5s 434us/step - loss: 0.0990 - coeff_determination: 0.9001 - rmse: 1.2539 - val_loss: 0.1293 - val_coeff_determination: 0.8695 - val_rmse: 1.3069\n"
     ]
    }
   ],
   "source": [
    "model  = build_RNN(\n",
    "    num_pred_words,\n",
    "    EMBEDDING_DIM_PRED,\n",
    "    EMBEDDING_DIM_TYPES,\n",
    "    emb_matrix_pred,\n",
    "    emb_matrix_types,\n",
    "    lstm_units=32,\n",
    "    lstm_types_units=5\n",
    "    )\n",
    "model,history = train_rnn_ann(\n",
    "    model, \n",
    "    [x_train_lstm_type, x_train_lstm_pred, x_train],\n",
    "    y_train_log_std, \n",
    "    [x_val_lstm_type, x_val_lstm_pred, x_val], \n",
    "    y_val_log_std\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model  = build_RNN2(\n",
    "    num_pred_words,\n",
    "    EMBEDDING_DIM_PRED,\n",
    "    EMBEDDING_DIM_TYPES,\n",
    "    emb_matrix_pred,\n",
    "    emb_matrix_types,\n",
    "    lstm_units=32,\n",
    "    lstm_types_units=5\n",
    "    )\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')\n",
    "model,history = train_rnn_ann(model, [x_train_lstm_type, x_train_lstm_pred], y_train_log_std, [x_val_lstm_type, x_val_lstm_pred], y_val_log_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train: Init time: 1585677696.846\n",
      "Train on 11759 samples, validate on 2520 samples\n",
      "Epoch 1/550\n",
      "11759/11759 [==============================] - 1s 96us/step - loss: 0.4618 - coeff_determination: 0.5339 - rmse: 1.8893 - val_loss: 0.2966 - val_coeff_determination: 0.7012 - val_rmse: 1.5849\n",
      "Epoch 2/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.3352 - coeff_determination: 0.6623 - rmse: 1.6751 - val_loss: 0.2595 - val_coeff_determination: 0.7386 - val_rmse: 1.5280\n",
      "Epoch 3/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.3107 - coeff_determination: 0.6862 - rmse: 1.6314 - val_loss: 0.2543 - val_coeff_determination: 0.7439 - val_rmse: 1.5234\n",
      "Epoch 4/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.2961 - coeff_determination: 0.7015 - rmse: 1.6062 - val_loss: 0.2439 - val_coeff_determination: 0.7543 - val_rmse: 1.5006\n",
      "Epoch 5/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.2854 - coeff_determination: 0.7118 - rmse: 1.5887 - val_loss: 0.2382 - val_coeff_determination: 0.7601 - val_rmse: 1.4898\n",
      "Epoch 6/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.2757 - coeff_determination: 0.7221 - rmse: 1.5721 - val_loss: 0.2468 - val_coeff_determination: 0.7515 - val_rmse: 1.5096\n",
      "Epoch 7/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.2686 - coeff_determination: 0.7290 - rmse: 1.5575 - val_loss: 0.2370 - val_coeff_determination: 0.7614 - val_rmse: 1.5049\n",
      "Epoch 8/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.2609 - coeff_determination: 0.7359 - rmse: 1.5438 - val_loss: 0.2378 - val_coeff_determination: 0.7606 - val_rmse: 1.5041\n",
      "Epoch 9/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.2541 - coeff_determination: 0.7440 - rmse: 1.5314 - val_loss: 0.2312 - val_coeff_determination: 0.7672 - val_rmse: 1.4997\n",
      "Epoch 10/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.2449 - coeff_determination: 0.7535 - rmse: 1.5163 - val_loss: 0.2325 - val_coeff_determination: 0.7659 - val_rmse: 1.5080\n",
      "Epoch 11/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.2455 - coeff_determination: 0.7522 - rmse: 1.5174 - val_loss: 0.2289 - val_coeff_determination: 0.7695 - val_rmse: 1.4948\n",
      "Epoch 12/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2390 - coeff_determination: 0.7584 - rmse: 1.5066 - val_loss: 0.2254 - val_coeff_determination: 0.7730 - val_rmse: 1.4915\n",
      "Epoch 13/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.2331 - coeff_determination: 0.7646 - rmse: 1.4957 - val_loss: 0.2306 - val_coeff_determination: 0.7678 - val_rmse: 1.5032\n",
      "Epoch 14/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.2297 - coeff_determination: 0.7688 - rmse: 1.4908 - val_loss: 0.2278 - val_coeff_determination: 0.7706 - val_rmse: 1.5015\n",
      "Epoch 15/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.2273 - coeff_determination: 0.7704 - rmse: 1.4851 - val_loss: 0.2239 - val_coeff_determination: 0.7745 - val_rmse: 1.4907\n",
      "Epoch 16/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.2237 - coeff_determination: 0.7746 - rmse: 1.4782 - val_loss: 0.2233 - val_coeff_determination: 0.7751 - val_rmse: 1.4962\n",
      "Epoch 17/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.2198 - coeff_determination: 0.7788 - rmse: 1.4733 - val_loss: 0.2253 - val_coeff_determination: 0.7731 - val_rmse: 1.5079\n",
      "Epoch 18/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.2154 - coeff_determination: 0.7824 - rmse: 1.4648 - val_loss: 0.2305 - val_coeff_determination: 0.7679 - val_rmse: 1.5180\n",
      "Epoch 19/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.2155 - coeff_determination: 0.7825 - rmse: 1.4636 - val_loss: 0.2325 - val_coeff_determination: 0.7659 - val_rmse: 1.5219\n",
      "Epoch 20/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.2160 - coeff_determination: 0.7821 - rmse: 1.4656 - val_loss: 0.2238 - val_coeff_determination: 0.7746 - val_rmse: 1.5028\n",
      "Epoch 21/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.2101 - coeff_determination: 0.7875 - rmse: 1.4538 - val_loss: 0.2258 - val_coeff_determination: 0.7727 - val_rmse: 1.5086\n",
      "Epoch 22/550\n",
      "11759/11759 [==============================] - 1s 74us/step - loss: 0.2081 - coeff_determination: 0.7898 - rmse: 1.4505 - val_loss: 0.2232 - val_coeff_determination: 0.7752 - val_rmse: 1.5054\n",
      "Epoch 23/550\n",
      "11759/11759 [==============================] - 1s 74us/step - loss: 0.2067 - coeff_determination: 0.7910 - rmse: 1.4467 - val_loss: 0.2295 - val_coeff_determination: 0.7690 - val_rmse: 1.5185\n",
      "Epoch 24/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.2061 - coeff_determination: 0.7923 - rmse: 1.4456 - val_loss: 0.2246 - val_coeff_determination: 0.7738 - val_rmse: 1.5057\n",
      "Epoch 25/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.2053 - coeff_determination: 0.7929 - rmse: 1.4436 - val_loss: 0.2307 - val_coeff_determination: 0.7676 - val_rmse: 1.5235\n",
      "Epoch 26/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.2047 - coeff_determination: 0.7942 - rmse: 1.4424 - val_loss: 0.2185 - val_coeff_determination: 0.7799 - val_rmse: 1.4858\n",
      "Epoch 27/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.2020 - coeff_determination: 0.7961 - rmse: 1.4370 - val_loss: 0.2152 - val_coeff_determination: 0.7832 - val_rmse: 1.4854\n",
      "Epoch 28/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.2014 - coeff_determination: 0.7968 - rmse: 1.4365 - val_loss: 0.2223 - val_coeff_determination: 0.7761 - val_rmse: 1.4993\n",
      "Epoch 29/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1995 - coeff_determination: 0.7992 - rmse: 1.4325 - val_loss: 0.2214 - val_coeff_determination: 0.7770 - val_rmse: 1.5048\n",
      "Epoch 30/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1978 - coeff_determination: 0.7996 - rmse: 1.4296 - val_loss: 0.2165 - val_coeff_determination: 0.7819 - val_rmse: 1.4969\n",
      "Epoch 31/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1965 - coeff_determination: 0.8016 - rmse: 1.4268 - val_loss: 0.2184 - val_coeff_determination: 0.7800 - val_rmse: 1.4991\n",
      "Epoch 32/550\n",
      "11759/11759 [==============================] - 1s 74us/step - loss: 0.1966 - coeff_determination: 0.8021 - rmse: 1.4273 - val_loss: 0.2181 - val_coeff_determination: 0.7803 - val_rmse: 1.4972\n",
      "Epoch 33/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1935 - coeff_determination: 0.8050 - rmse: 1.4215 - val_loss: 0.2152 - val_coeff_determination: 0.7832 - val_rmse: 1.4877\n",
      "Epoch 34/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1911 - coeff_determination: 0.8075 - rmse: 1.4172 - val_loss: 0.2168 - val_coeff_determination: 0.7816 - val_rmse: 1.4877\n",
      "Epoch 35/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1914 - coeff_determination: 0.8075 - rmse: 1.4171 - val_loss: 0.2178 - val_coeff_determination: 0.7806 - val_rmse: 1.4919\n",
      "Epoch 36/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1884 - coeff_determination: 0.8101 - rmse: 1.4115 - val_loss: 0.2121 - val_coeff_determination: 0.7864 - val_rmse: 1.4882\n",
      "Epoch 37/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1880 - coeff_determination: 0.8103 - rmse: 1.4117 - val_loss: 0.2092 - val_coeff_determination: 0.7893 - val_rmse: 1.4802\n",
      "Epoch 38/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1870 - coeff_determination: 0.8114 - rmse: 1.4089 - val_loss: 0.2142 - val_coeff_determination: 0.7843 - val_rmse: 1.4943\n",
      "Epoch 39/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1869 - coeff_determination: 0.8115 - rmse: 1.4096 - val_loss: 0.2153 - val_coeff_determination: 0.7832 - val_rmse: 1.4955\n",
      "Epoch 40/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1867 - coeff_determination: 0.8116 - rmse: 1.4085 - val_loss: 0.2159 - val_coeff_determination: 0.7825 - val_rmse: 1.4940\n",
      "Epoch 41/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1852 - coeff_determination: 0.8136 - rmse: 1.4043 - val_loss: 0.2146 - val_coeff_determination: 0.7838 - val_rmse: 1.4978\n",
      "Epoch 42/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1848 - coeff_determination: 0.8128 - rmse: 1.4050 - val_loss: 0.2152 - val_coeff_determination: 0.7833 - val_rmse: 1.4932\n",
      "Epoch 43/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1869 - coeff_determination: 0.8116 - rmse: 1.4078 - val_loss: 0.2141 - val_coeff_determination: 0.7844 - val_rmse: 1.4944\n",
      "Epoch 44/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1825 - coeff_determination: 0.8159 - rmse: 1.3996 - val_loss: 0.2133 - val_coeff_determination: 0.7852 - val_rmse: 1.4922\n",
      "Epoch 45/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1815 - coeff_determination: 0.8169 - rmse: 1.3987 - val_loss: 0.2132 - val_coeff_determination: 0.7853 - val_rmse: 1.4876\n",
      "Epoch 46/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1814 - coeff_determination: 0.8171 - rmse: 1.3981 - val_loss: 0.2108 - val_coeff_determination: 0.7877 - val_rmse: 1.4914\n",
      "Epoch 47/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1797 - coeff_determination: 0.8188 - rmse: 1.3951 - val_loss: 0.2108 - val_coeff_determination: 0.7877 - val_rmse: 1.4861\n",
      "Epoch 48/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1793 - coeff_determination: 0.8197 - rmse: 1.3933 - val_loss: 0.2087 - val_coeff_determination: 0.7898 - val_rmse: 1.4823\n",
      "Epoch 49/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1762 - coeff_determination: 0.8227 - rmse: 1.3880 - val_loss: 0.2107 - val_coeff_determination: 0.7878 - val_rmse: 1.4814\n",
      "Epoch 50/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1800 - coeff_determination: 0.8182 - rmse: 1.3938 - val_loss: 0.2060 - val_coeff_determination: 0.7926 - val_rmse: 1.4777\n",
      "Epoch 51/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1780 - coeff_determination: 0.8203 - rmse: 1.3904 - val_loss: 0.2110 - val_coeff_determination: 0.7875 - val_rmse: 1.4890\n",
      "Epoch 52/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1763 - coeff_determination: 0.8223 - rmse: 1.3879 - val_loss: 0.2072 - val_coeff_determination: 0.7914 - val_rmse: 1.4776\n",
      "Epoch 53/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1762 - coeff_determination: 0.8223 - rmse: 1.3876 - val_loss: 0.2131 - val_coeff_determination: 0.7854 - val_rmse: 1.4918\n",
      "Epoch 54/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1740 - coeff_determination: 0.8243 - rmse: 1.3840 - val_loss: 0.2036 - val_coeff_determination: 0.7949 - val_rmse: 1.4705\n",
      "Epoch 55/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1759 - coeff_determination: 0.8229 - rmse: 1.3866 - val_loss: 0.2038 - val_coeff_determination: 0.7948 - val_rmse: 1.4698\n",
      "Epoch 56/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1742 - coeff_determination: 0.8243 - rmse: 1.3831 - val_loss: 0.2015 - val_coeff_determination: 0.7971 - val_rmse: 1.4658\n",
      "Epoch 57/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1743 - coeff_determination: 0.8243 - rmse: 1.3825 - val_loss: 0.2021 - val_coeff_determination: 0.7964 - val_rmse: 1.4649\n",
      "Epoch 58/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1741 - coeff_determination: 0.8243 - rmse: 1.3826 - val_loss: 0.2007 - val_coeff_determination: 0.7978 - val_rmse: 1.4628\n",
      "Epoch 59/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1724 - coeff_determination: 0.8261 - rmse: 1.3785 - val_loss: 0.2013 - val_coeff_determination: 0.7973 - val_rmse: 1.4617\n",
      "Epoch 60/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1726 - coeff_determination: 0.8263 - rmse: 1.3791 - val_loss: 0.2029 - val_coeff_determination: 0.7956 - val_rmse: 1.4709\n",
      "Epoch 61/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1729 - coeff_determination: 0.8261 - rmse: 1.3807 - val_loss: 0.1971 - val_coeff_determination: 0.8015 - val_rmse: 1.4542\n",
      "Epoch 62/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1728 - coeff_determination: 0.8255 - rmse: 1.3797 - val_loss: 0.1945 - val_coeff_determination: 0.8041 - val_rmse: 1.4481\n",
      "Epoch 63/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1723 - coeff_determination: 0.8256 - rmse: 1.3783 - val_loss: 0.1937 - val_coeff_determination: 0.8049 - val_rmse: 1.4425\n",
      "Epoch 64/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1699 - coeff_determination: 0.8287 - rmse: 1.3731 - val_loss: 0.1943 - val_coeff_determination: 0.8044 - val_rmse: 1.4507\n",
      "Epoch 65/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1711 - coeff_determination: 0.8272 - rmse: 1.3757 - val_loss: 0.1935 - val_coeff_determination: 0.8051 - val_rmse: 1.4437\n",
      "Epoch 66/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1716 - coeff_determination: 0.8266 - rmse: 1.3764 - val_loss: 0.1899 - val_coeff_determination: 0.8087 - val_rmse: 1.4351\n",
      "Epoch 67/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1704 - coeff_determination: 0.8280 - rmse: 1.3745 - val_loss: 0.1947 - val_coeff_determination: 0.8039 - val_rmse: 1.4496\n",
      "Epoch 68/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1703 - coeff_determination: 0.8281 - rmse: 1.3737 - val_loss: 0.1903 - val_coeff_determination: 0.8083 - val_rmse: 1.4363\n",
      "Epoch 69/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1696 - coeff_determination: 0.8284 - rmse: 1.3724 - val_loss: 0.1918 - val_coeff_determination: 0.8068 - val_rmse: 1.4412\n",
      "Epoch 70/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1699 - coeff_determination: 0.8285 - rmse: 1.3736 - val_loss: 0.1959 - val_coeff_determination: 0.8028 - val_rmse: 1.4546\n",
      "Epoch 71/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1691 - coeff_determination: 0.8298 - rmse: 1.3717 - val_loss: 0.1924 - val_coeff_determination: 0.8063 - val_rmse: 1.4430\n",
      "Epoch 72/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1687 - coeff_determination: 0.8295 - rmse: 1.3705 - val_loss: 0.1957 - val_coeff_determination: 0.8030 - val_rmse: 1.4516\n",
      "Epoch 73/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1698 - coeff_determination: 0.8292 - rmse: 1.3722 - val_loss: 0.1936 - val_coeff_determination: 0.8050 - val_rmse: 1.4466\n",
      "Epoch 74/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1666 - coeff_determination: 0.8318 - rmse: 1.3672 - val_loss: 0.1858 - val_coeff_determination: 0.8129 - val_rmse: 1.4256\n",
      "Epoch 75/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1681 - coeff_determination: 0.8308 - rmse: 1.3691 - val_loss: 0.1910 - val_coeff_determination: 0.8076 - val_rmse: 1.4395\n",
      "Epoch 76/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1661 - coeff_determination: 0.8328 - rmse: 1.3666 - val_loss: 0.1873 - val_coeff_determination: 0.8114 - val_rmse: 1.4293\n",
      "Epoch 77/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1660 - coeff_determination: 0.8323 - rmse: 1.3661 - val_loss: 0.1824 - val_coeff_determination: 0.8163 - val_rmse: 1.4164\n",
      "Epoch 78/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1685 - coeff_determination: 0.8299 - rmse: 1.3702 - val_loss: 0.1899 - val_coeff_determination: 0.8087 - val_rmse: 1.4381\n",
      "Epoch 79/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1659 - coeff_determination: 0.8329 - rmse: 1.3643 - val_loss: 0.1871 - val_coeff_determination: 0.8116 - val_rmse: 1.4301\n",
      "Epoch 80/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1671 - coeff_determination: 0.8311 - rmse: 1.3676 - val_loss: 0.1874 - val_coeff_determination: 0.8113 - val_rmse: 1.4311\n",
      "Epoch 81/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1663 - coeff_determination: 0.8325 - rmse: 1.3663 - val_loss: 0.1887 - val_coeff_determination: 0.8099 - val_rmse: 1.4338\n",
      "Epoch 82/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1652 - coeff_determination: 0.8333 - rmse: 1.3622 - val_loss: 0.1854 - val_coeff_determination: 0.8133 - val_rmse: 1.4240\n",
      "Epoch 83/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1650 - coeff_determination: 0.8335 - rmse: 1.3624 - val_loss: 0.1857 - val_coeff_determination: 0.8130 - val_rmse: 1.4254\n",
      "Epoch 84/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1645 - coeff_determination: 0.8337 - rmse: 1.3625 - val_loss: 0.1849 - val_coeff_determination: 0.8139 - val_rmse: 1.4233\n",
      "Epoch 85/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1641 - coeff_determination: 0.8345 - rmse: 1.3610 - val_loss: 0.1847 - val_coeff_determination: 0.8139 - val_rmse: 1.4221\n",
      "Epoch 86/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1645 - coeff_determination: 0.8341 - rmse: 1.3612 - val_loss: 0.1873 - val_coeff_determination: 0.8115 - val_rmse: 1.4308\n",
      "Epoch 87/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1659 - coeff_determination: 0.8323 - rmse: 1.3644 - val_loss: 0.1859 - val_coeff_determination: 0.8128 - val_rmse: 1.4242\n",
      "Epoch 88/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1632 - coeff_determination: 0.8352 - rmse: 1.3589 - val_loss: 0.1840 - val_coeff_determination: 0.8147 - val_rmse: 1.4191\n",
      "Epoch 89/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1634 - coeff_determination: 0.8354 - rmse: 1.3594 - val_loss: 0.1839 - val_coeff_determination: 0.8148 - val_rmse: 1.4206\n",
      "Epoch 90/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1646 - coeff_determination: 0.8337 - rmse: 1.3609 - val_loss: 0.1853 - val_coeff_determination: 0.8135 - val_rmse: 1.4249\n",
      "Epoch 91/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1628 - coeff_determination: 0.8358 - rmse: 1.3587 - val_loss: 0.1821 - val_coeff_determination: 0.8167 - val_rmse: 1.4151\n",
      "Epoch 92/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1631 - coeff_determination: 0.8355 - rmse: 1.3591 - val_loss: 0.1796 - val_coeff_determination: 0.8192 - val_rmse: 1.4074\n",
      "Epoch 93/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1634 - coeff_determination: 0.8349 - rmse: 1.3586 - val_loss: 0.1796 - val_coeff_determination: 0.8191 - val_rmse: 1.4080\n",
      "Epoch 94/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1635 - coeff_determination: 0.8348 - rmse: 1.3591 - val_loss: 0.1780 - val_coeff_determination: 0.8207 - val_rmse: 1.4023\n",
      "Epoch 95/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1626 - coeff_determination: 0.8355 - rmse: 1.3582 - val_loss: 0.1812 - val_coeff_determination: 0.8176 - val_rmse: 1.4135\n",
      "Epoch 96/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1627 - coeff_determination: 0.8358 - rmse: 1.3578 - val_loss: 0.1800 - val_coeff_determination: 0.8188 - val_rmse: 1.4129\n",
      "Epoch 97/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1631 - coeff_determination: 0.8353 - rmse: 1.3587 - val_loss: 0.1786 - val_coeff_determination: 0.8201 - val_rmse: 1.4048\n",
      "Epoch 98/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1632 - coeff_determination: 0.8353 - rmse: 1.3579 - val_loss: 0.1793 - val_coeff_determination: 0.8194 - val_rmse: 1.4048\n",
      "Epoch 99/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1614 - coeff_determination: 0.8368 - rmse: 1.3547 - val_loss: 0.1796 - val_coeff_determination: 0.8191 - val_rmse: 1.4072\n",
      "Epoch 100/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1624 - coeff_determination: 0.8356 - rmse: 1.3564 - val_loss: 0.1801 - val_coeff_determination: 0.8188 - val_rmse: 1.4125\n",
      "Epoch 101/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1612 - coeff_determination: 0.8375 - rmse: 1.3543 - val_loss: 0.1776 - val_coeff_determination: 0.8212 - val_rmse: 1.4003\n",
      "Epoch 102/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1632 - coeff_determination: 0.8355 - rmse: 1.3575 - val_loss: 0.1798 - val_coeff_determination: 0.8190 - val_rmse: 1.4067\n",
      "Epoch 103/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1614 - coeff_determination: 0.8370 - rmse: 1.3548 - val_loss: 0.1782 - val_coeff_determination: 0.8206 - val_rmse: 1.4017\n",
      "Epoch 104/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1607 - coeff_determination: 0.8378 - rmse: 1.3533 - val_loss: 0.1773 - val_coeff_determination: 0.8215 - val_rmse: 1.3970\n",
      "Epoch 105/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1597 - coeff_determination: 0.8386 - rmse: 1.3523 - val_loss: 0.1779 - val_coeff_determination: 0.8209 - val_rmse: 1.4023\n",
      "Epoch 106/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1607 - coeff_determination: 0.8378 - rmse: 1.3533 - val_loss: 0.1797 - val_coeff_determination: 0.8190 - val_rmse: 1.4067\n",
      "Epoch 107/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1596 - coeff_determination: 0.8389 - rmse: 1.3520 - val_loss: 0.1777 - val_coeff_determination: 0.8211 - val_rmse: 1.3983\n",
      "Epoch 108/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1610 - coeff_determination: 0.8377 - rmse: 1.3535 - val_loss: 0.1781 - val_coeff_determination: 0.8207 - val_rmse: 1.4028\n",
      "Epoch 109/550\n",
      "11759/11759 [==============================] - 1s 75us/step - loss: 0.1604 - coeff_determination: 0.8378 - rmse: 1.3518 - val_loss: 0.1802 - val_coeff_determination: 0.8186 - val_rmse: 1.4103\n",
      "Epoch 110/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1604 - coeff_determination: 0.8380 - rmse: 1.3528 - val_loss: 0.1776 - val_coeff_determination: 0.8211 - val_rmse: 1.3946\n",
      "Epoch 111/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1620 - coeff_determination: 0.8362 - rmse: 1.3552 - val_loss: 0.1782 - val_coeff_determination: 0.8206 - val_rmse: 1.3980\n",
      "Epoch 112/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1595 - coeff_determination: 0.8390 - rmse: 1.3505 - val_loss: 0.1779 - val_coeff_determination: 0.8209 - val_rmse: 1.4024\n",
      "Epoch 113/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1592 - coeff_determination: 0.8393 - rmse: 1.3499 - val_loss: 0.1777 - val_coeff_determination: 0.8211 - val_rmse: 1.3980\n",
      "Epoch 114/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1609 - coeff_determination: 0.8376 - rmse: 1.3532 - val_loss: 0.1772 - val_coeff_determination: 0.8215 - val_rmse: 1.3976\n",
      "Epoch 115/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1590 - coeff_determination: 0.8388 - rmse: 1.3496 - val_loss: 0.1758 - val_coeff_determination: 0.8230 - val_rmse: 1.3928\n",
      "Epoch 116/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1607 - coeff_determination: 0.8376 - rmse: 1.3533 - val_loss: 0.1766 - val_coeff_determination: 0.8222 - val_rmse: 1.3920\n",
      "Epoch 117/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1600 - coeff_determination: 0.8391 - rmse: 1.3512 - val_loss: 0.1784 - val_coeff_determination: 0.8203 - val_rmse: 1.3974\n",
      "Epoch 118/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1592 - coeff_determination: 0.8395 - rmse: 1.3496 - val_loss: 0.1758 - val_coeff_determination: 0.8229 - val_rmse: 1.3924\n",
      "Epoch 119/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1586 - coeff_determination: 0.8401 - rmse: 1.3485 - val_loss: 0.1762 - val_coeff_determination: 0.8226 - val_rmse: 1.3949\n",
      "Epoch 120/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1581 - coeff_determination: 0.8402 - rmse: 1.3486 - val_loss: 0.1772 - val_coeff_determination: 0.8215 - val_rmse: 1.3926\n",
      "Epoch 121/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1590 - coeff_determination: 0.8395 - rmse: 1.3497 - val_loss: 0.1770 - val_coeff_determination: 0.8218 - val_rmse: 1.3874\n",
      "Epoch 122/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1596 - coeff_determination: 0.8388 - rmse: 1.3511 - val_loss: 0.1739 - val_coeff_determination: 0.8248 - val_rmse: 1.3821\n",
      "Epoch 123/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1591 - coeff_determination: 0.8392 - rmse: 1.3494 - val_loss: 0.1773 - val_coeff_determination: 0.8214 - val_rmse: 1.3939\n",
      "Epoch 124/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1590 - coeff_determination: 0.8395 - rmse: 1.3486 - val_loss: 0.1755 - val_coeff_determination: 0.8232 - val_rmse: 1.3895\n",
      "Epoch 125/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1588 - coeff_determination: 0.8401 - rmse: 1.3488 - val_loss: 0.1740 - val_coeff_determination: 0.8248 - val_rmse: 1.3814\n",
      "Epoch 126/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1580 - coeff_determination: 0.8405 - rmse: 1.3465 - val_loss: 0.1757 - val_coeff_determination: 0.8231 - val_rmse: 1.3900\n",
      "Epoch 127/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1592 - coeff_determination: 0.8392 - rmse: 1.3495 - val_loss: 0.1747 - val_coeff_determination: 0.8241 - val_rmse: 1.3858\n",
      "Epoch 128/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1582 - coeff_determination: 0.8403 - rmse: 1.3475 - val_loss: 0.1747 - val_coeff_determination: 0.8241 - val_rmse: 1.3852\n",
      "Epoch 129/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1577 - coeff_determination: 0.8411 - rmse: 1.3467 - val_loss: 0.1738 - val_coeff_determination: 0.8250 - val_rmse: 1.3819\n",
      "Epoch 130/550\n",
      "11759/11759 [==============================] - 1s 74us/step - loss: 0.1591 - coeff_determination: 0.8393 - rmse: 1.3490 - val_loss: 0.1753 - val_coeff_determination: 0.8234 - val_rmse: 1.3879\n",
      "Epoch 131/550\n",
      "11759/11759 [==============================] - 1s 74us/step - loss: 0.1593 - coeff_determination: 0.8391 - rmse: 1.3490 - val_loss: 0.1758 - val_coeff_determination: 0.8230 - val_rmse: 1.3877\n",
      "Epoch 132/550\n",
      "11759/11759 [==============================] - 1s 74us/step - loss: 0.1583 - coeff_determination: 0.8406 - rmse: 1.3480 - val_loss: 0.1726 - val_coeff_determination: 0.8262 - val_rmse: 1.3772\n",
      "Epoch 133/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1585 - coeff_determination: 0.8398 - rmse: 1.3482 - val_loss: 0.1724 - val_coeff_determination: 0.8263 - val_rmse: 1.3803\n",
      "Epoch 134/550\n",
      "11759/11759 [==============================] - 1s 74us/step - loss: 0.1581 - coeff_determination: 0.8401 - rmse: 1.3476 - val_loss: 0.1744 - val_coeff_determination: 0.8243 - val_rmse: 1.3869\n",
      "Epoch 135/550\n",
      "11759/11759 [==============================] - 1s 74us/step - loss: 0.1578 - coeff_determination: 0.8407 - rmse: 1.3471 - val_loss: 0.1753 - val_coeff_determination: 0.8235 - val_rmse: 1.3919\n",
      "Epoch 136/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1581 - coeff_determination: 0.8405 - rmse: 1.3467 - val_loss: 0.1749 - val_coeff_determination: 0.8239 - val_rmse: 1.3861\n",
      "Epoch 137/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1573 - coeff_determination: 0.8419 - rmse: 1.3452 - val_loss: 0.1744 - val_coeff_determination: 0.8244 - val_rmse: 1.3865\n",
      "Epoch 138/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1585 - coeff_determination: 0.8404 - rmse: 1.3472 - val_loss: 0.1761 - val_coeff_determination: 0.8227 - val_rmse: 1.3922\n",
      "Epoch 139/550\n",
      "11759/11759 [==============================] - 1s 75us/step - loss: 0.1589 - coeff_determination: 0.8399 - rmse: 1.3495 - val_loss: 0.1746 - val_coeff_determination: 0.8242 - val_rmse: 1.3833\n",
      "Epoch 140/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1575 - coeff_determination: 0.8415 - rmse: 1.3457 - val_loss: 0.1746 - val_coeff_determination: 0.8242 - val_rmse: 1.3825\n",
      "Epoch 141/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1584 - coeff_determination: 0.8400 - rmse: 1.3480 - val_loss: 0.1742 - val_coeff_determination: 0.8246 - val_rmse: 1.3806\n",
      "Epoch 142/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1567 - coeff_determination: 0.8415 - rmse: 1.3443 - val_loss: 0.1737 - val_coeff_determination: 0.8250 - val_rmse: 1.3789\n",
      "Epoch 143/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1571 - coeff_determination: 0.8412 - rmse: 1.3442 - val_loss: 0.1753 - val_coeff_determination: 0.8235 - val_rmse: 1.3876\n",
      "Epoch 144/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1572 - coeff_determination: 0.8414 - rmse: 1.3443 - val_loss: 0.1740 - val_coeff_determination: 0.8248 - val_rmse: 1.3817\n",
      "Epoch 145/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1581 - coeff_determination: 0.8403 - rmse: 1.3467 - val_loss: 0.1745 - val_coeff_determination: 0.8243 - val_rmse: 1.3837\n",
      "Epoch 146/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1568 - coeff_determination: 0.8416 - rmse: 1.3444 - val_loss: 0.1731 - val_coeff_determination: 0.8257 - val_rmse: 1.3812\n",
      "Epoch 147/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1578 - coeff_determination: 0.8410 - rmse: 1.3463 - val_loss: 0.1742 - val_coeff_determination: 0.8245 - val_rmse: 1.3791\n",
      "Epoch 148/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1574 - coeff_determination: 0.8411 - rmse: 1.3451 - val_loss: 0.1728 - val_coeff_determination: 0.8259 - val_rmse: 1.3788\n",
      "Epoch 149/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1569 - coeff_determination: 0.8417 - rmse: 1.3449 - val_loss: 0.1748 - val_coeff_determination: 0.8240 - val_rmse: 1.3863\n",
      "Epoch 150/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1566 - coeff_determination: 0.8421 - rmse: 1.3435 - val_loss: 0.1745 - val_coeff_determination: 0.8242 - val_rmse: 1.3827\n",
      "Epoch 151/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1571 - coeff_determination: 0.8416 - rmse: 1.3453 - val_loss: 0.1748 - val_coeff_determination: 0.8240 - val_rmse: 1.3807\n",
      "Epoch 152/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1573 - coeff_determination: 0.8412 - rmse: 1.3448 - val_loss: 0.1725 - val_coeff_determination: 0.8262 - val_rmse: 1.3751\n",
      "Epoch 153/550\n",
      "11759/11759 [==============================] - 1s 76us/step - loss: 0.1577 - coeff_determination: 0.8410 - rmse: 1.3458 - val_loss: 0.1723 - val_coeff_determination: 0.8265 - val_rmse: 1.3771\n",
      "Epoch 154/550\n",
      "11759/11759 [==============================] - 1s 73us/step - loss: 0.1570 - coeff_determination: 0.8415 - rmse: 1.3443 - val_loss: 0.1717 - val_coeff_determination: 0.8271 - val_rmse: 1.3727\n",
      "Epoch 155/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1573 - coeff_determination: 0.8410 - rmse: 1.3450 - val_loss: 0.1756 - val_coeff_determination: 0.8232 - val_rmse: 1.3896\n",
      "Epoch 156/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1583 - coeff_determination: 0.8404 - rmse: 1.3475 - val_loss: 0.1737 - val_coeff_determination: 0.8251 - val_rmse: 1.3766\n",
      "Epoch 157/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1569 - coeff_determination: 0.8418 - rmse: 1.3442 - val_loss: 0.1738 - val_coeff_determination: 0.8249 - val_rmse: 1.3805\n",
      "Epoch 158/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1572 - coeff_determination: 0.8414 - rmse: 1.3440 - val_loss: 0.1749 - val_coeff_determination: 0.8239 - val_rmse: 1.3847\n",
      "Epoch 159/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1569 - coeff_determination: 0.8419 - rmse: 1.3445 - val_loss: 0.1746 - val_coeff_determination: 0.8241 - val_rmse: 1.3791\n",
      "Epoch 160/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1572 - coeff_determination: 0.8416 - rmse: 1.3450 - val_loss: 0.1744 - val_coeff_determination: 0.8243 - val_rmse: 1.3790\n",
      "Epoch 161/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1567 - coeff_determination: 0.8421 - rmse: 1.3434 - val_loss: 0.1733 - val_coeff_determination: 0.8254 - val_rmse: 1.3734\n",
      "Epoch 162/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1579 - coeff_determination: 0.8403 - rmse: 1.3455 - val_loss: 0.1732 - val_coeff_determination: 0.8255 - val_rmse: 1.3741\n",
      "Epoch 163/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1568 - coeff_determination: 0.8417 - rmse: 1.3438 - val_loss: 0.1738 - val_coeff_determination: 0.8249 - val_rmse: 1.3750\n",
      "Epoch 164/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1557 - coeff_determination: 0.8432 - rmse: 1.3428 - val_loss: 0.1744 - val_coeff_determination: 0.8243 - val_rmse: 1.3789\n",
      "Epoch 165/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1564 - coeff_determination: 0.8420 - rmse: 1.3431 - val_loss: 0.1735 - val_coeff_determination: 0.8253 - val_rmse: 1.3791\n",
      "Epoch 166/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1563 - coeff_determination: 0.8423 - rmse: 1.3427 - val_loss: 0.1741 - val_coeff_determination: 0.8247 - val_rmse: 1.3779\n",
      "Epoch 167/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1572 - coeff_determination: 0.8414 - rmse: 1.3446 - val_loss: 0.1751 - val_coeff_determination: 0.8236 - val_rmse: 1.3831\n",
      "Epoch 168/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1553 - coeff_determination: 0.8436 - rmse: 1.3414 - val_loss: 0.1734 - val_coeff_determination: 0.8253 - val_rmse: 1.3789\n",
      "Epoch 169/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1565 - coeff_determination: 0.8423 - rmse: 1.3430 - val_loss: 0.1757 - val_coeff_determination: 0.8230 - val_rmse: 1.3782\n",
      "Epoch 170/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1561 - coeff_determination: 0.8423 - rmse: 1.3422 - val_loss: 0.1749 - val_coeff_determination: 0.8238 - val_rmse: 1.3822\n",
      "Epoch 171/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1556 - coeff_determination: 0.8429 - rmse: 1.3422 - val_loss: 0.1736 - val_coeff_determination: 0.8252 - val_rmse: 1.3734\n",
      "Epoch 172/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1556 - coeff_determination: 0.8430 - rmse: 1.3419 - val_loss: 0.1740 - val_coeff_determination: 0.8248 - val_rmse: 1.3758\n",
      "Epoch 173/550\n",
      "11759/11759 [==============================] - 1s 72us/step - loss: 0.1554 - coeff_determination: 0.8430 - rmse: 1.3414 - val_loss: 0.1728 - val_coeff_determination: 0.8259 - val_rmse: 1.3696\n",
      "Epoch 174/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1555 - coeff_determination: 0.8431 - rmse: 1.3422 - val_loss: 0.1744 - val_coeff_determination: 0.8244 - val_rmse: 1.3737\n"
     ]
    }
   ],
   "source": [
    "model  = build_ANN2()\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')\n",
    "model,history = train_rnn_ann(model, x_train, y_train_log_std, x_val, y_val_log_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.exp(K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)))\n",
    "\n",
    "def coeff_determination_simple(y_true, y_pred):\n",
    "    SS_res =  np.sum(np.square( y_true - y_pred )) \n",
    "    SS_tot = np.sum(np.square( y_true - np.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=Adam(learning_rate=0.00015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68247447,  0.95044404, -0.21794449,  0.24006972,  1.48793652,\n",
       "       -0.28091159,  0.39879386,  1.19553429,  1.16573823, -0.53904325,\n",
       "       -0.94192961, -0.94192961,  0.54270737, -0.01181712, -0.94180167,\n",
       "       -0.91514247, -0.93945556, -0.87092274, -0.87092274, -0.33196525,\n",
       "       -0.94015335, -0.33196525, -0.88110212,  1.48791198, -0.99054621,\n",
       "        0.29797902,  2.30457163, -0.93348429, -0.94192961,  1.59477037,\n",
       "        1.25551032,  2.30457163,  0.69755857,  0.69755857])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train: Init time: 1585673327.173\n",
      "Train on 11467 samples, validate on 3823 samples\n",
      "Epoch 1/550\n",
      "11467/11467 [==============================] - 1s 113us/step - loss: 0.5099 - mae: 0.5633 - coeff_determination: 0.4871 - rmse: 1.9765 - val_loss: 0.3473 - val_mae: 0.3688 - val_coeff_determination: 0.6503 - val_rmse: 1.6919\n",
      "Epoch 2/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.3819 - mae: 0.4377 - coeff_determination: 0.6150 - rmse: 1.7654 - val_loss: 0.3273 - val_mae: 0.3215 - val_coeff_determination: 0.6707 - val_rmse: 1.6426\n",
      "Epoch 3/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.3493 - mae: 0.4069 - coeff_determination: 0.6495 - rmse: 1.7079 - val_loss: 0.3061 - val_mae: 0.3085 - val_coeff_determination: 0.6922 - val_rmse: 1.6064\n",
      "Epoch 4/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.3359 - mae: 0.3918 - coeff_determination: 0.6621 - rmse: 1.6859 - val_loss: 0.2956 - val_mae: 0.3174 - val_coeff_determination: 0.7028 - val_rmse: 1.5954\n",
      "Epoch 5/550\n",
      "11467/11467 [==============================] - 1s 73us/step - loss: 0.3217 - mae: 0.3752 - coeff_determination: 0.6754 - rmse: 1.6567 - val_loss: 0.3004 - val_mae: 0.3139 - val_coeff_determination: 0.6981 - val_rmse: 1.6115\n",
      "Epoch 6/550\n",
      "11467/11467 [==============================] - 1s 75us/step - loss: 0.3134 - mae: 0.3684 - coeff_determination: 0.6841 - rmse: 1.6423 - val_loss: 0.2988 - val_mae: 0.3236 - val_coeff_determination: 0.6996 - val_rmse: 1.6094\n",
      "Epoch 7/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.3062 - mae: 0.3623 - coeff_determination: 0.6927 - rmse: 1.6292 - val_loss: 0.2851 - val_mae: 0.3069 - val_coeff_determination: 0.7135 - val_rmse: 1.5804\n",
      "Epoch 8/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.3012 - mae: 0.3550 - coeff_determination: 0.6962 - rmse: 1.6198 - val_loss: 0.2861 - val_mae: 0.3425 - val_coeff_determination: 0.7124 - val_rmse: 1.5999\n",
      "Epoch 9/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2932 - mae: 0.3507 - coeff_determination: 0.7052 - rmse: 1.6078 - val_loss: 0.2782 - val_mae: 0.3185 - val_coeff_determination: 0.7204 - val_rmse: 1.5731\n",
      "Epoch 10/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2930 - mae: 0.3486 - coeff_determination: 0.7056 - rmse: 1.6050 - val_loss: 0.2783 - val_mae: 0.3128 - val_coeff_determination: 0.7204 - val_rmse: 1.5759\n",
      "Epoch 11/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2887 - mae: 0.3444 - coeff_determination: 0.7102 - rmse: 1.5974 - val_loss: 0.2749 - val_mae: 0.3355 - val_coeff_determination: 0.7236 - val_rmse: 1.5781\n",
      "Epoch 12/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2807 - mae: 0.3370 - coeff_determination: 0.7181 - rmse: 1.5823 - val_loss: 0.2702 - val_mae: 0.3180 - val_coeff_determination: 0.7284 - val_rmse: 1.5653\n",
      "Epoch 13/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2805 - mae: 0.3361 - coeff_determination: 0.7184 - rmse: 1.5828 - val_loss: 0.2709 - val_mae: 0.3420 - val_coeff_determination: 0.7277 - val_rmse: 1.5780\n",
      "Epoch 14/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2718 - mae: 0.3310 - coeff_determination: 0.7276 - rmse: 1.5685 - val_loss: 0.2651 - val_mae: 0.3236 - val_coeff_determination: 0.7336 - val_rmse: 1.5650\n",
      "Epoch 15/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.2688 - mae: 0.3262 - coeff_determination: 0.7301 - rmse: 1.5626 - val_loss: 0.2675 - val_mae: 0.3385 - val_coeff_determination: 0.7311 - val_rmse: 1.5728\n",
      "Epoch 16/550\n",
      "11467/11467 [==============================] - 1s 82us/step - loss: 0.2675 - mae: 0.3254 - coeff_determination: 0.7306 - rmse: 1.5590 - val_loss: 0.2662 - val_mae: 0.3106 - val_coeff_determination: 0.7326 - val_rmse: 1.5624\n",
      "Epoch 17/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2683 - mae: 0.3221 - coeff_determination: 0.7297 - rmse: 1.5600 - val_loss: 0.2659 - val_mae: 0.3318 - val_coeff_determination: 0.7328 - val_rmse: 1.5711\n",
      "Epoch 18/550\n",
      "11467/11467 [==============================] - 1s 74us/step - loss: 0.2625 - mae: 0.3202 - coeff_determination: 0.7364 - rmse: 1.5495 - val_loss: 0.2607 - val_mae: 0.3210 - val_coeff_determination: 0.7381 - val_rmse: 1.5559\n",
      "Epoch 19/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2612 - mae: 0.3184 - coeff_determination: 0.7382 - rmse: 1.5485 - val_loss: 0.2587 - val_mae: 0.3191 - val_coeff_determination: 0.7401 - val_rmse: 1.5553\n",
      "Epoch 20/550\n",
      "11467/11467 [==============================] - 1s 71us/step - loss: 0.2572 - mae: 0.3155 - coeff_determination: 0.7422 - rmse: 1.5403 - val_loss: 0.2597 - val_mae: 0.3384 - val_coeff_determination: 0.7390 - val_rmse: 1.5638\n",
      "Epoch 21/550\n",
      "11467/11467 [==============================] - 1s 71us/step - loss: 0.2537 - mae: 0.3120 - coeff_determination: 0.7444 - rmse: 1.5334 - val_loss: 0.2574 - val_mae: 0.3338 - val_coeff_determination: 0.7414 - val_rmse: 1.5610\n",
      "Epoch 22/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2527 - mae: 0.3113 - coeff_determination: 0.7458 - rmse: 1.5319 - val_loss: 0.2687 - val_mae: 0.3383 - val_coeff_determination: 0.7299 - val_rmse: 1.5781\n",
      "Epoch 23/550\n",
      "11467/11467 [==============================] - 1s 82us/step - loss: 0.2535 - mae: 0.3100 - coeff_determination: 0.7445 - rmse: 1.5318 - val_loss: 0.2602 - val_mae: 0.3307 - val_coeff_determination: 0.7386 - val_rmse: 1.5633\n",
      "Epoch 24/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.2506 - mae: 0.3060 - coeff_determination: 0.7469 - rmse: 1.5275 - val_loss: 0.2610 - val_mae: 0.3260 - val_coeff_determination: 0.7377 - val_rmse: 1.5640\n",
      "Epoch 25/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.2467 - mae: 0.3043 - coeff_determination: 0.7525 - rmse: 1.5220 - val_loss: 0.2558 - val_mae: 0.3356 - val_coeff_determination: 0.7430 - val_rmse: 1.5601\n",
      "Epoch 26/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.2500 - mae: 0.3043 - coeff_determination: 0.7486 - rmse: 1.5269 - val_loss: 0.2586 - val_mae: 0.3422 - val_coeff_determination: 0.7401 - val_rmse: 1.5691\n",
      "Epoch 27/550\n",
      "11467/11467 [==============================] - 1s 82us/step - loss: 0.2453 - mae: 0.3022 - coeff_determination: 0.7540 - rmse: 1.5185 - val_loss: 0.2542 - val_mae: 0.3278 - val_coeff_determination: 0.7445 - val_rmse: 1.5512\n",
      "Epoch 28/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2462 - mae: 0.2990 - coeff_determination: 0.7518 - rmse: 1.5174 - val_loss: 0.2627 - val_mae: 0.3436 - val_coeff_determination: 0.7360 - val_rmse: 1.5745\n",
      "Epoch 29/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.2411 - mae: 0.2964 - coeff_determination: 0.7577 - rmse: 1.5093 - val_loss: 0.2550 - val_mae: 0.3411 - val_coeff_determination: 0.7438 - val_rmse: 1.5621\n",
      "Epoch 30/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2391 - mae: 0.2951 - coeff_determination: 0.7598 - rmse: 1.5071 - val_loss: 0.2552 - val_mae: 0.3395 - val_coeff_determination: 0.7436 - val_rmse: 1.5611\n",
      "Epoch 31/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2388 - mae: 0.2956 - coeff_determination: 0.7606 - rmse: 1.5062 - val_loss: 0.2529 - val_mae: 0.3241 - val_coeff_determination: 0.7459 - val_rmse: 1.5482\n",
      "Epoch 32/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2379 - mae: 0.2942 - coeff_determination: 0.7612 - rmse: 1.5030 - val_loss: 0.2521 - val_mae: 0.3334 - val_coeff_determination: 0.7466 - val_rmse: 1.5533\n",
      "Epoch 33/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2389 - mae: 0.2948 - coeff_determination: 0.7608 - rmse: 1.5073 - val_loss: 0.2528 - val_mae: 0.3288 - val_coeff_determination: 0.7459 - val_rmse: 1.5511\n",
      "Epoch 34/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2367 - mae: 0.2913 - coeff_determination: 0.7617 - rmse: 1.5022 - val_loss: 0.2615 - val_mae: 0.3331 - val_coeff_determination: 0.7372 - val_rmse: 1.5652\n",
      "Epoch 35/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2360 - mae: 0.2911 - coeff_determination: 0.7634 - rmse: 1.5002 - val_loss: 0.2620 - val_mae: 0.3552 - val_coeff_determination: 0.7366 - val_rmse: 1.5785\n",
      "Epoch 36/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2349 - mae: 0.2913 - coeff_determination: 0.7656 - rmse: 1.4999 - val_loss: 0.2524 - val_mae: 0.3294 - val_coeff_determination: 0.7465 - val_rmse: 1.5527\n",
      "Epoch 37/550\n",
      "11467/11467 [==============================] - 1s 73us/step - loss: 0.2319 - mae: 0.2869 - coeff_determination: 0.7667 - rmse: 1.4920 - val_loss: 0.2525 - val_mae: 0.3244 - val_coeff_determination: 0.7464 - val_rmse: 1.5508\n",
      "Epoch 38/550\n",
      "11467/11467 [==============================] - 1s 73us/step - loss: 0.2320 - mae: 0.2843 - coeff_determination: 0.7670 - rmse: 1.4915 - val_loss: 0.2493 - val_mae: 0.3252 - val_coeff_determination: 0.7496 - val_rmse: 1.5479\n",
      "Epoch 39/550\n",
      "11467/11467 [==============================] - 1s 75us/step - loss: 0.2306 - mae: 0.2847 - coeff_determination: 0.7683 - rmse: 1.4905 - val_loss: 0.2612 - val_mae: 0.3367 - val_coeff_determination: 0.7375 - val_rmse: 1.5686\n",
      "Epoch 40/550\n",
      "11467/11467 [==============================] - 1s 74us/step - loss: 0.2289 - mae: 0.2823 - coeff_determination: 0.7695 - rmse: 1.4862 - val_loss: 0.2511 - val_mae: 0.3380 - val_coeff_determination: 0.7477 - val_rmse: 1.5549\n",
      "Epoch 41/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2306 - mae: 0.2840 - coeff_determination: 0.7689 - rmse: 1.4904 - val_loss: 0.2548 - val_mae: 0.3349 - val_coeff_determination: 0.7440 - val_rmse: 1.5586\n",
      "Epoch 42/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2284 - mae: 0.2808 - coeff_determination: 0.7706 - rmse: 1.4833 - val_loss: 0.2535 - val_mae: 0.3392 - val_coeff_determination: 0.7453 - val_rmse: 1.5593\n",
      "Epoch 43/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2269 - mae: 0.2801 - coeff_determination: 0.7723 - rmse: 1.4838 - val_loss: 0.2489 - val_mae: 0.3248 - val_coeff_determination: 0.7499 - val_rmse: 1.5443\n",
      "Epoch 44/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2270 - mae: 0.2810 - coeff_determination: 0.7725 - rmse: 1.4821 - val_loss: 0.2496 - val_mae: 0.3175 - val_coeff_determination: 0.7493 - val_rmse: 1.5453\n",
      "Epoch 45/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2254 - mae: 0.2780 - coeff_determination: 0.7732 - rmse: 1.4801 - val_loss: 0.2479 - val_mae: 0.3289 - val_coeff_determination: 0.7510 - val_rmse: 1.5464\n",
      "Epoch 46/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2263 - mae: 0.2788 - coeff_determination: 0.7735 - rmse: 1.4813 - val_loss: 0.2514 - val_mae: 0.3283 - val_coeff_determination: 0.7474 - val_rmse: 1.5500\n",
      "Epoch 47/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2226 - mae: 0.2759 - coeff_determination: 0.7757 - rmse: 1.4761 - val_loss: 0.2552 - val_mae: 0.3380 - val_coeff_determination: 0.7434 - val_rmse: 1.5596\n",
      "Epoch 48/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.2213 - mae: 0.2756 - coeff_determination: 0.7772 - rmse: 1.4724 - val_loss: 0.2459 - val_mae: 0.3269 - val_coeff_determination: 0.7529 - val_rmse: 1.5427\n",
      "Epoch 49/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2217 - mae: 0.2747 - coeff_determination: 0.7768 - rmse: 1.4727 - val_loss: 0.2463 - val_mae: 0.3164 - val_coeff_determination: 0.7527 - val_rmse: 1.5389\n",
      "Epoch 50/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.2226 - mae: 0.2730 - coeff_determination: 0.7759 - rmse: 1.4726 - val_loss: 0.2500 - val_mae: 0.3293 - val_coeff_determination: 0.7488 - val_rmse: 1.5499\n",
      "Epoch 51/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2204 - mae: 0.2725 - coeff_determination: 0.7773 - rmse: 1.4710 - val_loss: 0.2447 - val_mae: 0.3231 - val_coeff_determination: 0.7542 - val_rmse: 1.5400\n",
      "Epoch 52/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2206 - mae: 0.2719 - coeff_determination: 0.7786 - rmse: 1.4697 - val_loss: 0.2453 - val_mae: 0.3237 - val_coeff_determination: 0.7536 - val_rmse: 1.5418\n",
      "Epoch 53/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2212 - mae: 0.2726 - coeff_determination: 0.7772 - rmse: 1.4706 - val_loss: 0.2489 - val_mae: 0.3190 - val_coeff_determination: 0.7499 - val_rmse: 1.5418\n",
      "Epoch 54/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.2208 - mae: 0.2713 - coeff_determination: 0.7785 - rmse: 1.4706 - val_loss: 0.2456 - val_mae: 0.3188 - val_coeff_determination: 0.7531 - val_rmse: 1.5355\n",
      "Epoch 55/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2202 - mae: 0.2704 - coeff_determination: 0.7781 - rmse: 1.4679 - val_loss: 0.2447 - val_mae: 0.3241 - val_coeff_determination: 0.7541 - val_rmse: 1.5396\n",
      "Epoch 56/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2175 - mae: 0.2680 - coeff_determination: 0.7813 - rmse: 1.4641 - val_loss: 0.2444 - val_mae: 0.3255 - val_coeff_determination: 0.7545 - val_rmse: 1.5389\n",
      "Epoch 57/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2177 - mae: 0.2693 - coeff_determination: 0.7816 - rmse: 1.4644 - val_loss: 0.2465 - val_mae: 0.3165 - val_coeff_determination: 0.7523 - val_rmse: 1.5361\n",
      "Epoch 58/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2169 - mae: 0.2646 - coeff_determination: 0.7822 - rmse: 1.4623 - val_loss: 0.2507 - val_mae: 0.3423 - val_coeff_determination: 0.7481 - val_rmse: 1.5570\n",
      "Epoch 59/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2197 - mae: 0.2685 - coeff_determination: 0.7784 - rmse: 1.4670 - val_loss: 0.2486 - val_mae: 0.3229 - val_coeff_determination: 0.7503 - val_rmse: 1.5449\n",
      "Epoch 60/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.2177 - mae: 0.2672 - coeff_determination: 0.7819 - rmse: 1.4641 - val_loss: 0.2399 - val_mae: 0.3176 - val_coeff_determination: 0.7590 - val_rmse: 1.5300\n",
      "Epoch 61/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2143 - mae: 0.2650 - coeff_determination: 0.7844 - rmse: 1.4567 - val_loss: 0.2457 - val_mae: 0.3154 - val_coeff_determination: 0.7533 - val_rmse: 1.5396\n",
      "Epoch 62/550\n",
      "11467/11467 [==============================] - 1s 74us/step - loss: 0.2182 - mae: 0.2652 - coeff_determination: 0.7815 - rmse: 1.4640 - val_loss: 0.2488 - val_mae: 0.3275 - val_coeff_determination: 0.7499 - val_rmse: 1.5492\n",
      "Epoch 63/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2134 - mae: 0.2621 - coeff_determination: 0.7858 - rmse: 1.4548 - val_loss: 0.2426 - val_mae: 0.3218 - val_coeff_determination: 0.7564 - val_rmse: 1.5375\n",
      "Epoch 64/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2130 - mae: 0.2624 - coeff_determination: 0.7853 - rmse: 1.4550 - val_loss: 0.2464 - val_mae: 0.3316 - val_coeff_determination: 0.7524 - val_rmse: 1.5443\n",
      "Epoch 65/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2143 - mae: 0.2631 - coeff_determination: 0.7841 - rmse: 1.4578 - val_loss: 0.2334 - val_mae: 0.3002 - val_coeff_determination: 0.7656 - val_rmse: 1.5089\n",
      "Epoch 66/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2125 - mae: 0.2592 - coeff_determination: 0.7861 - rmse: 1.4516 - val_loss: 0.2477 - val_mae: 0.3327 - val_coeff_determination: 0.7510 - val_rmse: 1.5494\n",
      "Epoch 67/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2131 - mae: 0.2639 - coeff_determination: 0.7856 - rmse: 1.4559 - val_loss: 0.2332 - val_mae: 0.2968 - val_coeff_determination: 0.7657 - val_rmse: 1.5088\n",
      "Epoch 68/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.2131 - mae: 0.2606 - coeff_determination: 0.7846 - rmse: 1.4540 - val_loss: 0.2362 - val_mae: 0.3043 - val_coeff_determination: 0.7627 - val_rmse: 1.5163\n",
      "Epoch 69/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2116 - mae: 0.2596 - coeff_determination: 0.7858 - rmse: 1.4525 - val_loss: 0.2409 - val_mae: 0.3115 - val_coeff_determination: 0.7578 - val_rmse: 1.5262\n",
      "Epoch 70/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2123 - mae: 0.2592 - coeff_determination: 0.7866 - rmse: 1.4519 - val_loss: 0.2345 - val_mae: 0.3064 - val_coeff_determination: 0.7643 - val_rmse: 1.5180\n",
      "Epoch 71/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2115 - mae: 0.2598 - coeff_determination: 0.7871 - rmse: 1.4516 - val_loss: 0.2364 - val_mae: 0.3037 - val_coeff_determination: 0.7624 - val_rmse: 1.5182\n",
      "Epoch 72/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.2113 - mae: 0.2570 - coeff_determination: 0.7880 - rmse: 1.4508 - val_loss: 0.2364 - val_mae: 0.3090 - val_coeff_determination: 0.7625 - val_rmse: 1.5208\n",
      "Epoch 73/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2111 - mae: 0.2597 - coeff_determination: 0.7875 - rmse: 1.4496 - val_loss: 0.2358 - val_mae: 0.3092 - val_coeff_determination: 0.7630 - val_rmse: 1.5173\n",
      "Epoch 74/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2100 - mae: 0.2573 - coeff_determination: 0.7892 - rmse: 1.4478 - val_loss: 0.2397 - val_mae: 0.3118 - val_coeff_determination: 0.7591 - val_rmse: 1.5267\n",
      "Epoch 75/550\n",
      "11467/11467 [==============================] - 1s 71us/step - loss: 0.2086 - mae: 0.2561 - coeff_determination: 0.7900 - rmse: 1.4463 - val_loss: 0.2333 - val_mae: 0.3068 - val_coeff_determination: 0.7656 - val_rmse: 1.5142\n",
      "Epoch 76/550\n",
      "11467/11467 [==============================] - 1s 71us/step - loss: 0.2072 - mae: 0.2542 - coeff_determination: 0.7915 - rmse: 1.4424 - val_loss: 0.2446 - val_mae: 0.3202 - val_coeff_determination: 0.7541 - val_rmse: 1.5366\n",
      "Epoch 77/550\n",
      "11467/11467 [==============================] - 1s 74us/step - loss: 0.2101 - mae: 0.2573 - coeff_determination: 0.7896 - rmse: 1.4474 - val_loss: 0.2339 - val_mae: 0.3040 - val_coeff_determination: 0.7649 - val_rmse: 1.5129\n",
      "Epoch 78/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2090 - mae: 0.2559 - coeff_determination: 0.7897 - rmse: 1.4453 - val_loss: 0.2299 - val_mae: 0.2977 - val_coeff_determination: 0.7690 - val_rmse: 1.5062\n",
      "Epoch 79/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2060 - mae: 0.2532 - coeff_determination: 0.7930 - rmse: 1.4398 - val_loss: 0.2316 - val_mae: 0.3033 - val_coeff_determination: 0.7673 - val_rmse: 1.5130\n",
      "Epoch 80/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.2067 - mae: 0.2528 - coeff_determination: 0.7915 - rmse: 1.4401 - val_loss: 0.2348 - val_mae: 0.3082 - val_coeff_determination: 0.7641 - val_rmse: 1.5185\n",
      "Epoch 81/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2086 - mae: 0.2542 - coeff_determination: 0.7905 - rmse: 1.4437 - val_loss: 0.2344 - val_mae: 0.3117 - val_coeff_determination: 0.7645 - val_rmse: 1.5188\n",
      "Epoch 82/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2073 - mae: 0.2543 - coeff_determination: 0.7917 - rmse: 1.4422 - val_loss: 0.2320 - val_mae: 0.3001 - val_coeff_determination: 0.7669 - val_rmse: 1.5078\n",
      "Epoch 83/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2078 - mae: 0.2537 - coeff_determination: 0.7913 - rmse: 1.4432 - val_loss: 0.2314 - val_mae: 0.2993 - val_coeff_determination: 0.7674 - val_rmse: 1.5069\n",
      "Epoch 84/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2082 - mae: 0.2535 - coeff_determination: 0.7907 - rmse: 1.4422 - val_loss: 0.2239 - val_mae: 0.2852 - val_coeff_determination: 0.7751 - val_rmse: 1.4897\n",
      "Epoch 85/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2074 - mae: 0.2532 - coeff_determination: 0.7908 - rmse: 1.4423 - val_loss: 0.2293 - val_mae: 0.2934 - val_coeff_determination: 0.7696 - val_rmse: 1.5014\n",
      "Epoch 86/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2047 - mae: 0.2509 - coeff_determination: 0.7944 - rmse: 1.4372 - val_loss: 0.2331 - val_mae: 0.3019 - val_coeff_determination: 0.7658 - val_rmse: 1.5124\n",
      "Epoch 87/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2059 - mae: 0.2509 - coeff_determination: 0.7927 - rmse: 1.4394 - val_loss: 0.2280 - val_mae: 0.2959 - val_coeff_determination: 0.7710 - val_rmse: 1.5021\n",
      "Epoch 88/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.2043 - mae: 0.2503 - coeff_determination: 0.7954 - rmse: 1.4361 - val_loss: 0.2256 - val_mae: 0.2918 - val_coeff_determination: 0.7734 - val_rmse: 1.4977\n",
      "Epoch 89/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2036 - mae: 0.2486 - coeff_determination: 0.7953 - rmse: 1.4357 - val_loss: 0.2248 - val_mae: 0.2921 - val_coeff_determination: 0.7741 - val_rmse: 1.4957\n",
      "Epoch 90/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2016 - mae: 0.2492 - coeff_determination: 0.7977 - rmse: 1.4328 - val_loss: 0.2252 - val_mae: 0.2837 - val_coeff_determination: 0.7738 - val_rmse: 1.4911\n",
      "Epoch 91/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2042 - mae: 0.2512 - coeff_determination: 0.7943 - rmse: 1.4365 - val_loss: 0.2273 - val_mae: 0.2985 - val_coeff_determination: 0.7717 - val_rmse: 1.5050\n",
      "Epoch 92/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2007 - mae: 0.2478 - coeff_determination: 0.7986 - rmse: 1.4303 - val_loss: 0.2268 - val_mae: 0.2929 - val_coeff_determination: 0.7722 - val_rmse: 1.5001\n",
      "Epoch 93/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2021 - mae: 0.2464 - coeff_determination: 0.7965 - rmse: 1.4318 - val_loss: 0.2266 - val_mae: 0.2984 - val_coeff_determination: 0.7724 - val_rmse: 1.5040\n",
      "Epoch 94/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.2019 - mae: 0.2465 - coeff_determination: 0.7965 - rmse: 1.4304 - val_loss: 0.2271 - val_mae: 0.2953 - val_coeff_determination: 0.7719 - val_rmse: 1.5025\n",
      "Epoch 95/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.2027 - mae: 0.2497 - coeff_determination: 0.7952 - rmse: 1.4331 - val_loss: 0.2208 - val_mae: 0.2824 - val_coeff_determination: 0.7783 - val_rmse: 1.4850\n",
      "Epoch 96/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.2011 - mae: 0.2470 - coeff_determination: 0.7984 - rmse: 1.4301 - val_loss: 0.2225 - val_mae: 0.2752 - val_coeff_determination: 0.7765 - val_rmse: 1.4845\n",
      "Epoch 97/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1991 - mae: 0.2455 - coeff_determination: 0.8003 - rmse: 1.4271 - val_loss: 0.2206 - val_mae: 0.2809 - val_coeff_determination: 0.7785 - val_rmse: 1.4862\n",
      "Epoch 98/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1999 - mae: 0.2450 - coeff_determination: 0.7990 - rmse: 1.4279 - val_loss: 0.2218 - val_mae: 0.2943 - val_coeff_determination: 0.7771 - val_rmse: 1.4935\n",
      "Epoch 99/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1999 - mae: 0.2464 - coeff_determination: 0.7990 - rmse: 1.4287 - val_loss: 0.2187 - val_mae: 0.2768 - val_coeff_determination: 0.7803 - val_rmse: 1.4802\n",
      "Epoch 100/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1974 - mae: 0.2441 - coeff_determination: 0.8017 - rmse: 1.4243 - val_loss: 0.2140 - val_mae: 0.2653 - val_coeff_determination: 0.7851 - val_rmse: 1.4657\n",
      "Epoch 101/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1983 - mae: 0.2447 - coeff_determination: 0.7995 - rmse: 1.4249 - val_loss: 0.2216 - val_mae: 0.2829 - val_coeff_determination: 0.7773 - val_rmse: 1.4870\n",
      "Epoch 102/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1964 - mae: 0.2405 - coeff_determination: 0.8017 - rmse: 1.4227 - val_loss: 0.2210 - val_mae: 0.2918 - val_coeff_determination: 0.7779 - val_rmse: 1.4899\n",
      "Epoch 103/550\n",
      "11467/11467 [==============================] - 1s 83us/step - loss: 0.1966 - mae: 0.2437 - coeff_determination: 0.8020 - rmse: 1.4221 - val_loss: 0.2189 - val_mae: 0.2721 - val_coeff_determination: 0.7801 - val_rmse: 1.4765\n",
      "Epoch 104/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1942 - mae: 0.2408 - coeff_determination: 0.8044 - rmse: 1.4182 - val_loss: 0.2195 - val_mae: 0.2765 - val_coeff_determination: 0.7796 - val_rmse: 1.4806\n",
      "Epoch 105/550\n",
      "11467/11467 [==============================] - 1s 82us/step - loss: 0.1991 - mae: 0.2437 - coeff_determination: 0.7995 - rmse: 1.4258 - val_loss: 0.2155 - val_mae: 0.2688 - val_coeff_determination: 0.7836 - val_rmse: 1.4705\n",
      "Epoch 106/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.1951 - mae: 0.2420 - coeff_determination: 0.8043 - rmse: 1.4199 - val_loss: 0.2167 - val_mae: 0.2785 - val_coeff_determination: 0.7824 - val_rmse: 1.4771\n",
      "Epoch 107/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.1943 - mae: 0.2391 - coeff_determination: 0.8049 - rmse: 1.4173 - val_loss: 0.2174 - val_mae: 0.2806 - val_coeff_determination: 0.7816 - val_rmse: 1.4802\n",
      "Epoch 108/550\n",
      "11467/11467 [==============================] - 1s 81us/step - loss: 0.1956 - mae: 0.2427 - coeff_determination: 0.8030 - rmse: 1.4198 - val_loss: 0.2181 - val_mae: 0.2765 - val_coeff_determination: 0.7809 - val_rmse: 1.4779\n",
      "Epoch 109/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1952 - mae: 0.2402 - coeff_determination: 0.8029 - rmse: 1.4191 - val_loss: 0.2173 - val_mae: 0.2691 - val_coeff_determination: 0.7819 - val_rmse: 1.4733\n",
      "Epoch 110/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1957 - mae: 0.2410 - coeff_determination: 0.8030 - rmse: 1.4193 - val_loss: 0.2193 - val_mae: 0.2757 - val_coeff_determination: 0.7798 - val_rmse: 1.4792\n",
      "Epoch 111/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1944 - mae: 0.2386 - coeff_determination: 0.8053 - rmse: 1.4173 - val_loss: 0.2139 - val_mae: 0.2696 - val_coeff_determination: 0.7853 - val_rmse: 1.4690\n",
      "Epoch 112/550\n",
      "11467/11467 [==============================] - 1s 82us/step - loss: 0.1954 - mae: 0.2406 - coeff_determination: 0.8040 - rmse: 1.4196 - val_loss: 0.2186 - val_mae: 0.2699 - val_coeff_determination: 0.7803 - val_rmse: 1.4712\n",
      "Epoch 113/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1977 - mae: 0.2407 - coeff_determination: 0.8015 - rmse: 1.4222 - val_loss: 0.2151 - val_mae: 0.2806 - val_coeff_determination: 0.7839 - val_rmse: 1.4759\n",
      "Epoch 114/550\n",
      "11467/11467 [==============================] - 1s 75us/step - loss: 0.1943 - mae: 0.2399 - coeff_determination: 0.8035 - rmse: 1.4176 - val_loss: 0.2111 - val_mae: 0.2694 - val_coeff_determination: 0.7880 - val_rmse: 1.4635\n",
      "Epoch 115/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.1927 - mae: 0.2380 - coeff_determination: 0.8070 - rmse: 1.4145 - val_loss: 0.2137 - val_mae: 0.2645 - val_coeff_determination: 0.7853 - val_rmse: 1.4635\n",
      "Epoch 116/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1921 - mae: 0.2368 - coeff_determination: 0.8072 - rmse: 1.4132 - val_loss: 0.2133 - val_mae: 0.2729 - val_coeff_determination: 0.7857 - val_rmse: 1.4693\n",
      "Epoch 117/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1913 - mae: 0.2387 - coeff_determination: 0.8077 - rmse: 1.4131 - val_loss: 0.2103 - val_mae: 0.2647 - val_coeff_determination: 0.7888 - val_rmse: 1.4596\n",
      "Epoch 118/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1901 - mae: 0.2345 - coeff_determination: 0.8097 - rmse: 1.4090 - val_loss: 0.2098 - val_mae: 0.2685 - val_coeff_determination: 0.7893 - val_rmse: 1.4620\n",
      "Epoch 119/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1931 - mae: 0.2386 - coeff_determination: 0.8061 - rmse: 1.4154 - val_loss: 0.2121 - val_mae: 0.2712 - val_coeff_determination: 0.7869 - val_rmse: 1.4668\n",
      "Epoch 120/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1899 - mae: 0.2359 - coeff_determination: 0.8092 - rmse: 1.4102 - val_loss: 0.2207 - val_mae: 0.2649 - val_coeff_determination: 0.7783 - val_rmse: 1.4747\n",
      "Epoch 121/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1946 - mae: 0.2397 - coeff_determination: 0.8033 - rmse: 1.4173 - val_loss: 0.2121 - val_mae: 0.2675 - val_coeff_determination: 0.7870 - val_rmse: 1.4664\n",
      "Epoch 122/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1901 - mae: 0.2350 - coeff_determination: 0.8092 - rmse: 1.4092 - val_loss: 0.2113 - val_mae: 0.2691 - val_coeff_determination: 0.7876 - val_rmse: 1.4650\n",
      "Epoch 123/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1933 - mae: 0.2373 - coeff_determination: 0.8067 - rmse: 1.4148 - val_loss: 0.2116 - val_mae: 0.2595 - val_coeff_determination: 0.7875 - val_rmse: 1.4581\n",
      "Epoch 124/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.1897 - mae: 0.2359 - coeff_determination: 0.8091 - rmse: 1.4090 - val_loss: 0.2147 - val_mae: 0.2621 - val_coeff_determination: 0.7842 - val_rmse: 1.4629\n",
      "Epoch 125/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1896 - mae: 0.2344 - coeff_determination: 0.8103 - rmse: 1.4084 - val_loss: 0.2082 - val_mae: 0.2529 - val_coeff_determination: 0.7909 - val_rmse: 1.4507\n",
      "Epoch 126/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1898 - mae: 0.2341 - coeff_determination: 0.8081 - rmse: 1.4084 - val_loss: 0.2090 - val_mae: 0.2588 - val_coeff_determination: 0.7900 - val_rmse: 1.4553\n",
      "Epoch 127/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1911 - mae: 0.2362 - coeff_determination: 0.8077 - rmse: 1.4116 - val_loss: 0.2093 - val_mae: 0.2653 - val_coeff_determination: 0.7897 - val_rmse: 1.4608\n",
      "Epoch 128/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1886 - mae: 0.2341 - coeff_determination: 0.8109 - rmse: 1.4077 - val_loss: 0.2114 - val_mae: 0.2670 - val_coeff_determination: 0.7875 - val_rmse: 1.4634\n",
      "Epoch 129/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1892 - mae: 0.2342 - coeff_determination: 0.8105 - rmse: 1.4076 - val_loss: 0.2207 - val_mae: 0.2744 - val_coeff_determination: 0.7780 - val_rmse: 1.4779\n",
      "Epoch 130/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1899 - mae: 0.2356 - coeff_determination: 0.8096 - rmse: 1.4091 - val_loss: 0.2087 - val_mae: 0.2461 - val_coeff_determination: 0.7904 - val_rmse: 1.4457\n",
      "Epoch 131/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1889 - mae: 0.2326 - coeff_determination: 0.8101 - rmse: 1.4069 - val_loss: 0.2090 - val_mae: 0.2526 - val_coeff_determination: 0.7900 - val_rmse: 1.4512\n",
      "Epoch 132/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1880 - mae: 0.2327 - coeff_determination: 0.8104 - rmse: 1.4044 - val_loss: 0.2098 - val_mae: 0.2580 - val_coeff_determination: 0.7892 - val_rmse: 1.4549\n",
      "Epoch 133/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1880 - mae: 0.2321 - coeff_determination: 0.8121 - rmse: 1.4041 - val_loss: 0.2122 - val_mae: 0.2626 - val_coeff_determination: 0.7868 - val_rmse: 1.4617\n",
      "Epoch 134/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1883 - mae: 0.2345 - coeff_determination: 0.8108 - rmse: 1.4067 - val_loss: 0.2080 - val_mae: 0.2571 - val_coeff_determination: 0.7910 - val_rmse: 1.4530\n",
      "Epoch 135/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1914 - mae: 0.2354 - coeff_determination: 0.8070 - rmse: 1.4116 - val_loss: 0.2126 - val_mae: 0.2575 - val_coeff_determination: 0.7862 - val_rmse: 1.4553\n",
      "Epoch 136/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1892 - mae: 0.2332 - coeff_determination: 0.8090 - rmse: 1.4061 - val_loss: 0.2081 - val_mae: 0.2590 - val_coeff_determination: 0.7909 - val_rmse: 1.4535\n",
      "Epoch 137/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1895 - mae: 0.2337 - coeff_determination: 0.8088 - rmse: 1.4075 - val_loss: 0.2102 - val_mae: 0.2621 - val_coeff_determination: 0.7887 - val_rmse: 1.4594\n",
      "Epoch 138/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1892 - mae: 0.2347 - coeff_determination: 0.8095 - rmse: 1.4078 - val_loss: 0.2085 - val_mae: 0.2508 - val_coeff_determination: 0.7905 - val_rmse: 1.4486\n",
      "Epoch 139/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1866 - mae: 0.2312 - coeff_determination: 0.8117 - rmse: 1.4020 - val_loss: 0.2073 - val_mae: 0.2508 - val_coeff_determination: 0.7917 - val_rmse: 1.4487\n",
      "Epoch 140/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1892 - mae: 0.2338 - coeff_determination: 0.8102 - rmse: 1.4079 - val_loss: 0.2072 - val_mae: 0.2518 - val_coeff_determination: 0.7918 - val_rmse: 1.4469\n",
      "Epoch 141/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1868 - mae: 0.2311 - coeff_determination: 0.8127 - rmse: 1.4021 - val_loss: 0.2118 - val_mae: 0.2508 - val_coeff_determination: 0.7873 - val_rmse: 1.4524\n",
      "Epoch 142/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1870 - mae: 0.2322 - coeff_determination: 0.8117 - rmse: 1.4044 - val_loss: 0.2075 - val_mae: 0.2466 - val_coeff_determination: 0.7916 - val_rmse: 1.4447\n",
      "Epoch 143/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1887 - mae: 0.2328 - coeff_determination: 0.8101 - rmse: 1.4064 - val_loss: 0.2124 - val_mae: 0.2670 - val_coeff_determination: 0.7866 - val_rmse: 1.4643\n",
      "Epoch 144/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1890 - mae: 0.2327 - coeff_determination: 0.8106 - rmse: 1.4057 - val_loss: 0.2074 - val_mae: 0.2471 - val_coeff_determination: 0.7917 - val_rmse: 1.4447\n",
      "Epoch 145/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.1871 - mae: 0.2302 - coeff_determination: 0.8122 - rmse: 1.4024 - val_loss: 0.2106 - val_mae: 0.2622 - val_coeff_determination: 0.7882 - val_rmse: 1.4588\n",
      "Epoch 146/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1887 - mae: 0.2322 - coeff_determination: 0.8106 - rmse: 1.4058 - val_loss: 0.2074 - val_mae: 0.2602 - val_coeff_determination: 0.7917 - val_rmse: 1.4536\n",
      "Epoch 147/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1873 - mae: 0.2321 - coeff_determination: 0.8120 - rmse: 1.4040 - val_loss: 0.2063 - val_mae: 0.2532 - val_coeff_determination: 0.7927 - val_rmse: 1.4470\n",
      "Epoch 148/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1855 - mae: 0.2295 - coeff_determination: 0.8141 - rmse: 1.3990 - val_loss: 0.2097 - val_mae: 0.2574 - val_coeff_determination: 0.7894 - val_rmse: 1.4560\n",
      "Epoch 149/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1872 - mae: 0.2307 - coeff_determination: 0.8114 - rmse: 1.4033 - val_loss: 0.2101 - val_mae: 0.2548 - val_coeff_determination: 0.7889 - val_rmse: 1.4522\n",
      "Epoch 150/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1863 - mae: 0.2308 - coeff_determination: 0.8134 - rmse: 1.4010 - val_loss: 0.2105 - val_mae: 0.2548 - val_coeff_determination: 0.7884 - val_rmse: 1.4529\n",
      "Epoch 151/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1870 - mae: 0.2302 - coeff_determination: 0.8117 - rmse: 1.4029 - val_loss: 0.2085 - val_mae: 0.2597 - val_coeff_determination: 0.7905 - val_rmse: 1.4545\n",
      "Epoch 152/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1859 - mae: 0.2298 - coeff_determination: 0.8142 - rmse: 1.4008 - val_loss: 0.2065 - val_mae: 0.2504 - val_coeff_determination: 0.7925 - val_rmse: 1.4449\n",
      "Epoch 153/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1857 - mae: 0.2303 - coeff_determination: 0.8132 - rmse: 1.4005 - val_loss: 0.2066 - val_mae: 0.2462 - val_coeff_determination: 0.7925 - val_rmse: 1.4435\n",
      "Epoch 154/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1866 - mae: 0.2303 - coeff_determination: 0.8126 - rmse: 1.4017 - val_loss: 0.2077 - val_mae: 0.2551 - val_coeff_determination: 0.7913 - val_rmse: 1.4514\n",
      "Epoch 155/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1840 - mae: 0.2290 - coeff_determination: 0.8147 - rmse: 1.3975 - val_loss: 0.2066 - val_mae: 0.2499 - val_coeff_determination: 0.7925 - val_rmse: 1.4458\n",
      "Epoch 156/550\n",
      "11467/11467 [==============================] - 1s 82us/step - loss: 0.1862 - mae: 0.2296 - coeff_determination: 0.8132 - rmse: 1.4014 - val_loss: 0.2113 - val_mae: 0.2459 - val_coeff_determination: 0.7878 - val_rmse: 1.4488\n",
      "Epoch 157/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.1860 - mae: 0.2312 - coeff_determination: 0.8130 - rmse: 1.4006 - val_loss: 0.2085 - val_mae: 0.2467 - val_coeff_determination: 0.7905 - val_rmse: 1.4487\n",
      "Epoch 158/550\n",
      "11467/11467 [==============================] - 1s 75us/step - loss: 0.1858 - mae: 0.2279 - coeff_determination: 0.8138 - rmse: 1.3996 - val_loss: 0.2102 - val_mae: 0.2537 - val_coeff_determination: 0.7888 - val_rmse: 1.4521\n",
      "Epoch 159/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1848 - mae: 0.2290 - coeff_determination: 0.8143 - rmse: 1.3994 - val_loss: 0.2089 - val_mae: 0.2565 - val_coeff_determination: 0.7901 - val_rmse: 1.4530\n",
      "Epoch 160/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1852 - mae: 0.2281 - coeff_determination: 0.8136 - rmse: 1.3989 - val_loss: 0.2077 - val_mae: 0.2544 - val_coeff_determination: 0.7913 - val_rmse: 1.4505\n",
      "Epoch 161/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1852 - mae: 0.2300 - coeff_determination: 0.8140 - rmse: 1.4005 - val_loss: 0.2080 - val_mae: 0.2541 - val_coeff_determination: 0.7909 - val_rmse: 1.4496\n",
      "Epoch 162/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1848 - mae: 0.2280 - coeff_determination: 0.8134 - rmse: 1.3978 - val_loss: 0.2049 - val_mae: 0.2482 - val_coeff_determination: 0.7941 - val_rmse: 1.4415\n",
      "Epoch 163/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1835 - mae: 0.2297 - coeff_determination: 0.8160 - rmse: 1.3965 - val_loss: 0.2040 - val_mae: 0.2396 - val_coeff_determination: 0.7951 - val_rmse: 1.4348\n",
      "Epoch 164/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1846 - mae: 0.2275 - coeff_determination: 0.8144 - rmse: 1.3975 - val_loss: 0.2121 - val_mae: 0.2618 - val_coeff_determination: 0.7868 - val_rmse: 1.4610\n",
      "Epoch 165/550\n",
      "11467/11467 [==============================] - 1s 74us/step - loss: 0.1858 - mae: 0.2282 - coeff_determination: 0.8126 - rmse: 1.4004 - val_loss: 0.2082 - val_mae: 0.2597 - val_coeff_determination: 0.7907 - val_rmse: 1.4520\n",
      "Epoch 166/550\n",
      "11467/11467 [==============================] - 1s 75us/step - loss: 0.1835 - mae: 0.2286 - coeff_determination: 0.8156 - rmse: 1.3958 - val_loss: 0.2049 - val_mae: 0.2424 - val_coeff_determination: 0.7941 - val_rmse: 1.4393\n",
      "Epoch 167/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1834 - mae: 0.2269 - coeff_determination: 0.8166 - rmse: 1.3969 - val_loss: 0.2034 - val_mae: 0.2484 - val_coeff_determination: 0.7956 - val_rmse: 1.4401\n",
      "Epoch 168/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.1850 - mae: 0.2297 - coeff_determination: 0.8141 - rmse: 1.3989 - val_loss: 0.2059 - val_mae: 0.2403 - val_coeff_determination: 0.7932 - val_rmse: 1.4374\n",
      "Epoch 169/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1840 - mae: 0.2273 - coeff_determination: 0.8148 - rmse: 1.3962 - val_loss: 0.2065 - val_mae: 0.2552 - val_coeff_determination: 0.7925 - val_rmse: 1.4504\n",
      "Epoch 170/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1837 - mae: 0.2286 - coeff_determination: 0.8147 - rmse: 1.3967 - val_loss: 0.2060 - val_mae: 0.2450 - val_coeff_determination: 0.7929 - val_rmse: 1.4410\n",
      "Epoch 171/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1838 - mae: 0.2280 - coeff_determination: 0.8155 - rmse: 1.3972 - val_loss: 0.2066 - val_mae: 0.2379 - val_coeff_determination: 0.7923 - val_rmse: 1.4367\n",
      "Epoch 172/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1824 - mae: 0.2259 - coeff_determination: 0.8158 - rmse: 1.3932 - val_loss: 0.2084 - val_mae: 0.2496 - val_coeff_determination: 0.7905 - val_rmse: 1.4494\n",
      "Epoch 173/550\n",
      "11467/11467 [==============================] - 1s 79us/step - loss: 0.1844 - mae: 0.2277 - coeff_determination: 0.8146 - rmse: 1.3980 - val_loss: 0.2043 - val_mae: 0.2455 - val_coeff_determination: 0.7947 - val_rmse: 1.4395\n",
      "Epoch 174/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1832 - mae: 0.2273 - coeff_determination: 0.8163 - rmse: 1.3954 - val_loss: 0.2052 - val_mae: 0.2392 - val_coeff_determination: 0.7939 - val_rmse: 1.4369\n",
      "Epoch 175/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1853 - mae: 0.2282 - coeff_determination: 0.8137 - rmse: 1.3990 - val_loss: 0.2062 - val_mae: 0.2518 - val_coeff_determination: 0.7927 - val_rmse: 1.4460\n",
      "Epoch 176/550\n",
      "11467/11467 [==============================] - 1s 80us/step - loss: 0.1830 - mae: 0.2261 - coeff_determination: 0.8162 - rmse: 1.3944 - val_loss: 0.2056 - val_mae: 0.2480 - val_coeff_determination: 0.7934 - val_rmse: 1.4423\n",
      "Epoch 177/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1820 - mae: 0.2265 - coeff_determination: 0.8172 - rmse: 1.3937 - val_loss: 0.2070 - val_mae: 0.2464 - val_coeff_determination: 0.7919 - val_rmse: 1.4444\n",
      "Epoch 178/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1818 - mae: 0.2249 - coeff_determination: 0.8169 - rmse: 1.3926 - val_loss: 0.2108 - val_mae: 0.2510 - val_coeff_determination: 0.7882 - val_rmse: 1.4518\n",
      "Epoch 179/550\n",
      "11467/11467 [==============================] - 1s 75us/step - loss: 0.1844 - mae: 0.2277 - coeff_determination: 0.8146 - rmse: 1.3974 - val_loss: 0.2044 - val_mae: 0.2417 - val_coeff_determination: 0.7947 - val_rmse: 1.4373\n",
      "Epoch 180/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1817 - mae: 0.2256 - coeff_determination: 0.8168 - rmse: 1.3923 - val_loss: 0.2043 - val_mae: 0.2407 - val_coeff_determination: 0.7947 - val_rmse: 1.4367\n",
      "Epoch 181/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1832 - mae: 0.2274 - coeff_determination: 0.8171 - rmse: 1.3956 - val_loss: 0.2058 - val_mae: 0.2445 - val_coeff_determination: 0.7932 - val_rmse: 1.4412\n",
      "Epoch 182/550\n",
      "11467/11467 [==============================] - 1s 77us/step - loss: 0.1832 - mae: 0.2280 - coeff_determination: 0.8158 - rmse: 1.3966 - val_loss: 0.2050 - val_mae: 0.2385 - val_coeff_determination: 0.7939 - val_rmse: 1.4344\n",
      "Epoch 183/550\n",
      "11467/11467 [==============================] - 1s 76us/step - loss: 0.1832 - mae: 0.2256 - coeff_determination: 0.8160 - rmse: 1.3946 - val_loss: 0.2050 - val_mae: 0.2404 - val_coeff_determination: 0.7940 - val_rmse: 1.4368\n",
      "Epoch 184/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1825 - mae: 0.2262 - coeff_determination: 0.8161 - rmse: 1.3936 - val_loss: 0.2044 - val_mae: 0.2427 - val_coeff_determination: 0.7946 - val_rmse: 1.4377\n",
      "Epoch 185/550\n",
      "11467/11467 [==============================] - 1s 75us/step - loss: 0.1831 - mae: 0.2260 - coeff_determination: 0.8164 - rmse: 1.3946 - val_loss: 0.2047 - val_mae: 0.2448 - val_coeff_determination: 0.7943 - val_rmse: 1.4386\n",
      "Epoch 186/550\n",
      "11467/11467 [==============================] - 1s 75us/step - loss: 0.1824 - mae: 0.2269 - coeff_determination: 0.8161 - rmse: 1.3939 - val_loss: 0.2067 - val_mae: 0.2444 - val_coeff_determination: 0.7921 - val_rmse: 1.4415\n",
      "Epoch 187/550\n",
      "11467/11467 [==============================] - 1s 78us/step - loss: 0.1813 - mae: 0.2231 - coeff_determination: 0.8178 - rmse: 1.3915 - val_loss: 0.2050 - val_mae: 0.2449 - val_coeff_determination: 0.7939 - val_rmse: 1.4394\n",
      "after train, finish time: 1585673498.511\n",
      "training time {} 171.338\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 260)               9100      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 260)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 300)               78300     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 240)               72240     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 241       \n",
      "=================================================================\n",
      "Total params: 159,881\n",
      "Trainable params: 159,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model, history,tiempo = build_train_ann(\n",
    "    x_train, y_train_log_std,\n",
    "    x_val, y_val_log_std,\n",
    "    260, 300,240,\n",
    "    550, \n",
    "    optimizer, \n",
    "    dropout=0.25,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(model, scalery, [x_train_lstm_type, x_train_lstm_pred], y_train_log_std, label_set=\"Data\")\n",
    "get_metrics(model, scalery, x_val, y_val, label_set=\"Val\")\n",
    "get_metrics(model, scalery, x_test, y_test, label_set=\"Test\")\n",
    "plot_history(history,['loss','val_loss',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Data 835.7060958724019\n",
      "R2 SCORE Data 0.06347385367434932\n",
      "RMSE Data 2027.0931385751442\n",
      "R2 SCORE Data -5.0208666224777705\n",
      "RMSE Data 1081.5506042666377\n",
      "R2 SCORE Data -0.6641584335625148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1081.5506042666377, -0.6641584335625148)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(model, scalery,[x_train_lstm_type, x_train_lstm_pred, x_train],y_train, label_set=\"Data\")\n",
    "get_metrics(model, scalery,[x_val_lstm_type, x_val_lstm_pred, x_val],y_val, label_set=\"Data\")\n",
    "get_metrics(model, scalery,[x_test_lstm_type, x_test_lstm_pred, x_test],y_test, label_set=\"Data\")\n",
    "\n",
    "#     y_train_log_std, \n",
    "#     [x_val_lstm_type, x_val_lstm_pred, x_val], \n",
    "#     y_val_log_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history, ['loss','val_loss'], start_at_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([4.2415695], dtype=float32), array([4]))\n",
      "(array([3.7786784], dtype=float32), array([4]))\n",
      "(array([1653.0991], dtype=float32), array([2006]))\n",
      "(array([837.9956], dtype=float32), array([1549]))\n",
      "(array([1271.9069], dtype=float32), array([1150]))\n",
      "(array([4.1987686], dtype=float32), array([4]))\n",
      "(array([4.185467], dtype=float32), array([4]))\n",
      "(array([1462.4739], dtype=float32), array([2015]))\n",
      "(array([1653.0991], dtype=float32), array([2312]))\n",
      "(array([4.179089], dtype=float32), array([3]))\n",
      "(array([4.74822], dtype=float32), array([4]))\n",
      "(array([4.2415695], dtype=float32), array([4]))\n",
      "(array([4.436848], dtype=float32), array([4]))\n",
      "(array([4.7469635], dtype=float32), array([3]))\n",
      "(array([1271.9069], dtype=float32), array([1151]))\n",
      "(array([850.44354], dtype=float32), array([958]))\n",
      "(array([889.9751], dtype=float32), array([642]))\n",
      "(array([2.977099], dtype=float32), array([3]))\n",
      "(array([90.920105], dtype=float32), array([1008]))\n",
      "(array([3.7786784], dtype=float32), array([3]))\n",
      "(array([1271.9069], dtype=float32), array([1185]))\n",
      "(array([2.9125948], dtype=float32), array([3]))\n",
      "(array([11.644212], dtype=float32), array([2]))\n",
      "(array([407.4741], dtype=float32), array([221]))\n",
      "(array([850.44354], dtype=float32), array([960]))\n",
      "(array([1271.9069], dtype=float32), array([1289]))\n",
      "(array([1271.9069], dtype=float32), array([1437]))\n",
      "(array([2.977099], dtype=float32), array([3]))\n",
      "(array([850.44354], dtype=float32), array([804]))\n",
      "(array([4.1987686], dtype=float32), array([2]))\n",
      "(array([617.7846], dtype=float32), array([528]))\n",
      "(array([1271.9069], dtype=float32), array([2007]))\n",
      "(array([350.6899], dtype=float32), array([3]))\n",
      "(array([701.7294], dtype=float32), array([554]))\n",
      "(array([3.7786784], dtype=float32), array([4]))\n",
      "(array([617.7846], dtype=float32), array([674]))\n",
      "(array([4.2415695], dtype=float32), array([4]))\n",
      "(array([30.462729], dtype=float32), array([5]))\n",
      "(array([1271.9069], dtype=float32), array([1167]))\n",
      "(array([4.7469635], dtype=float32), array([3]))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.exp(scalery.inverse_transform(model.predict([x_test_lstm_type, x_test_lstm_pred, x_test]).reshape(-1, 1)))\n",
    "for a in list(zip(y_pred,y_test))[:40]:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fdf6088ecf8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train: Init time: 1585685971.573\n",
      "Train on 11759 samples, validate on 2520 samples\n",
      "Epoch 1/550\n",
      "11759/11759 [==============================] - 4s 365us/step - loss: 0.4935 - coeff_determination: 0.5020 - rmse: 1.9567 - val_loss: 0.3011 - val_coeff_determination: 0.6966 - val_rmse: 1.6066\n",
      "Epoch 2/550\n",
      "11759/11759 [==============================] - 3s 285us/step - loss: 0.3394 - coeff_determination: 0.6564 - rmse: 1.6845 - val_loss: 0.2440 - val_coeff_determination: 0.7543 - val_rmse: 1.4890\n",
      "Epoch 3/550\n",
      "11759/11759 [==============================] - 3s 284us/step - loss: 0.2648 - coeff_determination: 0.7323 - rmse: 1.5577 - val_loss: 0.2047 - val_coeff_determination: 0.7938 - val_rmse: 1.4420\n",
      "Epoch 4/550\n",
      "11759/11759 [==============================] - 3s 285us/step - loss: 0.2240 - coeff_determination: 0.7741 - rmse: 1.4920 - val_loss: 0.2014 - val_coeff_determination: 0.7970 - val_rmse: 1.4416\n",
      "Epoch 5/550\n",
      "11759/11759 [==============================] - 3s 284us/step - loss: 0.2066 - coeff_determination: 0.7915 - rmse: 1.4605 - val_loss: 0.1875 - val_coeff_determination: 0.8110 - val_rmse: 1.4070\n",
      "Epoch 6/550\n",
      "11759/11759 [==============================] - 3s 284us/step - loss: 0.1989 - coeff_determination: 0.7994 - rmse: 1.4437 - val_loss: 0.1870 - val_coeff_determination: 0.8116 - val_rmse: 1.4138\n",
      "Epoch 7/550\n",
      "11759/11759 [==============================] - 3s 279us/step - loss: 0.1897 - coeff_determination: 0.8086 - rmse: 1.4256 - val_loss: 0.1880 - val_coeff_determination: 0.8106 - val_rmse: 1.4120\n",
      "Epoch 8/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1845 - coeff_determination: 0.8137 - rmse: 1.4164 - val_loss: 0.1860 - val_coeff_determination: 0.8125 - val_rmse: 1.4072\n",
      "Epoch 9/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1815 - coeff_determination: 0.8172 - rmse: 1.4099 - val_loss: 0.1868 - val_coeff_determination: 0.8118 - val_rmse: 1.4123\n",
      "Epoch 10/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1799 - coeff_determination: 0.8188 - rmse: 1.4061 - val_loss: 0.1845 - val_coeff_determination: 0.8141 - val_rmse: 1.4050\n",
      "Epoch 11/550\n",
      "11759/11759 [==============================] - 3s 284us/step - loss: 0.1786 - coeff_determination: 0.8202 - rmse: 1.4024 - val_loss: 0.1860 - val_coeff_determination: 0.8126 - val_rmse: 1.4096\n",
      "Epoch 12/550\n",
      "11759/11759 [==============================] - 3s 286us/step - loss: 0.1749 - coeff_determination: 0.8236 - rmse: 1.3955 - val_loss: 0.1874 - val_coeff_determination: 0.8113 - val_rmse: 1.4134\n",
      "Epoch 13/550\n",
      "11759/11759 [==============================] - 3s 289us/step - loss: 0.1750 - coeff_determination: 0.8231 - rmse: 1.3953 - val_loss: 0.1852 - val_coeff_determination: 0.8133 - val_rmse: 1.4049\n",
      "Epoch 14/550\n",
      "11759/11759 [==============================] - 3s 293us/step - loss: 0.1712 - coeff_determination: 0.8274 - rmse: 1.3882 - val_loss: 0.1843 - val_coeff_determination: 0.8142 - val_rmse: 1.4046\n",
      "Epoch 15/550\n",
      "11759/11759 [==============================] - 3s 280us/step - loss: 0.1705 - coeff_determination: 0.8282 - rmse: 1.3858 - val_loss: 0.1856 - val_coeff_determination: 0.8130 - val_rmse: 1.4157\n",
      "Epoch 16/550\n",
      "11759/11759 [==============================] - 3s 284us/step - loss: 0.1684 - coeff_determination: 0.8307 - rmse: 1.3804 - val_loss: 0.1858 - val_coeff_determination: 0.8128 - val_rmse: 1.4168\n",
      "Epoch 17/550\n",
      "11759/11759 [==============================] - 3s 284us/step - loss: 0.1689 - coeff_determination: 0.8294 - rmse: 1.3819 - val_loss: 0.1841 - val_coeff_determination: 0.8146 - val_rmse: 1.4121\n",
      "Epoch 18/550\n",
      "11759/11759 [==============================] - 3s 290us/step - loss: 0.1669 - coeff_determination: 0.8316 - rmse: 1.3779 - val_loss: 0.1857 - val_coeff_determination: 0.8129 - val_rmse: 1.4185\n",
      "Epoch 19/550\n",
      "11759/11759 [==============================] - 3s 277us/step - loss: 0.1672 - coeff_determination: 0.8317 - rmse: 1.3781 - val_loss: 0.1827 - val_coeff_determination: 0.8160 - val_rmse: 1.4065\n",
      "Epoch 20/550\n",
      "11759/11759 [==============================] - 3s 284us/step - loss: 0.1648 - coeff_determination: 0.8333 - rmse: 1.3746 - val_loss: 0.1812 - val_coeff_determination: 0.8174 - val_rmse: 1.3979\n",
      "Epoch 21/550\n",
      "11759/11759 [==============================] - 3s 287us/step - loss: 0.1656 - coeff_determination: 0.8327 - rmse: 1.3755 - val_loss: 0.1805 - val_coeff_determination: 0.8182 - val_rmse: 1.4045\n",
      "Epoch 22/550\n",
      "11759/11759 [==============================] - 3s 290us/step - loss: 0.1651 - coeff_determination: 0.8337 - rmse: 1.3743 - val_loss: 0.1832 - val_coeff_determination: 0.8155 - val_rmse: 1.4110\n",
      "Epoch 23/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1637 - coeff_determination: 0.8352 - rmse: 1.3721 - val_loss: 0.1791 - val_coeff_determination: 0.8196 - val_rmse: 1.3951\n",
      "Epoch 24/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1626 - coeff_determination: 0.8364 - rmse: 1.3678 - val_loss: 0.1803 - val_coeff_determination: 0.8184 - val_rmse: 1.4032\n",
      "Epoch 25/550\n",
      "11759/11759 [==============================] - 3s 266us/step - loss: 0.1624 - coeff_determination: 0.8363 - rmse: 1.3688 - val_loss: 0.1823 - val_coeff_determination: 0.8164 - val_rmse: 1.4103\n",
      "Epoch 26/550\n",
      "11759/11759 [==============================] - 3s 275us/step - loss: 0.1616 - coeff_determination: 0.8365 - rmse: 1.3683 - val_loss: 0.1807 - val_coeff_determination: 0.8180 - val_rmse: 1.4056\n",
      "Epoch 27/550\n",
      "11759/11759 [==============================] - 3s 278us/step - loss: 0.1603 - coeff_determination: 0.8380 - rmse: 1.3639 - val_loss: 0.1837 - val_coeff_determination: 0.8151 - val_rmse: 1.4161\n",
      "Epoch 28/550\n",
      "11759/11759 [==============================] - 3s 277us/step - loss: 0.1612 - coeff_determination: 0.8380 - rmse: 1.3658 - val_loss: 0.1776 - val_coeff_determination: 0.8212 - val_rmse: 1.3922\n",
      "Epoch 29/550\n",
      "11759/11759 [==============================] - 3s 286us/step - loss: 0.1575 - coeff_determination: 0.8409 - rmse: 1.3586 - val_loss: 0.1786 - val_coeff_determination: 0.8201 - val_rmse: 1.3985\n",
      "Epoch 30/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1586 - coeff_determination: 0.8402 - rmse: 1.3597 - val_loss: 0.1818 - val_coeff_determination: 0.8170 - val_rmse: 1.4111\n",
      "Epoch 31/550\n",
      "11759/11759 [==============================] - 3s 279us/step - loss: 0.1574 - coeff_determination: 0.8418 - rmse: 1.3576 - val_loss: 0.1810 - val_coeff_determination: 0.8177 - val_rmse: 1.4102\n",
      "Epoch 32/550\n",
      "11759/11759 [==============================] - 3s 275us/step - loss: 0.1579 - coeff_determination: 0.8405 - rmse: 1.3578 - val_loss: 0.1825 - val_coeff_determination: 0.8162 - val_rmse: 1.4119\n",
      "Epoch 33/550\n",
      "11759/11759 [==============================] - 3s 285us/step - loss: 0.1576 - coeff_determination: 0.8410 - rmse: 1.3577 - val_loss: 0.1780 - val_coeff_determination: 0.8208 - val_rmse: 1.4003\n",
      "Epoch 34/550\n",
      "11759/11759 [==============================] - 3s 293us/step - loss: 0.1566 - coeff_determination: 0.8423 - rmse: 1.3572 - val_loss: 0.1833 - val_coeff_determination: 0.8154 - val_rmse: 1.4155\n",
      "Epoch 35/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1551 - coeff_determination: 0.8431 - rmse: 1.3529 - val_loss: 0.1822 - val_coeff_determination: 0.8166 - val_rmse: 1.4135\n",
      "Epoch 36/550\n",
      "11759/11759 [==============================] - 3s 280us/step - loss: 0.1550 - coeff_determination: 0.8441 - rmse: 1.3537 - val_loss: 0.1774 - val_coeff_determination: 0.8213 - val_rmse: 1.3982\n",
      "Epoch 37/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1563 - coeff_determination: 0.8426 - rmse: 1.3555 - val_loss: 0.1810 - val_coeff_determination: 0.8177 - val_rmse: 1.4101\n",
      "Epoch 38/550\n",
      "11759/11759 [==============================] - 3s 280us/step - loss: 0.1553 - coeff_determination: 0.8434 - rmse: 1.3533 - val_loss: 0.1773 - val_coeff_determination: 0.8215 - val_rmse: 1.3987\n",
      "Epoch 39/550\n",
      "11759/11759 [==============================] - 3s 277us/step - loss: 0.1547 - coeff_determination: 0.8439 - rmse: 1.3522 - val_loss: 0.1776 - val_coeff_determination: 0.8211 - val_rmse: 1.3973\n",
      "Epoch 40/550\n",
      "11759/11759 [==============================] - 3s 285us/step - loss: 0.1531 - coeff_determination: 0.8460 - rmse: 1.3505 - val_loss: 0.1763 - val_coeff_determination: 0.8225 - val_rmse: 1.3993\n",
      "Epoch 41/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1523 - coeff_determination: 0.8467 - rmse: 1.3472 - val_loss: 0.1807 - val_coeff_determination: 0.8181 - val_rmse: 1.4126\n",
      "Epoch 42/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1514 - coeff_determination: 0.8476 - rmse: 1.3462 - val_loss: 0.1781 - val_coeff_determination: 0.8207 - val_rmse: 1.4058\n",
      "Epoch 43/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1532 - coeff_determination: 0.8457 - rmse: 1.3486 - val_loss: 0.1743 - val_coeff_determination: 0.8244 - val_rmse: 1.3943\n",
      "Epoch 44/550\n",
      "11759/11759 [==============================] - 3s 274us/step - loss: 0.1520 - coeff_determination: 0.8466 - rmse: 1.3464 - val_loss: 0.1788 - val_coeff_determination: 0.8199 - val_rmse: 1.4040\n",
      "Epoch 45/550\n",
      "11759/11759 [==============================] - 3s 279us/step - loss: 0.1525 - coeff_determination: 0.8463 - rmse: 1.3479 - val_loss: 0.1776 - val_coeff_determination: 0.8211 - val_rmse: 1.4026\n",
      "Epoch 46/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1518 - coeff_determination: 0.8467 - rmse: 1.3455 - val_loss: 0.1788 - val_coeff_determination: 0.8199 - val_rmse: 1.4091\n",
      "Epoch 47/550\n",
      "11759/11759 [==============================] - 3s 288us/step - loss: 0.1514 - coeff_determination: 0.8470 - rmse: 1.3456 - val_loss: 0.1807 - val_coeff_determination: 0.8179 - val_rmse: 1.4112\n",
      "Epoch 48/550\n",
      "11759/11759 [==============================] - 3s 279us/step - loss: 0.1508 - coeff_determination: 0.8476 - rmse: 1.3438 - val_loss: 0.1776 - val_coeff_determination: 0.8211 - val_rmse: 1.4089\n",
      "Epoch 49/550\n",
      "11759/11759 [==============================] - 3s 270us/step - loss: 0.1508 - coeff_determination: 0.8481 - rmse: 1.3435 - val_loss: 0.1786 - val_coeff_determination: 0.8201 - val_rmse: 1.4092\n",
      "Epoch 50/550\n",
      "11759/11759 [==============================] - 3s 276us/step - loss: 0.1490 - coeff_determination: 0.8499 - rmse: 1.3406 - val_loss: 0.1771 - val_coeff_determination: 0.8216 - val_rmse: 1.4048\n",
      "Epoch 51/550\n",
      "11759/11759 [==============================] - 3s 276us/step - loss: 0.1481 - coeff_determination: 0.8508 - rmse: 1.3393 - val_loss: 0.1750 - val_coeff_determination: 0.8238 - val_rmse: 1.3988\n",
      "Epoch 52/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1485 - coeff_determination: 0.8501 - rmse: 1.3391 - val_loss: 0.1807 - val_coeff_determination: 0.8180 - val_rmse: 1.4157\n",
      "Epoch 53/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1482 - coeff_determination: 0.8505 - rmse: 1.3389 - val_loss: 0.1789 - val_coeff_determination: 0.8199 - val_rmse: 1.4107\n",
      "Epoch 54/550\n",
      "11759/11759 [==============================] - 3s 287us/step - loss: 0.1471 - coeff_determination: 0.8518 - rmse: 1.3375 - val_loss: 0.1751 - val_coeff_determination: 0.8237 - val_rmse: 1.3991\n",
      "Epoch 55/550\n",
      "11759/11759 [==============================] - 3s 290us/step - loss: 0.1485 - coeff_determination: 0.8506 - rmse: 1.3415 - val_loss: 0.1790 - val_coeff_determination: 0.8198 - val_rmse: 1.4118\n",
      "Epoch 56/550\n",
      "11759/11759 [==============================] - 3s 280us/step - loss: 0.1477 - coeff_determination: 0.8509 - rmse: 1.3380 - val_loss: 0.1762 - val_coeff_determination: 0.8225 - val_rmse: 1.4026\n",
      "Epoch 57/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1482 - coeff_determination: 0.8506 - rmse: 1.3389 - val_loss: 0.1759 - val_coeff_determination: 0.8229 - val_rmse: 1.4020\n",
      "Epoch 58/550\n",
      "11759/11759 [==============================] - 3s 277us/step - loss: 0.1480 - coeff_determination: 0.8509 - rmse: 1.3389 - val_loss: 0.1745 - val_coeff_determination: 0.8243 - val_rmse: 1.3989\n",
      "Epoch 59/550\n",
      "11759/11759 [==============================] - 3s 290us/step - loss: 0.1467 - coeff_determination: 0.8518 - rmse: 1.3358 - val_loss: 0.1768 - val_coeff_determination: 0.8220 - val_rmse: 1.4040\n",
      "Epoch 60/550\n",
      "11759/11759 [==============================] - 3s 285us/step - loss: 0.1464 - coeff_determination: 0.8525 - rmse: 1.3344 - val_loss: 0.1759 - val_coeff_determination: 0.8228 - val_rmse: 1.4032\n",
      "Epoch 61/550\n",
      "11759/11759 [==============================] - 3s 278us/step - loss: 0.1450 - coeff_determination: 0.8543 - rmse: 1.3336 - val_loss: 0.1727 - val_coeff_determination: 0.8260 - val_rmse: 1.3927\n",
      "Epoch 62/550\n",
      "11759/11759 [==============================] - 3s 279us/step - loss: 0.1470 - coeff_determination: 0.8518 - rmse: 1.3359 - val_loss: 0.1811 - val_coeff_determination: 0.8177 - val_rmse: 1.4157\n",
      "Epoch 63/550\n",
      "11759/11759 [==============================] - 3s 286us/step - loss: 0.1464 - coeff_determination: 0.8524 - rmse: 1.3351 - val_loss: 0.1803 - val_coeff_determination: 0.8184 - val_rmse: 1.4127\n",
      "Epoch 64/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1476 - coeff_determination: 0.8513 - rmse: 1.3369 - val_loss: 0.1719 - val_coeff_determination: 0.8269 - val_rmse: 1.3919\n",
      "Epoch 65/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1454 - coeff_determination: 0.8534 - rmse: 1.3334 - val_loss: 0.1771 - val_coeff_determination: 0.8216 - val_rmse: 1.3998\n",
      "Epoch 66/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1449 - coeff_determination: 0.8541 - rmse: 1.3313 - val_loss: 0.1803 - val_coeff_determination: 0.8185 - val_rmse: 1.4156\n",
      "Epoch 67/550\n",
      "11759/11759 [==============================] - 3s 279us/step - loss: 0.1450 - coeff_determination: 0.8536 - rmse: 1.3317 - val_loss: 0.1728 - val_coeff_determination: 0.8259 - val_rmse: 1.3940\n",
      "Epoch 68/550\n",
      "11759/11759 [==============================] - 3s 279us/step - loss: 0.1441 - coeff_determination: 0.8546 - rmse: 1.3305 - val_loss: 0.1816 - val_coeff_determination: 0.8172 - val_rmse: 1.4198\n",
      "Epoch 69/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1443 - coeff_determination: 0.8545 - rmse: 1.3302 - val_loss: 0.1749 - val_coeff_determination: 0.8238 - val_rmse: 1.3999\n",
      "Epoch 70/550\n",
      "11759/11759 [==============================] - 3s 276us/step - loss: 0.1440 - coeff_determination: 0.8549 - rmse: 1.3301 - val_loss: 0.1730 - val_coeff_determination: 0.8258 - val_rmse: 1.3965\n",
      "Epoch 71/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1434 - coeff_determination: 0.8552 - rmse: 1.3288 - val_loss: 0.1728 - val_coeff_determination: 0.8259 - val_rmse: 1.3922\n",
      "Epoch 72/550\n",
      "11759/11759 [==============================] - 3s 294us/step - loss: 0.1435 - coeff_determination: 0.8552 - rmse: 1.3281 - val_loss: 0.1736 - val_coeff_determination: 0.8252 - val_rmse: 1.3985\n",
      "Epoch 73/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1452 - coeff_determination: 0.8540 - rmse: 1.3322 - val_loss: 0.1759 - val_coeff_determination: 0.8228 - val_rmse: 1.4027\n",
      "Epoch 74/550\n",
      "11759/11759 [==============================] - 3s 284us/step - loss: 0.1430 - coeff_determination: 0.8556 - rmse: 1.3277 - val_loss: 0.1728 - val_coeff_determination: 0.8259 - val_rmse: 1.3961\n",
      "Epoch 75/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1430 - coeff_determination: 0.8560 - rmse: 1.3275 - val_loss: 0.1762 - val_coeff_determination: 0.8225 - val_rmse: 1.4043\n",
      "Epoch 76/550\n",
      "11759/11759 [==============================] - 3s 290us/step - loss: 0.1441 - coeff_determination: 0.8545 - rmse: 1.3304 - val_loss: 0.1710 - val_coeff_determination: 0.8277 - val_rmse: 1.3899\n",
      "Epoch 77/550\n",
      "11759/11759 [==============================] - 3s 286us/step - loss: 0.1421 - coeff_determination: 0.8571 - rmse: 1.3265 - val_loss: 0.1717 - val_coeff_determination: 0.8270 - val_rmse: 1.3911\n",
      "Epoch 78/550\n",
      "11759/11759 [==============================] - 3s 279us/step - loss: 0.1423 - coeff_determination: 0.8564 - rmse: 1.3261 - val_loss: 0.1727 - val_coeff_determination: 0.8260 - val_rmse: 1.3931\n",
      "Epoch 79/550\n",
      "11759/11759 [==============================] - 3s 277us/step - loss: 0.1420 - coeff_determination: 0.8565 - rmse: 1.3264 - val_loss: 0.1756 - val_coeff_determination: 0.8231 - val_rmse: 1.4012\n",
      "Epoch 80/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1425 - coeff_determination: 0.8561 - rmse: 1.3257 - val_loss: 0.1751 - val_coeff_determination: 0.8236 - val_rmse: 1.4024\n",
      "Epoch 81/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1416 - coeff_determination: 0.8574 - rmse: 1.3242 - val_loss: 0.1732 - val_coeff_determination: 0.8256 - val_rmse: 1.3979\n",
      "Epoch 82/550\n",
      "11759/11759 [==============================] - 3s 295us/step - loss: 0.1442 - coeff_determination: 0.8547 - rmse: 1.3294 - val_loss: 0.1760 - val_coeff_determination: 0.8227 - val_rmse: 1.4012\n",
      "Epoch 83/550\n",
      "11759/11759 [==============================] - 3s 287us/step - loss: 0.1430 - coeff_determination: 0.8558 - rmse: 1.3273 - val_loss: 0.1711 - val_coeff_determination: 0.8276 - val_rmse: 1.3901\n",
      "Epoch 84/550\n",
      "11759/11759 [==============================] - 3s 287us/step - loss: 0.1421 - coeff_determination: 0.8570 - rmse: 1.3256 - val_loss: 0.1682 - val_coeff_determination: 0.8305 - val_rmse: 1.3827\n",
      "Epoch 85/550\n",
      "11759/11759 [==============================] - 3s 286us/step - loss: 0.1414 - coeff_determination: 0.8572 - rmse: 1.3243 - val_loss: 0.1731 - val_coeff_determination: 0.8255 - val_rmse: 1.3930\n",
      "Epoch 86/550\n",
      "11759/11759 [==============================] - 3s 293us/step - loss: 0.1419 - coeff_determination: 0.8566 - rmse: 1.3243 - val_loss: 0.1700 - val_coeff_determination: 0.8288 - val_rmse: 1.3882\n",
      "Epoch 87/550\n",
      "11759/11759 [==============================] - 3s 295us/step - loss: 0.1417 - coeff_determination: 0.8573 - rmse: 1.3244 - val_loss: 0.1711 - val_coeff_determination: 0.8276 - val_rmse: 1.3876\n",
      "Epoch 88/550\n",
      "11759/11759 [==============================] - 3s 290us/step - loss: 0.1409 - coeff_determination: 0.8575 - rmse: 1.3235 - val_loss: 0.1746 - val_coeff_determination: 0.8241 - val_rmse: 1.3963\n",
      "Epoch 89/550\n",
      "11759/11759 [==============================] - 3s 285us/step - loss: 0.1418 - coeff_determination: 0.8562 - rmse: 1.3241 - val_loss: 0.1685 - val_coeff_determination: 0.8303 - val_rmse: 1.3829\n",
      "Epoch 90/550\n",
      "11759/11759 [==============================] - 3s 284us/step - loss: 0.1425 - coeff_determination: 0.8559 - rmse: 1.3280 - val_loss: 0.1715 - val_coeff_determination: 0.8272 - val_rmse: 1.3893\n",
      "Epoch 91/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1417 - coeff_determination: 0.8567 - rmse: 1.3242 - val_loss: 0.1747 - val_coeff_determination: 0.8241 - val_rmse: 1.4015\n",
      "Epoch 92/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1419 - coeff_determination: 0.8571 - rmse: 1.3240 - val_loss: 0.1721 - val_coeff_determination: 0.8266 - val_rmse: 1.3932\n",
      "Epoch 93/550\n",
      "11759/11759 [==============================] - 3s 279us/step - loss: 0.1413 - coeff_determination: 0.8576 - rmse: 1.3223 - val_loss: 0.1702 - val_coeff_determination: 0.8285 - val_rmse: 1.3884\n",
      "Epoch 94/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1417 - coeff_determination: 0.8572 - rmse: 1.3263 - val_loss: 0.1764 - val_coeff_determination: 0.8223 - val_rmse: 1.4055\n",
      "Epoch 95/550\n",
      "11759/11759 [==============================] - 3s 283us/step - loss: 0.1408 - coeff_determination: 0.8582 - rmse: 1.3230 - val_loss: 0.1697 - val_coeff_determination: 0.8291 - val_rmse: 1.3850\n",
      "Epoch 96/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1420 - coeff_determination: 0.8569 - rmse: 1.3238 - val_loss: 0.1737 - val_coeff_determination: 0.8251 - val_rmse: 1.3996\n",
      "Epoch 97/550\n",
      "11759/11759 [==============================] - 3s 281us/step - loss: 0.1414 - coeff_determination: 0.8574 - rmse: 1.3221 - val_loss: 0.1706 - val_coeff_determination: 0.8281 - val_rmse: 1.3889\n",
      "Epoch 98/550\n",
      "11759/11759 [==============================] - 3s 276us/step - loss: 0.1406 - coeff_determination: 0.8582 - rmse: 1.3205 - val_loss: 0.1747 - val_coeff_determination: 0.8239 - val_rmse: 1.3978\n",
      "Epoch 99/550\n",
      "11759/11759 [==============================] - 3s 278us/step - loss: 0.1407 - coeff_determination: 0.8580 - rmse: 1.3222 - val_loss: 0.1699 - val_coeff_determination: 0.8288 - val_rmse: 1.3817\n",
      "Epoch 100/550\n",
      "11759/11759 [==============================] - 3s 289us/step - loss: 0.1386 - coeff_determination: 0.8601 - rmse: 1.3180 - val_loss: 0.1719 - val_coeff_determination: 0.8268 - val_rmse: 1.3886\n",
      "Epoch 101/550\n",
      "11759/11759 [==============================] - 3s 288us/step - loss: 0.1414 - coeff_determination: 0.8568 - rmse: 1.3228 - val_loss: 0.1732 - val_coeff_determination: 0.8256 - val_rmse: 1.3997\n",
      "Epoch 102/550\n",
      "11759/11759 [==============================] - 3s 291us/step - loss: 0.1397 - coeff_determination: 0.8590 - rmse: 1.3195 - val_loss: 0.1687 - val_coeff_determination: 0.8301 - val_rmse: 1.3864\n",
      "Epoch 103/550\n",
      "11759/11759 [==============================] - 3s 291us/step - loss: 0.1398 - coeff_determination: 0.8586 - rmse: 1.3190 - val_loss: 0.1705 - val_coeff_determination: 0.8281 - val_rmse: 1.3861\n",
      "Epoch 104/550\n",
      "11759/11759 [==============================] - 3s 282us/step - loss: 0.1396 - coeff_determination: 0.8590 - rmse: 1.3186 - val_loss: 0.1701 - val_coeff_determination: 0.8287 - val_rmse: 1.3851\n"
     ]
    }
   ],
   "source": [
    "model2  = build_RNN3(\n",
    "    num_pred_words,\n",
    "    EMBEDDING_DIM_PRED,\n",
    "    EMBEDDING_DIM_TYPES,\n",
    "    emb_matrix_pred,\n",
    "    emb_matrix_types,\n",
    "    lstm_units=32,\n",
    "    lstm_types_units=5\n",
    "    )\n",
    "plot_model(model2, to_file='model2.png')\n",
    "model2,history = train_rnn_ann(\n",
    "    model2, \n",
    "    [x_train_lstm_pred, x_train],\n",
    "    y_train_log_std, \n",
    "    [x_val_lstm_pred, x_val], \n",
    "    y_val_log_std\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model2, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Data 653.479883602672\n",
      "R2 SCORE Data 0.4273658917905765\n",
      "RMSE Data 634.5793277802323\n",
      "R2 SCORE Data 0.4099573023010602\n",
      "RMSE Data 640.050921477401\n",
      "R2 SCORE Data 0.41718591893201296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(640.050921477401, 0.41718591893201296)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(model2, scalery,[x_train_lstm_pred, x_train],y_train, label_set=\"Data\")\n",
    "get_metrics(model2, scalery,[x_val_lstm_pred, x_val],y_val, label_set=\"Data\")\n",
    "get_metrics(model2, scalery,[x_test_lstm_pred, x_test],y_test, label_set=\"Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([5.1861644], dtype=float32), array([4]))\n",
      "(array([4.329108], dtype=float32), array([4]))\n",
      "(array([1368.4554], dtype=float32), array([2006]))\n",
      "(array([495.6614], dtype=float32), array([1549]))\n",
      "(array([1222.3663], dtype=float32), array([1150]))\n",
      "(array([2.9431815], dtype=float32), array([4]))\n",
      "(array([5.09594], dtype=float32), array([4]))\n",
      "(array([994.9835], dtype=float32), array([2015]))\n",
      "(array([1368.4554], dtype=float32), array([2312]))\n",
      "(array([6.186955], dtype=float32), array([3]))\n",
      "(array([5.752227], dtype=float32), array([4]))\n",
      "(array([5.1861644], dtype=float32), array([4]))\n",
      "(array([5.342058], dtype=float32), array([4]))\n",
      "(array([14.111796], dtype=float32), array([3]))\n",
      "(array([1222.3663], dtype=float32), array([1151]))\n",
      "(array([748.4635], dtype=float32), array([958]))\n",
      "(array([860.3194], dtype=float32), array([642]))\n",
      "(array([2.6324553], dtype=float32), array([3]))\n",
      "(array([47.396603], dtype=float32), array([1008]))\n",
      "(array([4.329108], dtype=float32), array([3]))\n",
      "(array([1222.3663], dtype=float32), array([1185]))\n",
      "(array([3.1761975], dtype=float32), array([3]))\n",
      "(array([14.777179], dtype=float32), array([2]))\n",
      "(array([72.02802], dtype=float32), array([221]))\n",
      "(array([748.4635], dtype=float32), array([960]))\n",
      "(array([1222.3663], dtype=float32), array([1289]))\n",
      "(array([1222.3663], dtype=float32), array([1437]))\n",
      "(array([2.6324553], dtype=float32), array([3]))\n",
      "(array([748.4635], dtype=float32), array([804]))\n",
      "(array([2.9431815], dtype=float32), array([2]))\n",
      "(array([662.624], dtype=float32), array([528]))\n",
      "(array([1222.3663], dtype=float32), array([2007]))\n",
      "(array([356.51], dtype=float32), array([3]))\n",
      "(array([521.31915], dtype=float32), array([554]))\n",
      "(array([4.329108], dtype=float32), array([4]))\n",
      "(array([662.624], dtype=float32), array([674]))\n",
      "(array([5.1861644], dtype=float32), array([4]))\n",
      "(array([17.858484], dtype=float32), array([5]))\n",
      "(array([1222.3663], dtype=float32), array([1167]))\n",
      "(array([14.111796], dtype=float32), array([3]))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.exp(scalery.inverse_transform(model2.predict([x_test_lstm_pred, x_test]).reshape(-1, 1)))\n",
    "for a in list(zip(y_pred,y_test))[:40]:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "def build_train_denseextended(x_train, y_train, x_val, y_val, n1, n2, n3, epochs, optimizer, dropout, verbose=False):\n",
    "    \n",
    "    callbacks_best = [EarlyStopping(monitor='val_loss', patience=20),\n",
    "                      ModelCheckpoint(filepath='models_newdata/bestm_newdata.h5'.format(n1,n2,n3),\n",
    "                                      monitor='val_loss', save_best_only=True\n",
    "                                     )]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n1, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n2, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n3, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae', coeff_determination, rmse])\n",
    "    t0=time()\n",
    "    print(\"before train: Init time: {}\".format(round(t0,3)))\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=120,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=callbacks_best,\n",
    "                    verbose=verbose\n",
    "                     )\n",
    "    t1=time()\n",
    "    print(\"after train, finish time: {}\".format(round(t1,3)))\n",
    "    print(\"training time {}\",format(round(t1-t0, 3)))\n",
    "    print(model.summary())\n",
    "\n",
    "    return model, history, round(t1-t0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train: Init time: 1585693910.071\n",
      "Train on 11759 samples, validate on 2520 samples\n",
      "Epoch 1/550\n",
      "11759/11759 [==============================] - 1s 92us/step - loss: 0.8236 - mae: 0.8683 - coeff_determination: 0.1704 - rmse: 2.4634 - val_loss: 0.6377 - val_mae: 0.7376 - val_coeff_determination: 0.3584 - val_rmse: 2.1902\n",
      "Epoch 2/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.6380 - mae: 0.7230 - coeff_determination: 0.3579 - rmse: 2.1818 - val_loss: 0.5291 - val_mae: 0.6187 - val_coeff_determination: 0.4674 - val_rmse: 2.0039\n",
      "Epoch 3/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.5649 - mae: 0.6540 - coeff_determination: 0.4300 - rmse: 2.0647 - val_loss: 0.4844 - val_mae: 0.5677 - val_coeff_determination: 0.5123 - val_rmse: 1.9275\n",
      "Epoch 4/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.5266 - mae: 0.6165 - coeff_determination: 0.4681 - rmse: 2.0032 - val_loss: 0.4545 - val_mae: 0.5334 - val_coeff_determination: 0.5423 - val_rmse: 1.8747\n",
      "Epoch 5/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.4978 - mae: 0.5887 - coeff_determination: 0.4977 - rmse: 1.9560 - val_loss: 0.4307 - val_mae: 0.5078 - val_coeff_determination: 0.5663 - val_rmse: 1.8322\n",
      "Epoch 6/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.4746 - mae: 0.5660 - coeff_determination: 0.5215 - rmse: 1.9169 - val_loss: 0.4114 - val_mae: 0.4846 - val_coeff_determination: 0.5858 - val_rmse: 1.7958\n",
      "Epoch 7/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.4579 - mae: 0.5488 - coeff_determination: 0.5381 - rmse: 1.8885 - val_loss: 0.3951 - val_mae: 0.4660 - val_coeff_determination: 0.6021 - val_rmse: 1.7662\n",
      "Epoch 8/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.4426 - mae: 0.5331 - coeff_determination: 0.5535 - rmse: 1.8633 - val_loss: 0.3812 - val_mae: 0.4531 - val_coeff_determination: 0.6161 - val_rmse: 1.7442\n",
      "Epoch 9/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.4285 - mae: 0.5208 - coeff_determination: 0.5675 - rmse: 1.8418 - val_loss: 0.3683 - val_mae: 0.4428 - val_coeff_determination: 0.6291 - val_rmse: 1.7252\n",
      "Epoch 10/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.4180 - mae: 0.5100 - coeff_determination: 0.5778 - rmse: 1.8242 - val_loss: 0.3576 - val_mae: 0.4298 - val_coeff_determination: 0.6399 - val_rmse: 1.7075\n",
      "Epoch 11/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.4060 - mae: 0.4966 - coeff_determination: 0.5901 - rmse: 1.8027 - val_loss: 0.3469 - val_mae: 0.4192 - val_coeff_determination: 0.6506 - val_rmse: 1.6899\n",
      "Epoch 12/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.3931 - mae: 0.4857 - coeff_determination: 0.6043 - rmse: 1.7824 - val_loss: 0.3377 - val_mae: 0.4089 - val_coeff_determination: 0.6598 - val_rmse: 1.6745\n",
      "Epoch 13/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.3891 - mae: 0.4781 - coeff_determination: 0.6062 - rmse: 1.7741 - val_loss: 0.3289 - val_mae: 0.3983 - val_coeff_determination: 0.6687 - val_rmse: 1.6584\n",
      "Epoch 14/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.3807 - mae: 0.4703 - coeff_determination: 0.6152 - rmse: 1.7614 - val_loss: 0.3218 - val_mae: 0.3885 - val_coeff_determination: 0.6759 - val_rmse: 1.6451\n",
      "Epoch 15/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.3705 - mae: 0.4608 - coeff_determination: 0.6256 - rmse: 1.7437 - val_loss: 0.3142 - val_mae: 0.3793 - val_coeff_determination: 0.6835 - val_rmse: 1.6307\n",
      "Epoch 16/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.3625 - mae: 0.4533 - coeff_determination: 0.6333 - rmse: 1.7298 - val_loss: 0.3077 - val_mae: 0.3701 - val_coeff_determination: 0.6901 - val_rmse: 1.6174\n",
      "Epoch 17/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.3560 - mae: 0.4447 - coeff_determination: 0.6402 - rmse: 1.7180 - val_loss: 0.3011 - val_mae: 0.3625 - val_coeff_determination: 0.6967 - val_rmse: 1.6048\n",
      "Epoch 18/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.3498 - mae: 0.4381 - coeff_determination: 0.6468 - rmse: 1.7072 - val_loss: 0.2944 - val_mae: 0.3565 - val_coeff_determination: 0.7034 - val_rmse: 1.5923\n",
      "Epoch 19/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.3456 - mae: 0.4344 - coeff_determination: 0.6519 - rmse: 1.6995 - val_loss: 0.2908 - val_mae: 0.3485 - val_coeff_determination: 0.7070 - val_rmse: 1.5841\n",
      "Epoch 20/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.3427 - mae: 0.4272 - coeff_determination: 0.6538 - rmse: 1.6927 - val_loss: 0.2850 - val_mae: 0.3428 - val_coeff_determination: 0.7129 - val_rmse: 1.5726\n",
      "Epoch 21/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.3382 - mae: 0.4252 - coeff_determination: 0.6588 - rmse: 1.6852 - val_loss: 0.2810 - val_mae: 0.3381 - val_coeff_determination: 0.7169 - val_rmse: 1.5648\n",
      "Epoch 22/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.3315 - mae: 0.4183 - coeff_determination: 0.6660 - rmse: 1.6751 - val_loss: 0.2778 - val_mae: 0.3324 - val_coeff_determination: 0.7201 - val_rmse: 1.5579\n",
      "Epoch 23/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.3301 - mae: 0.4142 - coeff_determination: 0.6667 - rmse: 1.6707 - val_loss: 0.2746 - val_mae: 0.3277 - val_coeff_determination: 0.7233 - val_rmse: 1.5512\n",
      "Epoch 24/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.3274 - mae: 0.4124 - coeff_determination: 0.6698 - rmse: 1.6668 - val_loss: 0.2708 - val_mae: 0.3239 - val_coeff_determination: 0.7271 - val_rmse: 1.5442\n",
      "Epoch 25/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.3225 - mae: 0.4065 - coeff_determination: 0.6752 - rmse: 1.6561 - val_loss: 0.2686 - val_mae: 0.3207 - val_coeff_determination: 0.7293 - val_rmse: 1.5400\n",
      "Epoch 26/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.3168 - mae: 0.4018 - coeff_determination: 0.6811 - rmse: 1.6474 - val_loss: 0.2658 - val_mae: 0.3180 - val_coeff_determination: 0.7322 - val_rmse: 1.5349\n",
      "Epoch 27/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.3164 - mae: 0.3997 - coeff_determination: 0.6806 - rmse: 1.6460 - val_loss: 0.2632 - val_mae: 0.3141 - val_coeff_determination: 0.7348 - val_rmse: 1.5292\n",
      "Epoch 28/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.3160 - mae: 0.4004 - coeff_determination: 0.6804 - rmse: 1.6462 - val_loss: 0.2610 - val_mae: 0.3126 - val_coeff_determination: 0.7370 - val_rmse: 1.5256\n",
      "Epoch 29/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.3120 - mae: 0.3946 - coeff_determination: 0.6850 - rmse: 1.6384 - val_loss: 0.2591 - val_mae: 0.3103 - val_coeff_determination: 0.7390 - val_rmse: 1.5218\n",
      "Epoch 30/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.3061 - mae: 0.3922 - coeff_determination: 0.6916 - rmse: 1.6291 - val_loss: 0.2577 - val_mae: 0.3077 - val_coeff_determination: 0.7403 - val_rmse: 1.5190\n",
      "Epoch 31/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.3072 - mae: 0.3907 - coeff_determination: 0.6909 - rmse: 1.6301 - val_loss: 0.2557 - val_mae: 0.3049 - val_coeff_determination: 0.7424 - val_rmse: 1.5146\n",
      "Epoch 32/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.3048 - mae: 0.3876 - coeff_determination: 0.6926 - rmse: 1.6250 - val_loss: 0.2545 - val_mae: 0.3020 - val_coeff_determination: 0.7435 - val_rmse: 1.5117\n",
      "Epoch 33/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.3012 - mae: 0.3843 - coeff_determination: 0.6966 - rmse: 1.6195 - val_loss: 0.2509 - val_mae: 0.3024 - val_coeff_determination: 0.7472 - val_rmse: 1.5066\n",
      "Epoch 34/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.3002 - mae: 0.3843 - coeff_determination: 0.6971 - rmse: 1.6185 - val_loss: 0.2510 - val_mae: 0.2994 - val_coeff_determination: 0.7470 - val_rmse: 1.5059\n",
      "Epoch 35/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2949 - mae: 0.3799 - coeff_determination: 0.7025 - rmse: 1.6085 - val_loss: 0.2484 - val_mae: 0.2986 - val_coeff_determination: 0.7497 - val_rmse: 1.5017\n",
      "Epoch 36/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2934 - mae: 0.3798 - coeff_determination: 0.7026 - rmse: 1.6080 - val_loss: 0.2479 - val_mae: 0.2962 - val_coeff_determination: 0.7502 - val_rmse: 1.5003\n",
      "Epoch 37/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2932 - mae: 0.3759 - coeff_determination: 0.7042 - rmse: 1.6050 - val_loss: 0.2449 - val_mae: 0.2968 - val_coeff_determination: 0.7532 - val_rmse: 1.4963\n",
      "Epoch 38/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2942 - mae: 0.3779 - coeff_determination: 0.7034 - rmse: 1.6076 - val_loss: 0.2440 - val_mae: 0.2954 - val_coeff_determination: 0.7541 - val_rmse: 1.4947\n",
      "Epoch 39/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2895 - mae: 0.3757 - coeff_determination: 0.7079 - rmse: 1.6007 - val_loss: 0.2445 - val_mae: 0.2924 - val_coeff_determination: 0.7536 - val_rmse: 1.4944\n",
      "Epoch 40/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2884 - mae: 0.3718 - coeff_determination: 0.7091 - rmse: 1.5970 - val_loss: 0.2425 - val_mae: 0.2930 - val_coeff_determination: 0.7556 - val_rmse: 1.4921\n",
      "Epoch 41/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2904 - mae: 0.3742 - coeff_determination: 0.7069 - rmse: 1.6009 - val_loss: 0.2410 - val_mae: 0.2927 - val_coeff_determination: 0.7572 - val_rmse: 1.4899\n",
      "Epoch 42/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2854 - mae: 0.3706 - coeff_determination: 0.7124 - rmse: 1.5930 - val_loss: 0.2397 - val_mae: 0.2916 - val_coeff_determination: 0.7585 - val_rmse: 1.4876\n",
      "Epoch 43/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2882 - mae: 0.3711 - coeff_determination: 0.7094 - rmse: 1.5981 - val_loss: 0.2404 - val_mae: 0.2888 - val_coeff_determination: 0.7577 - val_rmse: 1.4879\n",
      "Epoch 44/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2836 - mae: 0.3682 - coeff_determination: 0.7135 - rmse: 1.5884 - val_loss: 0.2386 - val_mae: 0.2888 - val_coeff_determination: 0.7595 - val_rmse: 1.4856\n",
      "Epoch 45/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2822 - mae: 0.3665 - coeff_determination: 0.7153 - rmse: 1.5877 - val_loss: 0.2358 - val_mae: 0.2905 - val_coeff_determination: 0.7624 - val_rmse: 1.4821\n",
      "Epoch 46/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2828 - mae: 0.3688 - coeff_determination: 0.7143 - rmse: 1.5896 - val_loss: 0.2362 - val_mae: 0.2881 - val_coeff_determination: 0.7620 - val_rmse: 1.4821\n",
      "Epoch 47/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2805 - mae: 0.3663 - coeff_determination: 0.7166 - rmse: 1.5843 - val_loss: 0.2350 - val_mae: 0.2872 - val_coeff_determination: 0.7631 - val_rmse: 1.4803\n",
      "Epoch 48/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2786 - mae: 0.3645 - coeff_determination: 0.7183 - rmse: 1.5811 - val_loss: 0.2352 - val_mae: 0.2857 - val_coeff_determination: 0.7630 - val_rmse: 1.4803\n",
      "Epoch 49/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2761 - mae: 0.3602 - coeff_determination: 0.7215 - rmse: 1.5770 - val_loss: 0.2320 - val_mae: 0.2875 - val_coeff_determination: 0.7662 - val_rmse: 1.4764\n",
      "Epoch 50/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2769 - mae: 0.3640 - coeff_determination: 0.7206 - rmse: 1.5792 - val_loss: 0.2320 - val_mae: 0.2857 - val_coeff_determination: 0.7661 - val_rmse: 1.4761\n",
      "Epoch 51/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2766 - mae: 0.3615 - coeff_determination: 0.7210 - rmse: 1.5775 - val_loss: 0.2318 - val_mae: 0.2851 - val_coeff_determination: 0.7664 - val_rmse: 1.4759\n",
      "Epoch 52/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2712 - mae: 0.3582 - coeff_determination: 0.7266 - rmse: 1.5694 - val_loss: 0.2296 - val_mae: 0.2853 - val_coeff_determination: 0.7686 - val_rmse: 1.4728\n",
      "Epoch 53/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2710 - mae: 0.3588 - coeff_determination: 0.7270 - rmse: 1.5692 - val_loss: 0.2298 - val_mae: 0.2827 - val_coeff_determination: 0.7684 - val_rmse: 1.4720\n",
      "Epoch 54/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2735 - mae: 0.3597 - coeff_determination: 0.7240 - rmse: 1.5723 - val_loss: 0.2283 - val_mae: 0.2836 - val_coeff_determination: 0.7700 - val_rmse: 1.4704\n",
      "Epoch 55/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2693 - mae: 0.3565 - coeff_determination: 0.7277 - rmse: 1.5662 - val_loss: 0.2275 - val_mae: 0.2816 - val_coeff_determination: 0.7707 - val_rmse: 1.4685\n",
      "Epoch 56/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2706 - mae: 0.3562 - coeff_determination: 0.7272 - rmse: 1.5682 - val_loss: 0.2263 - val_mae: 0.2821 - val_coeff_determination: 0.7719 - val_rmse: 1.4672\n",
      "Epoch 57/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2680 - mae: 0.3556 - coeff_determination: 0.7301 - rmse: 1.5641 - val_loss: 0.2253 - val_mae: 0.2816 - val_coeff_determination: 0.7729 - val_rmse: 1.4656\n",
      "Epoch 58/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2663 - mae: 0.3537 - coeff_determination: 0.7305 - rmse: 1.5617 - val_loss: 0.2257 - val_mae: 0.2810 - val_coeff_determination: 0.7725 - val_rmse: 1.4665\n",
      "Epoch 59/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.2678 - mae: 0.3535 - coeff_determination: 0.7291 - rmse: 1.5639 - val_loss: 0.2234 - val_mae: 0.2817 - val_coeff_determination: 0.7749 - val_rmse: 1.4633\n",
      "Epoch 60/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2650 - mae: 0.3520 - coeff_determination: 0.7330 - rmse: 1.5589 - val_loss: 0.2233 - val_mae: 0.2795 - val_coeff_determination: 0.7750 - val_rmse: 1.4625\n",
      "Epoch 61/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2646 - mae: 0.3529 - coeff_determination: 0.7341 - rmse: 1.5594 - val_loss: 0.2234 - val_mae: 0.2784 - val_coeff_determination: 0.7748 - val_rmse: 1.4624\n",
      "Epoch 62/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2596 - mae: 0.3490 - coeff_determination: 0.7383 - rmse: 1.5511 - val_loss: 0.2231 - val_mae: 0.2772 - val_coeff_determination: 0.7751 - val_rmse: 1.4617\n",
      "Epoch 63/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2623 - mae: 0.3502 - coeff_determination: 0.7349 - rmse: 1.5552 - val_loss: 0.2222 - val_mae: 0.2758 - val_coeff_determination: 0.7761 - val_rmse: 1.4596\n",
      "Epoch 64/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2598 - mae: 0.3467 - coeff_determination: 0.7378 - rmse: 1.5493 - val_loss: 0.2219 - val_mae: 0.2761 - val_coeff_determination: 0.7764 - val_rmse: 1.4598\n",
      "Epoch 65/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2586 - mae: 0.3458 - coeff_determination: 0.7389 - rmse: 1.5482 - val_loss: 0.2203 - val_mae: 0.2764 - val_coeff_determination: 0.7780 - val_rmse: 1.4577\n",
      "Epoch 66/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2567 - mae: 0.3444 - coeff_determination: 0.7411 - rmse: 1.5449 - val_loss: 0.2187 - val_mae: 0.2786 - val_coeff_determination: 0.7795 - val_rmse: 1.4569\n",
      "Epoch 67/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2584 - mae: 0.3456 - coeff_determination: 0.7398 - rmse: 1.5476 - val_loss: 0.2189 - val_mae: 0.2757 - val_coeff_determination: 0.7793 - val_rmse: 1.4559\n",
      "Epoch 68/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2577 - mae: 0.3448 - coeff_determination: 0.7404 - rmse: 1.5476 - val_loss: 0.2179 - val_mae: 0.2778 - val_coeff_determination: 0.7804 - val_rmse: 1.4558\n",
      "Epoch 69/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2566 - mae: 0.3436 - coeff_determination: 0.7410 - rmse: 1.5442 - val_loss: 0.2173 - val_mae: 0.2761 - val_coeff_determination: 0.7810 - val_rmse: 1.4540\n",
      "Epoch 70/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2563 - mae: 0.3460 - coeff_determination: 0.7410 - rmse: 1.5464 - val_loss: 0.2171 - val_mae: 0.2753 - val_coeff_determination: 0.7812 - val_rmse: 1.4537\n",
      "Epoch 71/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2556 - mae: 0.3440 - coeff_determination: 0.7419 - rmse: 1.5442 - val_loss: 0.2153 - val_mae: 0.2770 - val_coeff_determination: 0.7830 - val_rmse: 1.4520\n",
      "Epoch 72/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2510 - mae: 0.3417 - coeff_determination: 0.7467 - rmse: 1.5370 - val_loss: 0.2165 - val_mae: 0.2726 - val_coeff_determination: 0.7818 - val_rmse: 1.4516\n",
      "Epoch 73/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2503 - mae: 0.3388 - coeff_determination: 0.7476 - rmse: 1.5348 - val_loss: 0.2148 - val_mae: 0.2728 - val_coeff_determination: 0.7835 - val_rmse: 1.4493\n",
      "Epoch 74/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2503 - mae: 0.3392 - coeff_determination: 0.7479 - rmse: 1.5345 - val_loss: 0.2150 - val_mae: 0.2732 - val_coeff_determination: 0.7833 - val_rmse: 1.4501\n",
      "Epoch 75/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2494 - mae: 0.3386 - coeff_determination: 0.7484 - rmse: 1.5335 - val_loss: 0.2127 - val_mae: 0.2726 - val_coeff_determination: 0.7856 - val_rmse: 1.4462\n",
      "Epoch 76/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2498 - mae: 0.3385 - coeff_determination: 0.7487 - rmse: 1.5339 - val_loss: 0.2129 - val_mae: 0.2722 - val_coeff_determination: 0.7854 - val_rmse: 1.4467\n",
      "Epoch 77/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2495 - mae: 0.3372 - coeff_determination: 0.7484 - rmse: 1.5330 - val_loss: 0.2122 - val_mae: 0.2718 - val_coeff_determination: 0.7861 - val_rmse: 1.4457\n",
      "Epoch 78/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2483 - mae: 0.3370 - coeff_determination: 0.7497 - rmse: 1.5309 - val_loss: 0.2118 - val_mae: 0.2709 - val_coeff_determination: 0.7865 - val_rmse: 1.4448\n",
      "Epoch 79/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2484 - mae: 0.3357 - coeff_determination: 0.7498 - rmse: 1.5302 - val_loss: 0.2113 - val_mae: 0.2711 - val_coeff_determination: 0.7871 - val_rmse: 1.4443\n",
      "Epoch 80/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2457 - mae: 0.3330 - coeff_determination: 0.7524 - rmse: 1.5265 - val_loss: 0.2106 - val_mae: 0.2697 - val_coeff_determination: 0.7878 - val_rmse: 1.4427\n",
      "Epoch 81/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2452 - mae: 0.3350 - coeff_determination: 0.7525 - rmse: 1.5269 - val_loss: 0.2110 - val_mae: 0.2692 - val_coeff_determination: 0.7873 - val_rmse: 1.4436\n",
      "Epoch 82/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2465 - mae: 0.3321 - coeff_determination: 0.7518 - rmse: 1.5270 - val_loss: 0.2102 - val_mae: 0.2708 - val_coeff_determination: 0.7882 - val_rmse: 1.4434\n",
      "Epoch 83/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2426 - mae: 0.3323 - coeff_determination: 0.7551 - rmse: 1.5223 - val_loss: 0.2086 - val_mae: 0.2716 - val_coeff_determination: 0.7897 - val_rmse: 1.4415\n",
      "Epoch 84/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2470 - mae: 0.3357 - coeff_determination: 0.7512 - rmse: 1.5292 - val_loss: 0.2087 - val_mae: 0.2697 - val_coeff_determination: 0.7896 - val_rmse: 1.4407\n",
      "Epoch 85/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2428 - mae: 0.3333 - coeff_determination: 0.7551 - rmse: 1.5232 - val_loss: 0.2088 - val_mae: 0.2676 - val_coeff_determination: 0.7896 - val_rmse: 1.4399\n",
      "Epoch 86/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2447 - mae: 0.3327 - coeff_determination: 0.7527 - rmse: 1.5254 - val_loss: 0.2074 - val_mae: 0.2692 - val_coeff_determination: 0.7909 - val_rmse: 1.4388\n",
      "Epoch 87/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2423 - mae: 0.3314 - coeff_determination: 0.7560 - rmse: 1.5214 - val_loss: 0.2070 - val_mae: 0.2693 - val_coeff_determination: 0.7913 - val_rmse: 1.4384\n",
      "Epoch 88/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2430 - mae: 0.3311 - coeff_determination: 0.7543 - rmse: 1.5223 - val_loss: 0.2072 - val_mae: 0.2684 - val_coeff_determination: 0.7911 - val_rmse: 1.4384\n",
      "Epoch 89/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2414 - mae: 0.3308 - coeff_determination: 0.7563 - rmse: 1.5198 - val_loss: 0.2071 - val_mae: 0.2662 - val_coeff_determination: 0.7913 - val_rmse: 1.4372\n",
      "Epoch 90/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2460 - mae: 0.3326 - coeff_determination: 0.7518 - rmse: 1.5273 - val_loss: 0.2069 - val_mae: 0.2667 - val_coeff_determination: 0.7915 - val_rmse: 1.4374\n",
      "Epoch 91/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2393 - mae: 0.3263 - coeff_determination: 0.7589 - rmse: 1.5144 - val_loss: 0.2058 - val_mae: 0.2673 - val_coeff_determination: 0.7925 - val_rmse: 1.4362\n",
      "Epoch 92/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2383 - mae: 0.3286 - coeff_determination: 0.7592 - rmse: 1.5143 - val_loss: 0.2046 - val_mae: 0.2687 - val_coeff_determination: 0.7938 - val_rmse: 1.4352\n",
      "Epoch 93/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2395 - mae: 0.3281 - coeff_determination: 0.7586 - rmse: 1.5164 - val_loss: 0.2045 - val_mae: 0.2662 - val_coeff_determination: 0.7939 - val_rmse: 1.4337\n",
      "Epoch 94/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2376 - mae: 0.3260 - coeff_determination: 0.7608 - rmse: 1.5125 - val_loss: 0.2039 - val_mae: 0.2653 - val_coeff_determination: 0.7945 - val_rmse: 1.4324\n",
      "Epoch 95/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2366 - mae: 0.3257 - coeff_determination: 0.7618 - rmse: 1.5111 - val_loss: 0.2045 - val_mae: 0.2638 - val_coeff_determination: 0.7939 - val_rmse: 1.4325\n",
      "Epoch 96/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2377 - mae: 0.3264 - coeff_determination: 0.7598 - rmse: 1.5127 - val_loss: 0.2037 - val_mae: 0.2642 - val_coeff_determination: 0.7947 - val_rmse: 1.4317\n",
      "Epoch 97/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2365 - mae: 0.3240 - coeff_determination: 0.7616 - rmse: 1.5111 - val_loss: 0.2032 - val_mae: 0.2644 - val_coeff_determination: 0.7951 - val_rmse: 1.4314\n",
      "Epoch 98/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2358 - mae: 0.3258 - coeff_determination: 0.7621 - rmse: 1.5102 - val_loss: 0.2038 - val_mae: 0.2624 - val_coeff_determination: 0.7945 - val_rmse: 1.4314\n",
      "Epoch 99/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2363 - mae: 0.3240 - coeff_determination: 0.7611 - rmse: 1.5108 - val_loss: 0.2026 - val_mae: 0.2650 - val_coeff_determination: 0.7958 - val_rmse: 1.4313\n",
      "Epoch 100/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2331 - mae: 0.3232 - coeff_determination: 0.7647 - rmse: 1.5055 - val_loss: 0.2020 - val_mae: 0.2638 - val_coeff_determination: 0.7964 - val_rmse: 1.4298\n",
      "Epoch 101/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2332 - mae: 0.3227 - coeff_determination: 0.7641 - rmse: 1.5062 - val_loss: 0.2019 - val_mae: 0.2628 - val_coeff_determination: 0.7965 - val_rmse: 1.4291\n",
      "Epoch 102/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2322 - mae: 0.3207 - coeff_determination: 0.7658 - rmse: 1.5037 - val_loss: 0.2015 - val_mae: 0.2649 - val_coeff_determination: 0.7969 - val_rmse: 1.4299\n",
      "Epoch 103/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2341 - mae: 0.3246 - coeff_determination: 0.7643 - rmse: 1.5075 - val_loss: 0.2019 - val_mae: 0.2615 - val_coeff_determination: 0.7964 - val_rmse: 1.4287\n",
      "Epoch 104/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2336 - mae: 0.3220 - coeff_determination: 0.7647 - rmse: 1.5062 - val_loss: 0.2009 - val_mae: 0.2627 - val_coeff_determination: 0.7975 - val_rmse: 1.4277\n",
      "Epoch 105/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2322 - mae: 0.3199 - coeff_determination: 0.7656 - rmse: 1.5030 - val_loss: 0.2005 - val_mae: 0.2636 - val_coeff_determination: 0.7979 - val_rmse: 1.4279\n",
      "Epoch 106/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2319 - mae: 0.3214 - coeff_determination: 0.7660 - rmse: 1.5038 - val_loss: 0.2008 - val_mae: 0.2627 - val_coeff_determination: 0.7976 - val_rmse: 1.4282\n",
      "Epoch 107/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2268 - mae: 0.3161 - coeff_determination: 0.7712 - rmse: 1.4947 - val_loss: 0.2009 - val_mae: 0.2599 - val_coeff_determination: 0.7975 - val_rmse: 1.4267\n",
      "Epoch 108/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2282 - mae: 0.3165 - coeff_determination: 0.7703 - rmse: 1.4954 - val_loss: 0.2006 - val_mae: 0.2595 - val_coeff_determination: 0.7978 - val_rmse: 1.4260\n",
      "Epoch 109/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2295 - mae: 0.3163 - coeff_determination: 0.7678 - rmse: 1.4982 - val_loss: 0.1990 - val_mae: 0.2616 - val_coeff_determination: 0.7994 - val_rmse: 1.4248\n",
      "Epoch 110/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2286 - mae: 0.3161 - coeff_determination: 0.7693 - rmse: 1.4960 - val_loss: 0.1984 - val_mae: 0.2641 - val_coeff_determination: 0.8000 - val_rmse: 1.4255\n",
      "Epoch 111/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2269 - mae: 0.3163 - coeff_determination: 0.7711 - rmse: 1.4938 - val_loss: 0.1989 - val_mae: 0.2622 - val_coeff_determination: 0.7995 - val_rmse: 1.4254\n",
      "Epoch 112/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2288 - mae: 0.3160 - coeff_determination: 0.7692 - rmse: 1.4964 - val_loss: 0.1980 - val_mae: 0.2632 - val_coeff_determination: 0.8004 - val_rmse: 1.4246\n",
      "Epoch 113/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2297 - mae: 0.3170 - coeff_determination: 0.7686 - rmse: 1.5014 - val_loss: 0.1987 - val_mae: 0.2608 - val_coeff_determination: 0.7997 - val_rmse: 1.4245\n",
      "Epoch 114/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2279 - mae: 0.3136 - coeff_determination: 0.7704 - rmse: 1.4944 - val_loss: 0.1986 - val_mae: 0.2613 - val_coeff_determination: 0.7998 - val_rmse: 1.4248\n",
      "Epoch 115/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2289 - mae: 0.3161 - coeff_determination: 0.7692 - rmse: 1.4972 - val_loss: 0.1986 - val_mae: 0.2589 - val_coeff_determination: 0.7998 - val_rmse: 1.4234\n",
      "Epoch 116/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2235 - mae: 0.3115 - coeff_determination: 0.7749 - rmse: 1.4875 - val_loss: 0.1979 - val_mae: 0.2596 - val_coeff_determination: 0.8005 - val_rmse: 1.4229\n",
      "Epoch 117/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2269 - mae: 0.3164 - coeff_determination: 0.7711 - rmse: 1.4949 - val_loss: 0.1980 - val_mae: 0.2593 - val_coeff_determination: 0.8005 - val_rmse: 1.4228\n",
      "Epoch 118/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2260 - mae: 0.3140 - coeff_determination: 0.7725 - rmse: 1.4925 - val_loss: 0.1968 - val_mae: 0.2612 - val_coeff_determination: 0.8016 - val_rmse: 1.4222\n",
      "Epoch 119/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2251 - mae: 0.3129 - coeff_determination: 0.7720 - rmse: 1.4906 - val_loss: 0.1966 - val_mae: 0.2605 - val_coeff_determination: 0.8018 - val_rmse: 1.4214\n",
      "Epoch 120/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2248 - mae: 0.3128 - coeff_determination: 0.7735 - rmse: 1.4901 - val_loss: 0.1968 - val_mae: 0.2586 - val_coeff_determination: 0.8017 - val_rmse: 1.4207\n",
      "Epoch 121/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2248 - mae: 0.3125 - coeff_determination: 0.7736 - rmse: 1.4897 - val_loss: 0.1972 - val_mae: 0.2566 - val_coeff_determination: 0.8012 - val_rmse: 1.4203\n",
      "Epoch 122/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2246 - mae: 0.3117 - coeff_determination: 0.7737 - rmse: 1.4893 - val_loss: 0.1967 - val_mae: 0.2571 - val_coeff_determination: 0.8018 - val_rmse: 1.4198\n",
      "Epoch 123/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2235 - mae: 0.3099 - coeff_determination: 0.7754 - rmse: 1.4866 - val_loss: 0.1959 - val_mae: 0.2582 - val_coeff_determination: 0.8025 - val_rmse: 1.4193\n",
      "Epoch 124/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2260 - mae: 0.3129 - coeff_determination: 0.7720 - rmse: 1.4922 - val_loss: 0.1952 - val_mae: 0.2590 - val_coeff_determination: 0.8032 - val_rmse: 1.4187\n",
      "Epoch 125/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2220 - mae: 0.3100 - coeff_determination: 0.7764 - rmse: 1.4849 - val_loss: 0.1958 - val_mae: 0.2566 - val_coeff_determination: 0.8026 - val_rmse: 1.4182\n",
      "Epoch 126/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2210 - mae: 0.3092 - coeff_determination: 0.7771 - rmse: 1.4841 - val_loss: 0.1952 - val_mae: 0.2578 - val_coeff_determination: 0.8032 - val_rmse: 1.4183\n",
      "Epoch 127/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2238 - mae: 0.3118 - coeff_determination: 0.7744 - rmse: 1.4902 - val_loss: 0.1963 - val_mae: 0.2553 - val_coeff_determination: 0.8022 - val_rmse: 1.4186\n",
      "Epoch 128/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2198 - mae: 0.3060 - coeff_determination: 0.7784 - rmse: 1.4796 - val_loss: 0.1955 - val_mae: 0.2555 - val_coeff_determination: 0.8029 - val_rmse: 1.4174\n",
      "Epoch 129/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2215 - mae: 0.3073 - coeff_determination: 0.7771 - rmse: 1.4831 - val_loss: 0.1943 - val_mae: 0.2578 - val_coeff_determination: 0.8041 - val_rmse: 1.4168\n",
      "Epoch 130/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2229 - mae: 0.3108 - coeff_determination: 0.7756 - rmse: 1.4863 - val_loss: 0.1950 - val_mae: 0.2542 - val_coeff_determination: 0.8035 - val_rmse: 1.4157\n",
      "Epoch 131/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2191 - mae: 0.3077 - coeff_determination: 0.7790 - rmse: 1.4806 - val_loss: 0.1951 - val_mae: 0.2551 - val_coeff_determination: 0.8034 - val_rmse: 1.4167\n",
      "Epoch 132/550\n",
      "11759/11759 [==============================] - 1s 62us/step - loss: 0.2201 - mae: 0.3055 - coeff_determination: 0.7782 - rmse: 1.4803 - val_loss: 0.1942 - val_mae: 0.2539 - val_coeff_determination: 0.8042 - val_rmse: 1.4145\n",
      "Epoch 133/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2187 - mae: 0.3070 - coeff_determination: 0.7797 - rmse: 1.4792 - val_loss: 0.1938 - val_mae: 0.2555 - val_coeff_determination: 0.8047 - val_rmse: 1.4147\n",
      "Epoch 134/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2221 - mae: 0.3084 - coeff_determination: 0.7759 - rmse: 1.4843 - val_loss: 0.1943 - val_mae: 0.2517 - val_coeff_determination: 0.8041 - val_rmse: 1.4132\n",
      "Epoch 135/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2196 - mae: 0.3050 - coeff_determination: 0.7782 - rmse: 1.4795 - val_loss: 0.1928 - val_mae: 0.2548 - val_coeff_determination: 0.8057 - val_rmse: 1.4127\n",
      "Epoch 136/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2178 - mae: 0.3058 - coeff_determination: 0.7802 - rmse: 1.4773 - val_loss: 0.1934 - val_mae: 0.2530 - val_coeff_determination: 0.8051 - val_rmse: 1.4129\n",
      "Epoch 137/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2187 - mae: 0.3054 - coeff_determination: 0.7798 - rmse: 1.4795 - val_loss: 0.1923 - val_mae: 0.2561 - val_coeff_determination: 0.8062 - val_rmse: 1.4130\n",
      "Epoch 138/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2180 - mae: 0.3049 - coeff_determination: 0.7804 - rmse: 1.4777 - val_loss: 0.1926 - val_mae: 0.2532 - val_coeff_determination: 0.8059 - val_rmse: 1.4117\n",
      "Epoch 139/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2176 - mae: 0.3053 - coeff_determination: 0.7809 - rmse: 1.4779 - val_loss: 0.1924 - val_mae: 0.2532 - val_coeff_determination: 0.8061 - val_rmse: 1.4116\n",
      "Epoch 140/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2186 - mae: 0.3043 - coeff_determination: 0.7794 - rmse: 1.4783 - val_loss: 0.1925 - val_mae: 0.2537 - val_coeff_determination: 0.8059 - val_rmse: 1.4122\n",
      "Epoch 141/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2176 - mae: 0.3046 - coeff_determination: 0.7803 - rmse: 1.4761 - val_loss: 0.1928 - val_mae: 0.2519 - val_coeff_determination: 0.8057 - val_rmse: 1.4115\n",
      "Epoch 142/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2178 - mae: 0.3043 - coeff_determination: 0.7808 - rmse: 1.4773 - val_loss: 0.1922 - val_mae: 0.2533 - val_coeff_determination: 0.8063 - val_rmse: 1.4115\n",
      "Epoch 143/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2192 - mae: 0.3039 - coeff_determination: 0.7792 - rmse: 1.4789 - val_loss: 0.1922 - val_mae: 0.2524 - val_coeff_determination: 0.8062 - val_rmse: 1.4111\n",
      "Epoch 144/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2173 - mae: 0.3042 - coeff_determination: 0.7808 - rmse: 1.4776 - val_loss: 0.1924 - val_mae: 0.2503 - val_coeff_determination: 0.8060 - val_rmse: 1.4101\n",
      "Epoch 145/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2179 - mae: 0.3023 - coeff_determination: 0.7800 - rmse: 1.4759 - val_loss: 0.1910 - val_mae: 0.2524 - val_coeff_determination: 0.8074 - val_rmse: 1.4090\n",
      "Epoch 146/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2175 - mae: 0.3024 - coeff_determination: 0.7810 - rmse: 1.4758 - val_loss: 0.1914 - val_mae: 0.2511 - val_coeff_determination: 0.8070 - val_rmse: 1.4088\n",
      "Epoch 147/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2149 - mae: 0.3017 - coeff_determination: 0.7828 - rmse: 1.4717 - val_loss: 0.1916 - val_mae: 0.2532 - val_coeff_determination: 0.8068 - val_rmse: 1.4108\n",
      "Epoch 148/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2132 - mae: 0.3009 - coeff_determination: 0.7847 - rmse: 1.4691 - val_loss: 0.1909 - val_mae: 0.2531 - val_coeff_determination: 0.8076 - val_rmse: 1.4095\n",
      "Epoch 149/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2152 - mae: 0.3021 - coeff_determination: 0.7830 - rmse: 1.4724 - val_loss: 0.1912 - val_mae: 0.2531 - val_coeff_determination: 0.8073 - val_rmse: 1.4102\n",
      "Epoch 150/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2133 - mae: 0.3006 - coeff_determination: 0.7849 - rmse: 1.4693 - val_loss: 0.1905 - val_mae: 0.2547 - val_coeff_determination: 0.8080 - val_rmse: 1.4100\n",
      "Epoch 151/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2168 - mae: 0.3011 - coeff_determination: 0.7808 - rmse: 1.4755 - val_loss: 0.1914 - val_mae: 0.2500 - val_coeff_determination: 0.8071 - val_rmse: 1.4086\n",
      "Epoch 152/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2137 - mae: 0.3003 - coeff_determination: 0.7850 - rmse: 1.4696 - val_loss: 0.1904 - val_mae: 0.2504 - val_coeff_determination: 0.8081 - val_rmse: 1.4073\n",
      "Epoch 153/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2128 - mae: 0.2996 - coeff_determination: 0.7851 - rmse: 1.4681 - val_loss: 0.1910 - val_mae: 0.2494 - val_coeff_determination: 0.8075 - val_rmse: 1.4076\n",
      "Epoch 154/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.2152 - mae: 0.3003 - coeff_determination: 0.7828 - rmse: 1.4719 - val_loss: 0.1910 - val_mae: 0.2488 - val_coeff_determination: 0.8075 - val_rmse: 1.4073\n",
      "Epoch 155/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2150 - mae: 0.3005 - coeff_determination: 0.7830 - rmse: 1.4721 - val_loss: 0.1912 - val_mae: 0.2479 - val_coeff_determination: 0.8073 - val_rmse: 1.4071\n",
      "Epoch 156/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2132 - mae: 0.2993 - coeff_determination: 0.7851 - rmse: 1.4687 - val_loss: 0.1917 - val_mae: 0.2479 - val_coeff_determination: 0.8067 - val_rmse: 1.4079\n",
      "Epoch 157/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2144 - mae: 0.2982 - coeff_determination: 0.7839 - rmse: 1.4698 - val_loss: 0.1895 - val_mae: 0.2521 - val_coeff_determination: 0.8090 - val_rmse: 1.4071\n",
      "Epoch 158/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2093 - mae: 0.2989 - coeff_determination: 0.7891 - rmse: 1.4639 - val_loss: 0.1912 - val_mae: 0.2501 - val_coeff_determination: 0.8073 - val_rmse: 1.4087\n",
      "Epoch 159/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2116 - mae: 0.2987 - coeff_determination: 0.7859 - rmse: 1.4656 - val_loss: 0.1911 - val_mae: 0.2475 - val_coeff_determination: 0.8074 - val_rmse: 1.4068\n",
      "Epoch 160/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2171 - mae: 0.3003 - coeff_determination: 0.7812 - rmse: 1.4740 - val_loss: 0.1887 - val_mae: 0.2528 - val_coeff_determination: 0.8098 - val_rmse: 1.4064\n",
      "Epoch 161/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2104 - mae: 0.2971 - coeff_determination: 0.7878 - rmse: 1.4636 - val_loss: 0.1897 - val_mae: 0.2502 - val_coeff_determination: 0.8088 - val_rmse: 1.4064\n",
      "Epoch 162/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2108 - mae: 0.2978 - coeff_determination: 0.7876 - rmse: 1.4648 - val_loss: 0.1888 - val_mae: 0.2493 - val_coeff_determination: 0.8097 - val_rmse: 1.4042\n",
      "Epoch 163/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.2121 - mae: 0.2979 - coeff_determination: 0.7857 - rmse: 1.4668 - val_loss: 0.1896 - val_mae: 0.2473 - val_coeff_determination: 0.8089 - val_rmse: 1.4042\n",
      "Epoch 164/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2107 - mae: 0.2960 - coeff_determination: 0.7873 - rmse: 1.4627 - val_loss: 0.1906 - val_mae: 0.2453 - val_coeff_determination: 0.8079 - val_rmse: 1.4045\n",
      "Epoch 165/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2090 - mae: 0.2952 - coeff_determination: 0.7894 - rmse: 1.4609 - val_loss: 0.1899 - val_mae: 0.2472 - val_coeff_determination: 0.8086 - val_rmse: 1.4047\n",
      "Epoch 166/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2087 - mae: 0.2948 - coeff_determination: 0.7898 - rmse: 1.4594 - val_loss: 0.1908 - val_mae: 0.2462 - val_coeff_determination: 0.8077 - val_rmse: 1.4057\n",
      "Epoch 167/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2115 - mae: 0.2972 - coeff_determination: 0.7862 - rmse: 1.4654 - val_loss: 0.1893 - val_mae: 0.2467 - val_coeff_determination: 0.8092 - val_rmse: 1.4037\n",
      "Epoch 168/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2080 - mae: 0.2944 - coeff_determination: 0.7903 - rmse: 1.4593 - val_loss: 0.1892 - val_mae: 0.2465 - val_coeff_determination: 0.8093 - val_rmse: 1.4034\n",
      "Epoch 169/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2081 - mae: 0.2927 - coeff_determination: 0.7902 - rmse: 1.4587 - val_loss: 0.1882 - val_mae: 0.2509 - val_coeff_determination: 0.8103 - val_rmse: 1.4047\n",
      "Epoch 170/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.2104 - mae: 0.2958 - coeff_determination: 0.7878 - rmse: 1.4633 - val_loss: 0.1889 - val_mae: 0.2482 - val_coeff_determination: 0.8096 - val_rmse: 1.4041\n",
      "Epoch 171/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2093 - mae: 0.2941 - coeff_determination: 0.7885 - rmse: 1.4610 - val_loss: 0.1889 - val_mae: 0.2484 - val_coeff_determination: 0.8096 - val_rmse: 1.4042\n",
      "Epoch 172/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.2087 - mae: 0.2936 - coeff_determination: 0.7894 - rmse: 1.4597 - val_loss: 0.1884 - val_mae: 0.2485 - val_coeff_determination: 0.8101 - val_rmse: 1.4037\n",
      "Epoch 173/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2087 - mae: 0.2940 - coeff_determination: 0.7898 - rmse: 1.4605 - val_loss: 0.1874 - val_mae: 0.2479 - val_coeff_determination: 0.8111 - val_rmse: 1.4017\n",
      "Epoch 174/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2085 - mae: 0.2928 - coeff_determination: 0.7901 - rmse: 1.4588 - val_loss: 0.1880 - val_mae: 0.2457 - val_coeff_determination: 0.8105 - val_rmse: 1.4010\n",
      "Epoch 175/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2080 - mae: 0.2942 - coeff_determination: 0.7899 - rmse: 1.4587 - val_loss: 0.1877 - val_mae: 0.2469 - val_coeff_determination: 0.8108 - val_rmse: 1.4013\n",
      "Epoch 176/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2044 - mae: 0.2919 - coeff_determination: 0.7935 - rmse: 1.4519 - val_loss: 0.1885 - val_mae: 0.2448 - val_coeff_determination: 0.8100 - val_rmse: 1.4013\n",
      "Epoch 177/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2066 - mae: 0.2926 - coeff_determination: 0.7912 - rmse: 1.4563 - val_loss: 0.1896 - val_mae: 0.2458 - val_coeff_determination: 0.8088 - val_rmse: 1.4041\n",
      "Epoch 178/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2054 - mae: 0.2892 - coeff_determination: 0.7928 - rmse: 1.4531 - val_loss: 0.1884 - val_mae: 0.2448 - val_coeff_determination: 0.8101 - val_rmse: 1.4013\n",
      "Epoch 179/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2070 - mae: 0.2924 - coeff_determination: 0.7915 - rmse: 1.4570 - val_loss: 0.1873 - val_mae: 0.2459 - val_coeff_determination: 0.8112 - val_rmse: 1.4002\n",
      "Epoch 180/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2066 - mae: 0.2922 - coeff_determination: 0.7909 - rmse: 1.4563 - val_loss: 0.1884 - val_mae: 0.2444 - val_coeff_determination: 0.8101 - val_rmse: 1.4012\n",
      "Epoch 181/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2044 - mae: 0.2905 - coeff_determination: 0.7937 - rmse: 1.4524 - val_loss: 0.1875 - val_mae: 0.2454 - val_coeff_determination: 0.8110 - val_rmse: 1.4004\n",
      "Epoch 182/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2067 - mae: 0.2913 - coeff_determination: 0.7912 - rmse: 1.4556 - val_loss: 0.1870 - val_mae: 0.2465 - val_coeff_determination: 0.8115 - val_rmse: 1.4003\n",
      "Epoch 183/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2044 - mae: 0.2906 - coeff_determination: 0.7934 - rmse: 1.4534 - val_loss: 0.1875 - val_mae: 0.2457 - val_coeff_determination: 0.8110 - val_rmse: 1.4007\n",
      "Epoch 184/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2033 - mae: 0.2882 - coeff_determination: 0.7953 - rmse: 1.4499 - val_loss: 0.1868 - val_mae: 0.2463 - val_coeff_determination: 0.8117 - val_rmse: 1.3999\n",
      "Epoch 185/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.2057 - mae: 0.2904 - coeff_determination: 0.7924 - rmse: 1.4576 - val_loss: 0.1864 - val_mae: 0.2474 - val_coeff_determination: 0.8121 - val_rmse: 1.4000\n",
      "Epoch 186/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2052 - mae: 0.2901 - coeff_determination: 0.7930 - rmse: 1.4523 - val_loss: 0.1880 - val_mae: 0.2434 - val_coeff_determination: 0.8105 - val_rmse: 1.4002\n",
      "Epoch 187/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2066 - mae: 0.2913 - coeff_determination: 0.7907 - rmse: 1.4554 - val_loss: 0.1867 - val_mae: 0.2467 - val_coeff_determination: 0.8118 - val_rmse: 1.4000\n",
      "Epoch 188/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2039 - mae: 0.2887 - coeff_determination: 0.7947 - rmse: 1.4502 - val_loss: 0.1873 - val_mae: 0.2440 - val_coeff_determination: 0.8112 - val_rmse: 1.3994\n",
      "Epoch 189/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2071 - mae: 0.2902 - coeff_determination: 0.7911 - rmse: 1.4557 - val_loss: 0.1875 - val_mae: 0.2434 - val_coeff_determination: 0.8110 - val_rmse: 1.3995\n",
      "Epoch 190/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2058 - mae: 0.2902 - coeff_determination: 0.7921 - rmse: 1.4546 - val_loss: 0.1857 - val_mae: 0.2443 - val_coeff_determination: 0.8128 - val_rmse: 1.3969\n",
      "Epoch 191/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2049 - mae: 0.2893 - coeff_determination: 0.7936 - rmse: 1.4525 - val_loss: 0.1856 - val_mae: 0.2451 - val_coeff_determination: 0.8129 - val_rmse: 1.3974\n",
      "Epoch 192/550\n",
      "11759/11759 [==============================] - 1s 62us/step - loss: 0.2012 - mae: 0.2878 - coeff_determination: 0.7974 - rmse: 1.4468 - val_loss: 0.1868 - val_mae: 0.2438 - val_coeff_determination: 0.8117 - val_rmse: 1.3986\n",
      "Epoch 193/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.2047 - mae: 0.2882 - coeff_determination: 0.7932 - rmse: 1.4520 - val_loss: 0.1857 - val_mae: 0.2447 - val_coeff_determination: 0.8128 - val_rmse: 1.3972\n",
      "Epoch 194/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2020 - mae: 0.2877 - coeff_determination: 0.7960 - rmse: 1.4476 - val_loss: 0.1847 - val_mae: 0.2474 - val_coeff_determination: 0.8138 - val_rmse: 1.3974\n",
      "Epoch 195/550\n",
      "11759/11759 [==============================] - 1s 61us/step - loss: 0.2048 - mae: 0.2908 - coeff_determination: 0.7934 - rmse: 1.4531 - val_loss: 0.1861 - val_mae: 0.2432 - val_coeff_determination: 0.8124 - val_rmse: 1.3969\n",
      "Epoch 196/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2051 - mae: 0.2896 - coeff_determination: 0.7928 - rmse: 1.4524 - val_loss: 0.1870 - val_mae: 0.2423 - val_coeff_determination: 0.8115 - val_rmse: 1.3980\n",
      "Epoch 197/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2031 - mae: 0.2892 - coeff_determination: 0.7946 - rmse: 1.4497 - val_loss: 0.1859 - val_mae: 0.2429 - val_coeff_determination: 0.8126 - val_rmse: 1.3966\n",
      "Epoch 198/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2013 - mae: 0.2864 - coeff_determination: 0.7974 - rmse: 1.4460 - val_loss: 0.1855 - val_mae: 0.2429 - val_coeff_determination: 0.8130 - val_rmse: 1.3958\n",
      "Epoch 199/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2040 - mae: 0.2868 - coeff_determination: 0.7946 - rmse: 1.4494 - val_loss: 0.1853 - val_mae: 0.2430 - val_coeff_determination: 0.8132 - val_rmse: 1.3956\n",
      "Epoch 200/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2031 - mae: 0.2880 - coeff_determination: 0.7949 - rmse: 1.4494 - val_loss: 0.1848 - val_mae: 0.2440 - val_coeff_determination: 0.8137 - val_rmse: 1.3954\n",
      "Epoch 201/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.2045 - mae: 0.2887 - coeff_determination: 0.7937 - rmse: 1.4527 - val_loss: 0.1858 - val_mae: 0.2417 - val_coeff_determination: 0.8127 - val_rmse: 1.3958\n",
      "Epoch 202/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2029 - mae: 0.2868 - coeff_determination: 0.7950 - rmse: 1.4480 - val_loss: 0.1848 - val_mae: 0.2426 - val_coeff_determination: 0.8137 - val_rmse: 1.3946\n",
      "Epoch 203/550\n",
      "11759/11759 [==============================] - 1s 61us/step - loss: 0.2024 - mae: 0.2874 - coeff_determination: 0.7958 - rmse: 1.4479 - val_loss: 0.1859 - val_mae: 0.2412 - val_coeff_determination: 0.8126 - val_rmse: 1.3957\n",
      "Epoch 204/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2010 - mae: 0.2860 - coeff_determination: 0.7978 - rmse: 1.4450 - val_loss: 0.1849 - val_mae: 0.2425 - val_coeff_determination: 0.8137 - val_rmse: 1.3947\n",
      "Epoch 205/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2036 - mae: 0.2875 - coeff_determination: 0.7943 - rmse: 1.4499 - val_loss: 0.1858 - val_mae: 0.2423 - val_coeff_determination: 0.8127 - val_rmse: 1.3965\n",
      "Epoch 206/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2016 - mae: 0.2875 - coeff_determination: 0.7966 - rmse: 1.4477 - val_loss: 0.1850 - val_mae: 0.2419 - val_coeff_determination: 0.8135 - val_rmse: 1.3947\n",
      "Epoch 207/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1987 - mae: 0.2842 - coeff_determination: 0.7994 - rmse: 1.4415 - val_loss: 0.1858 - val_mae: 0.2428 - val_coeff_determination: 0.8127 - val_rmse: 1.3968\n",
      "Epoch 208/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2032 - mae: 0.2871 - coeff_determination: 0.7942 - rmse: 1.4492 - val_loss: 0.1842 - val_mae: 0.2434 - val_coeff_determination: 0.8143 - val_rmse: 1.3943\n",
      "Epoch 209/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2017 - mae: 0.2860 - coeff_determination: 0.7962 - rmse: 1.4456 - val_loss: 0.1849 - val_mae: 0.2423 - val_coeff_determination: 0.8136 - val_rmse: 1.3950\n",
      "Epoch 210/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2005 - mae: 0.2842 - coeff_determination: 0.7978 - rmse: 1.4437 - val_loss: 0.1847 - val_mae: 0.2418 - val_coeff_determination: 0.8139 - val_rmse: 1.3941\n",
      "Epoch 211/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1998 - mae: 0.2838 - coeff_determination: 0.7983 - rmse: 1.4425 - val_loss: 0.1846 - val_mae: 0.2425 - val_coeff_determination: 0.8139 - val_rmse: 1.3946\n",
      "Epoch 212/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.2016 - mae: 0.2853 - coeff_determination: 0.7971 - rmse: 1.4451 - val_loss: 0.1852 - val_mae: 0.2416 - val_coeff_determination: 0.8133 - val_rmse: 1.3952\n",
      "Epoch 213/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.2003 - mae: 0.2842 - coeff_determination: 0.7975 - rmse: 1.4436 - val_loss: 0.1848 - val_mae: 0.2415 - val_coeff_determination: 0.8137 - val_rmse: 1.3944\n",
      "Epoch 214/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.2015 - mae: 0.2860 - coeff_determination: 0.7968 - rmse: 1.4461 - val_loss: 0.1838 - val_mae: 0.2430 - val_coeff_determination: 0.8147 - val_rmse: 1.3938\n",
      "Epoch 215/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.2001 - mae: 0.2840 - coeff_determination: 0.7984 - rmse: 1.4432 - val_loss: 0.1849 - val_mae: 0.2411 - val_coeff_determination: 0.8136 - val_rmse: 1.3946\n",
      "Epoch 216/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.2037 - mae: 0.2846 - coeff_determination: 0.7945 - rmse: 1.4482 - val_loss: 0.1833 - val_mae: 0.2434 - val_coeff_determination: 0.8152 - val_rmse: 1.3931\n",
      "Epoch 217/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.2016 - mae: 0.2863 - coeff_determination: 0.7965 - rmse: 1.4457 - val_loss: 0.1850 - val_mae: 0.2407 - val_coeff_determination: 0.8135 - val_rmse: 1.3944\n",
      "Epoch 218/550\n",
      "11759/11759 [==============================] - 1s 62us/step - loss: 0.1973 - mae: 0.2807 - coeff_determination: 0.8009 - rmse: 1.4380 - val_loss: 0.1834 - val_mae: 0.2420 - val_coeff_determination: 0.8152 - val_rmse: 1.3924\n",
      "Epoch 219/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1981 - mae: 0.2826 - coeff_determination: 0.8001 - rmse: 1.4399 - val_loss: 0.1830 - val_mae: 0.2431 - val_coeff_determination: 0.8156 - val_rmse: 1.3925\n",
      "Epoch 220/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1982 - mae: 0.2819 - coeff_determination: 0.8000 - rmse: 1.4390 - val_loss: 0.1841 - val_mae: 0.2398 - val_coeff_determination: 0.8144 - val_rmse: 1.3924\n",
      "Epoch 221/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1984 - mae: 0.2822 - coeff_determination: 0.8000 - rmse: 1.4400 - val_loss: 0.1834 - val_mae: 0.2418 - val_coeff_determination: 0.8151 - val_rmse: 1.3928\n",
      "Epoch 222/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1970 - mae: 0.2829 - coeff_determination: 0.8018 - rmse: 1.4388 - val_loss: 0.1840 - val_mae: 0.2414 - val_coeff_determination: 0.8145 - val_rmse: 1.3936\n",
      "Epoch 223/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1992 - mae: 0.2831 - coeff_determination: 0.7993 - rmse: 1.4416 - val_loss: 0.1840 - val_mae: 0.2410 - val_coeff_determination: 0.8145 - val_rmse: 1.3933\n",
      "Epoch 224/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1990 - mae: 0.2819 - coeff_determination: 0.7993 - rmse: 1.4400 - val_loss: 0.1836 - val_mae: 0.2402 - val_coeff_determination: 0.8150 - val_rmse: 1.3919\n",
      "Epoch 225/550\n",
      "11759/11759 [==============================] - 1s 57us/step - loss: 0.1962 - mae: 0.2814 - coeff_determination: 0.8019 - rmse: 1.4368 - val_loss: 0.1837 - val_mae: 0.2419 - val_coeff_determination: 0.8148 - val_rmse: 1.3931\n",
      "Epoch 226/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1957 - mae: 0.2806 - coeff_determination: 0.8030 - rmse: 1.4359 - val_loss: 0.1837 - val_mae: 0.2409 - val_coeff_determination: 0.8148 - val_rmse: 1.3926\n",
      "Epoch 227/550\n",
      "11759/11759 [==============================] - 1s 60us/step - loss: 0.1986 - mae: 0.2819 - coeff_determination: 0.7997 - rmse: 1.4403 - val_loss: 0.1831 - val_mae: 0.2427 - val_coeff_determination: 0.8155 - val_rmse: 1.3926\n",
      "Epoch 228/550\n",
      "11759/11759 [==============================] - 1s 61us/step - loss: 0.1988 - mae: 0.2823 - coeff_determination: 0.7990 - rmse: 1.4400 - val_loss: 0.1834 - val_mae: 0.2415 - val_coeff_determination: 0.8151 - val_rmse: 1.3925\n",
      "Epoch 229/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1986 - mae: 0.2820 - coeff_determination: 0.7999 - rmse: 1.4402 - val_loss: 0.1835 - val_mae: 0.2398 - val_coeff_determination: 0.8151 - val_rmse: 1.3915\n",
      "Epoch 230/550\n",
      "11759/11759 [==============================] - 1s 62us/step - loss: 0.1942 - mae: 0.2807 - coeff_determination: 0.8039 - rmse: 1.4336 - val_loss: 0.1839 - val_mae: 0.2396 - val_coeff_determination: 0.8147 - val_rmse: 1.3922\n",
      "Epoch 231/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1959 - mae: 0.2808 - coeff_determination: 0.8029 - rmse: 1.4363 - val_loss: 0.1843 - val_mae: 0.2398 - val_coeff_determination: 0.8142 - val_rmse: 1.3930\n",
      "Epoch 232/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1974 - mae: 0.2798 - coeff_determination: 0.8005 - rmse: 1.4374 - val_loss: 0.1828 - val_mae: 0.2397 - val_coeff_determination: 0.8158 - val_rmse: 1.3904\n",
      "Epoch 233/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1968 - mae: 0.2795 - coeff_determination: 0.8016 - rmse: 1.4363 - val_loss: 0.1826 - val_mae: 0.2408 - val_coeff_determination: 0.8159 - val_rmse: 1.3911\n",
      "Epoch 234/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1973 - mae: 0.2818 - coeff_determination: 0.8011 - rmse: 1.4383 - val_loss: 0.1832 - val_mae: 0.2398 - val_coeff_determination: 0.8153 - val_rmse: 1.3912\n",
      "Epoch 235/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1953 - mae: 0.2803 - coeff_determination: 0.8034 - rmse: 1.4351 - val_loss: 0.1834 - val_mae: 0.2395 - val_coeff_determination: 0.8152 - val_rmse: 1.3915\n",
      "Epoch 236/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1966 - mae: 0.2786 - coeff_determination: 0.8021 - rmse: 1.4362 - val_loss: 0.1825 - val_mae: 0.2398 - val_coeff_determination: 0.8160 - val_rmse: 1.3901\n",
      "Epoch 237/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1940 - mae: 0.2785 - coeff_determination: 0.8046 - rmse: 1.4323 - val_loss: 0.1826 - val_mae: 0.2399 - val_coeff_determination: 0.8160 - val_rmse: 1.3904\n",
      "Epoch 238/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1955 - mae: 0.2805 - coeff_determination: 0.8028 - rmse: 1.4356 - val_loss: 0.1835 - val_mae: 0.2396 - val_coeff_determination: 0.8151 - val_rmse: 1.3918\n",
      "Epoch 239/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1970 - mae: 0.2818 - coeff_determination: 0.8008 - rmse: 1.4382 - val_loss: 0.1829 - val_mae: 0.2395 - val_coeff_determination: 0.8156 - val_rmse: 1.3906\n",
      "Epoch 240/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1936 - mae: 0.2785 - coeff_determination: 0.8051 - rmse: 1.4320 - val_loss: 0.1824 - val_mae: 0.2408 - val_coeff_determination: 0.8162 - val_rmse: 1.3904\n",
      "Epoch 241/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1960 - mae: 0.2788 - coeff_determination: 0.8030 - rmse: 1.4348 - val_loss: 0.1824 - val_mae: 0.2400 - val_coeff_determination: 0.8161 - val_rmse: 1.3900\n",
      "Epoch 242/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1946 - mae: 0.2794 - coeff_determination: 0.8039 - rmse: 1.4334 - val_loss: 0.1831 - val_mae: 0.2387 - val_coeff_determination: 0.8154 - val_rmse: 1.3904\n",
      "Epoch 243/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1948 - mae: 0.2787 - coeff_determination: 0.8033 - rmse: 1.4334 - val_loss: 0.1830 - val_mae: 0.2387 - val_coeff_determination: 0.8155 - val_rmse: 1.3903\n",
      "Epoch 244/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1953 - mae: 0.2774 - coeff_determination: 0.8031 - rmse: 1.4333 - val_loss: 0.1817 - val_mae: 0.2394 - val_coeff_determination: 0.8168 - val_rmse: 1.3886\n",
      "Epoch 245/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1918 - mae: 0.2769 - coeff_determination: 0.8067 - rmse: 1.4287 - val_loss: 0.1818 - val_mae: 0.2404 - val_coeff_determination: 0.8167 - val_rmse: 1.3895\n",
      "Epoch 246/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1950 - mae: 0.2783 - coeff_determination: 0.8034 - rmse: 1.4336 - val_loss: 0.1817 - val_mae: 0.2409 - val_coeff_determination: 0.8169 - val_rmse: 1.3898\n",
      "Epoch 247/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1965 - mae: 0.2803 - coeff_determination: 0.8022 - rmse: 1.4357 - val_loss: 0.1820 - val_mae: 0.2407 - val_coeff_determination: 0.8165 - val_rmse: 1.3902\n",
      "Epoch 248/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1954 - mae: 0.2795 - coeff_determination: 0.8024 - rmse: 1.4350 - val_loss: 0.1821 - val_mae: 0.2391 - val_coeff_determination: 0.8164 - val_rmse: 1.3893\n",
      "Epoch 249/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1922 - mae: 0.2764 - coeff_determination: 0.8065 - rmse: 1.4287 - val_loss: 0.1831 - val_mae: 0.2377 - val_coeff_determination: 0.8155 - val_rmse: 1.3900\n",
      "Epoch 250/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1964 - mae: 0.2776 - coeff_determination: 0.8020 - rmse: 1.4346 - val_loss: 0.1811 - val_mae: 0.2401 - val_coeff_determination: 0.8174 - val_rmse: 1.3884\n",
      "Epoch 251/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1948 - mae: 0.2793 - coeff_determination: 0.8032 - rmse: 1.4340 - val_loss: 0.1814 - val_mae: 0.2392 - val_coeff_determination: 0.8171 - val_rmse: 1.3881\n",
      "Epoch 252/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1946 - mae: 0.2787 - coeff_determination: 0.8034 - rmse: 1.4331 - val_loss: 0.1829 - val_mae: 0.2372 - val_coeff_determination: 0.8157 - val_rmse: 1.3893\n",
      "Epoch 253/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1934 - mae: 0.2760 - coeff_determination: 0.8050 - rmse: 1.4301 - val_loss: 0.1813 - val_mae: 0.2394 - val_coeff_determination: 0.8173 - val_rmse: 1.3881\n",
      "Epoch 254/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1934 - mae: 0.2765 - coeff_determination: 0.8046 - rmse: 1.4298 - val_loss: 0.1813 - val_mae: 0.2401 - val_coeff_determination: 0.8173 - val_rmse: 1.3885\n",
      "Epoch 255/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1936 - mae: 0.2781 - coeff_determination: 0.8045 - rmse: 1.4323 - val_loss: 0.1811 - val_mae: 0.2410 - val_coeff_determination: 0.8175 - val_rmse: 1.3888\n",
      "Epoch 256/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1918 - mae: 0.2770 - coeff_determination: 0.8062 - rmse: 1.4287 - val_loss: 0.1814 - val_mae: 0.2390 - val_coeff_determination: 0.8171 - val_rmse: 1.3881\n",
      "Epoch 257/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1937 - mae: 0.2774 - coeff_determination: 0.8046 - rmse: 1.4313 - val_loss: 0.1811 - val_mae: 0.2398 - val_coeff_determination: 0.8175 - val_rmse: 1.3881\n",
      "Epoch 258/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1918 - mae: 0.2751 - coeff_determination: 0.8066 - rmse: 1.4270 - val_loss: 0.1820 - val_mae: 0.2385 - val_coeff_determination: 0.8166 - val_rmse: 1.3888\n",
      "Epoch 259/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1923 - mae: 0.2754 - coeff_determination: 0.8058 - rmse: 1.4286 - val_loss: 0.1826 - val_mae: 0.2381 - val_coeff_determination: 0.8159 - val_rmse: 1.3898\n",
      "Epoch 260/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1903 - mae: 0.2746 - coeff_determination: 0.8080 - rmse: 1.4256 - val_loss: 0.1812 - val_mae: 0.2393 - val_coeff_determination: 0.8174 - val_rmse: 1.3880\n",
      "Epoch 261/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1924 - mae: 0.2763 - coeff_determination: 0.8059 - rmse: 1.4285 - val_loss: 0.1827 - val_mae: 0.2378 - val_coeff_determination: 0.8158 - val_rmse: 1.3899\n",
      "Epoch 262/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1948 - mae: 0.2764 - coeff_determination: 0.8036 - rmse: 1.4321 - val_loss: 0.1815 - val_mae: 0.2375 - val_coeff_determination: 0.8170 - val_rmse: 1.3874\n",
      "Epoch 263/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1926 - mae: 0.2747 - coeff_determination: 0.8055 - rmse: 1.4284 - val_loss: 0.1810 - val_mae: 0.2395 - val_coeff_determination: 0.8175 - val_rmse: 1.3881\n",
      "Epoch 264/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1943 - mae: 0.2786 - coeff_determination: 0.8040 - rmse: 1.4324 - val_loss: 0.1817 - val_mae: 0.2383 - val_coeff_determination: 0.8168 - val_rmse: 1.3886\n",
      "Epoch 265/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1922 - mae: 0.2755 - coeff_determination: 0.8067 - rmse: 1.4282 - val_loss: 0.1812 - val_mae: 0.2388 - val_coeff_determination: 0.8173 - val_rmse: 1.3880\n",
      "Epoch 266/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1910 - mae: 0.2746 - coeff_determination: 0.8076 - rmse: 1.4266 - val_loss: 0.1811 - val_mae: 0.2385 - val_coeff_determination: 0.8175 - val_rmse: 1.3878\n",
      "Epoch 267/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1948 - mae: 0.2767 - coeff_determination: 0.8034 - rmse: 1.4327 - val_loss: 0.1812 - val_mae: 0.2385 - val_coeff_determination: 0.8174 - val_rmse: 1.3875\n",
      "Epoch 268/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1911 - mae: 0.2759 - coeff_determination: 0.8071 - rmse: 1.4271 - val_loss: 0.1824 - val_mae: 0.2369 - val_coeff_determination: 0.8161 - val_rmse: 1.3888\n",
      "Epoch 269/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1915 - mae: 0.2738 - coeff_determination: 0.8068 - rmse: 1.4270 - val_loss: 0.1805 - val_mae: 0.2394 - val_coeff_determination: 0.8181 - val_rmse: 1.3872\n",
      "Epoch 270/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1895 - mae: 0.2741 - coeff_determination: 0.8085 - rmse: 1.4244 - val_loss: 0.1805 - val_mae: 0.2392 - val_coeff_determination: 0.8180 - val_rmse: 1.3870\n",
      "Epoch 271/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1910 - mae: 0.2745 - coeff_determination: 0.8073 - rmse: 1.4256 - val_loss: 0.1817 - val_mae: 0.2381 - val_coeff_determination: 0.8168 - val_rmse: 1.3886\n",
      "Epoch 272/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1917 - mae: 0.2742 - coeff_determination: 0.8069 - rmse: 1.4269 - val_loss: 0.1806 - val_mae: 0.2402 - val_coeff_determination: 0.8180 - val_rmse: 1.3883\n",
      "Epoch 273/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1898 - mae: 0.2735 - coeff_determination: 0.8080 - rmse: 1.4243 - val_loss: 0.1825 - val_mae: 0.2384 - val_coeff_determination: 0.8160 - val_rmse: 1.3903\n",
      "Epoch 274/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1892 - mae: 0.2725 - coeff_determination: 0.8088 - rmse: 1.4228 - val_loss: 0.1813 - val_mae: 0.2384 - val_coeff_determination: 0.8172 - val_rmse: 1.3881\n",
      "Epoch 275/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1911 - mae: 0.2737 - coeff_determination: 0.8075 - rmse: 1.4259 - val_loss: 0.1814 - val_mae: 0.2382 - val_coeff_determination: 0.8171 - val_rmse: 1.3883\n",
      "Epoch 276/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1931 - mae: 0.2753 - coeff_determination: 0.8053 - rmse: 1.4302 - val_loss: 0.1809 - val_mae: 0.2390 - val_coeff_determination: 0.8177 - val_rmse: 1.3876\n",
      "Epoch 277/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1902 - mae: 0.2729 - coeff_determination: 0.8077 - rmse: 1.4239 - val_loss: 0.1799 - val_mae: 0.2397 - val_coeff_determination: 0.8186 - val_rmse: 1.3864\n",
      "Epoch 278/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1890 - mae: 0.2741 - coeff_determination: 0.8089 - rmse: 1.4231 - val_loss: 0.1800 - val_mae: 0.2392 - val_coeff_determination: 0.8185 - val_rmse: 1.3866\n",
      "Epoch 279/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1887 - mae: 0.2726 - coeff_determination: 0.8098 - rmse: 1.4220 - val_loss: 0.1804 - val_mae: 0.2381 - val_coeff_determination: 0.8182 - val_rmse: 1.3865\n",
      "Epoch 280/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1884 - mae: 0.2704 - coeff_determination: 0.8099 - rmse: 1.4208 - val_loss: 0.1801 - val_mae: 0.2393 - val_coeff_determination: 0.8184 - val_rmse: 1.3872\n",
      "Epoch 281/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1890 - mae: 0.2720 - coeff_determination: 0.8096 - rmse: 1.4216 - val_loss: 0.1801 - val_mae: 0.2403 - val_coeff_determination: 0.8185 - val_rmse: 1.3876\n",
      "Epoch 282/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1872 - mae: 0.2701 - coeff_determination: 0.8112 - rmse: 1.4190 - val_loss: 0.1801 - val_mae: 0.2402 - val_coeff_determination: 0.8184 - val_rmse: 1.3876\n",
      "Epoch 283/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1894 - mae: 0.2734 - coeff_determination: 0.8084 - rmse: 1.4232 - val_loss: 0.1807 - val_mae: 0.2380 - val_coeff_determination: 0.8179 - val_rmse: 1.3872\n",
      "Epoch 284/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1880 - mae: 0.2717 - coeff_determination: 0.8104 - rmse: 1.4209 - val_loss: 0.1801 - val_mae: 0.2398 - val_coeff_determination: 0.8184 - val_rmse: 1.3874\n",
      "Epoch 285/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1883 - mae: 0.2716 - coeff_determination: 0.8100 - rmse: 1.4209 - val_loss: 0.1799 - val_mae: 0.2402 - val_coeff_determination: 0.8186 - val_rmse: 1.3874\n",
      "Epoch 286/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1888 - mae: 0.2717 - coeff_determination: 0.8093 - rmse: 1.4208 - val_loss: 0.1802 - val_mae: 0.2379 - val_coeff_determination: 0.8183 - val_rmse: 1.3866\n",
      "Epoch 287/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1869 - mae: 0.2701 - coeff_determination: 0.8116 - rmse: 1.4181 - val_loss: 0.1808 - val_mae: 0.2380 - val_coeff_determination: 0.8178 - val_rmse: 1.3875\n",
      "Epoch 288/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1876 - mae: 0.2696 - coeff_determination: 0.8103 - rmse: 1.4189 - val_loss: 0.1794 - val_mae: 0.2392 - val_coeff_determination: 0.8191 - val_rmse: 1.3861\n",
      "Epoch 289/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1875 - mae: 0.2715 - coeff_determination: 0.8106 - rmse: 1.4197 - val_loss: 0.1804 - val_mae: 0.2377 - val_coeff_determination: 0.8182 - val_rmse: 1.3866\n",
      "Epoch 290/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1897 - mae: 0.2715 - coeff_determination: 0.8090 - rmse: 1.4232 - val_loss: 0.1800 - val_mae: 0.2384 - val_coeff_determination: 0.8185 - val_rmse: 1.3867\n",
      "Epoch 291/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1883 - mae: 0.2717 - coeff_determination: 0.8095 - rmse: 1.4213 - val_loss: 0.1796 - val_mae: 0.2402 - val_coeff_determination: 0.8190 - val_rmse: 1.3867\n",
      "Epoch 292/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1875 - mae: 0.2711 - coeff_determination: 0.8109 - rmse: 1.4201 - val_loss: 0.1794 - val_mae: 0.2407 - val_coeff_determination: 0.8192 - val_rmse: 1.3869\n",
      "Epoch 293/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1891 - mae: 0.2726 - coeff_determination: 0.8090 - rmse: 1.4224 - val_loss: 0.1791 - val_mae: 0.2400 - val_coeff_determination: 0.8195 - val_rmse: 1.3863\n",
      "Epoch 294/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1889 - mae: 0.2699 - coeff_determination: 0.8099 - rmse: 1.4213 - val_loss: 0.1792 - val_mae: 0.2395 - val_coeff_determination: 0.8194 - val_rmse: 1.3862\n",
      "Epoch 295/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1886 - mae: 0.2714 - coeff_determination: 0.8095 - rmse: 1.4207 - val_loss: 0.1789 - val_mae: 0.2392 - val_coeff_determination: 0.8196 - val_rmse: 1.3853\n",
      "Epoch 296/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1882 - mae: 0.2704 - coeff_determination: 0.8103 - rmse: 1.4199 - val_loss: 0.1788 - val_mae: 0.2397 - val_coeff_determination: 0.8197 - val_rmse: 1.3859\n",
      "Epoch 297/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1891 - mae: 0.2723 - coeff_determination: 0.8092 - rmse: 1.4228 - val_loss: 0.1791 - val_mae: 0.2388 - val_coeff_determination: 0.8194 - val_rmse: 1.3859\n",
      "Epoch 298/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1870 - mae: 0.2713 - coeff_determination: 0.8114 - rmse: 1.4188 - val_loss: 0.1798 - val_mae: 0.2383 - val_coeff_determination: 0.8187 - val_rmse: 1.3867\n",
      "Epoch 299/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1875 - mae: 0.2705 - coeff_determination: 0.8106 - rmse: 1.4195 - val_loss: 0.1789 - val_mae: 0.2388 - val_coeff_determination: 0.8197 - val_rmse: 1.3851\n",
      "Epoch 300/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1874 - mae: 0.2713 - coeff_determination: 0.8109 - rmse: 1.4200 - val_loss: 0.1790 - val_mae: 0.2391 - val_coeff_determination: 0.8196 - val_rmse: 1.3857\n",
      "Epoch 301/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1866 - mae: 0.2699 - coeff_determination: 0.8121 - rmse: 1.4182 - val_loss: 0.1794 - val_mae: 0.2380 - val_coeff_determination: 0.8191 - val_rmse: 1.3858\n",
      "Epoch 302/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1901 - mae: 0.2709 - coeff_determination: 0.8085 - rmse: 1.4244 - val_loss: 0.1787 - val_mae: 0.2402 - val_coeff_determination: 0.8199 - val_rmse: 1.3860\n",
      "Epoch 303/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1888 - mae: 0.2713 - coeff_determination: 0.8093 - rmse: 1.4215 - val_loss: 0.1787 - val_mae: 0.2380 - val_coeff_determination: 0.8198 - val_rmse: 1.3845\n",
      "Epoch 304/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1877 - mae: 0.2699 - coeff_determination: 0.8107 - rmse: 1.4191 - val_loss: 0.1796 - val_mae: 0.2373 - val_coeff_determination: 0.8190 - val_rmse: 1.3856\n",
      "Epoch 305/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1873 - mae: 0.2688 - coeff_determination: 0.8108 - rmse: 1.4184 - val_loss: 0.1786 - val_mae: 0.2387 - val_coeff_determination: 0.8199 - val_rmse: 1.3851\n",
      "Epoch 306/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1858 - mae: 0.2694 - coeff_determination: 0.8131 - rmse: 1.4164 - val_loss: 0.1796 - val_mae: 0.2380 - val_coeff_determination: 0.8190 - val_rmse: 1.3863\n",
      "Epoch 307/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1858 - mae: 0.2686 - coeff_determination: 0.8121 - rmse: 1.4160 - val_loss: 0.1788 - val_mae: 0.2392 - val_coeff_determination: 0.8198 - val_rmse: 1.3854\n",
      "Epoch 308/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1884 - mae: 0.2701 - coeff_determination: 0.8101 - rmse: 1.4202 - val_loss: 0.1795 - val_mae: 0.2385 - val_coeff_determination: 0.8191 - val_rmse: 1.3864\n",
      "Epoch 309/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1839 - mae: 0.2678 - coeff_determination: 0.8150 - rmse: 1.4139 - val_loss: 0.1787 - val_mae: 0.2381 - val_coeff_determination: 0.8199 - val_rmse: 1.3847\n",
      "Epoch 310/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1890 - mae: 0.2708 - coeff_determination: 0.8093 - rmse: 1.4212 - val_loss: 0.1789 - val_mae: 0.2386 - val_coeff_determination: 0.8196 - val_rmse: 1.3856\n",
      "Epoch 311/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1856 - mae: 0.2682 - coeff_determination: 0.8125 - rmse: 1.4160 - val_loss: 0.1788 - val_mae: 0.2373 - val_coeff_determination: 0.8197 - val_rmse: 1.3845\n",
      "Epoch 312/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1868 - mae: 0.2700 - coeff_determination: 0.8116 - rmse: 1.4181 - val_loss: 0.1782 - val_mae: 0.2382 - val_coeff_determination: 0.8203 - val_rmse: 1.3841\n",
      "Epoch 313/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1867 - mae: 0.2700 - coeff_determination: 0.8119 - rmse: 1.4176 - val_loss: 0.1797 - val_mae: 0.2367 - val_coeff_determination: 0.8189 - val_rmse: 1.3855\n",
      "Epoch 314/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1858 - mae: 0.2665 - coeff_determination: 0.8129 - rmse: 1.4147 - val_loss: 0.1780 - val_mae: 0.2380 - val_coeff_determination: 0.8206 - val_rmse: 1.3835\n",
      "Epoch 315/550\n",
      "11759/11759 [==============================] - 1s 61us/step - loss: 0.1862 - mae: 0.2693 - coeff_determination: 0.8117 - rmse: 1.4168 - val_loss: 0.1794 - val_mae: 0.2373 - val_coeff_determination: 0.8191 - val_rmse: 1.3858\n",
      "Epoch 316/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1863 - mae: 0.2685 - coeff_determination: 0.8121 - rmse: 1.4167 - val_loss: 0.1787 - val_mae: 0.2382 - val_coeff_determination: 0.8198 - val_rmse: 1.3851\n",
      "Epoch 317/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1864 - mae: 0.2671 - coeff_determination: 0.8121 - rmse: 1.4159 - val_loss: 0.1781 - val_mae: 0.2403 - val_coeff_determination: 0.8204 - val_rmse: 1.3855\n",
      "Epoch 318/550\n",
      "11759/11759 [==============================] - 1s 62us/step - loss: 0.1844 - mae: 0.2668 - coeff_determination: 0.8138 - rmse: 1.4129 - val_loss: 0.1789 - val_mae: 0.2389 - val_coeff_determination: 0.8197 - val_rmse: 1.3859\n",
      "Epoch 319/550\n",
      "11759/11759 [==============================] - 1s 62us/step - loss: 0.1876 - mae: 0.2693 - coeff_determination: 0.8107 - rmse: 1.4193 - val_loss: 0.1784 - val_mae: 0.2393 - val_coeff_determination: 0.8201 - val_rmse: 1.3854\n",
      "Epoch 320/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1852 - mae: 0.2676 - coeff_determination: 0.8135 - rmse: 1.4150 - val_loss: 0.1793 - val_mae: 0.2377 - val_coeff_determination: 0.8192 - val_rmse: 1.3860\n",
      "Epoch 321/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1842 - mae: 0.2655 - coeff_determination: 0.8139 - rmse: 1.4125 - val_loss: 0.1783 - val_mae: 0.2371 - val_coeff_determination: 0.8203 - val_rmse: 1.3839\n",
      "Epoch 322/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1852 - mae: 0.2672 - coeff_determination: 0.8138 - rmse: 1.4144 - val_loss: 0.1779 - val_mae: 0.2381 - val_coeff_determination: 0.8207 - val_rmse: 1.3838\n",
      "Epoch 323/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1828 - mae: 0.2662 - coeff_determination: 0.8152 - rmse: 1.4108 - val_loss: 0.1781 - val_mae: 0.2375 - val_coeff_determination: 0.8204 - val_rmse: 1.3839\n",
      "Epoch 324/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1841 - mae: 0.2655 - coeff_determination: 0.8136 - rmse: 1.4124 - val_loss: 0.1773 - val_mae: 0.2379 - val_coeff_determination: 0.8213 - val_rmse: 1.3827\n",
      "Epoch 325/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1859 - mae: 0.2678 - coeff_determination: 0.8121 - rmse: 1.4153 - val_loss: 0.1772 - val_mae: 0.2396 - val_coeff_determination: 0.8213 - val_rmse: 1.3840\n",
      "Epoch 326/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1851 - mae: 0.2683 - coeff_determination: 0.8133 - rmse: 1.4150 - val_loss: 0.1774 - val_mae: 0.2388 - val_coeff_determination: 0.8212 - val_rmse: 1.3838\n",
      "Epoch 327/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1848 - mae: 0.2675 - coeff_determination: 0.8131 - rmse: 1.4143 - val_loss: 0.1776 - val_mae: 0.2384 - val_coeff_determination: 0.8210 - val_rmse: 1.3837\n",
      "Epoch 328/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1852 - mae: 0.2683 - coeff_determination: 0.8129 - rmse: 1.4150 - val_loss: 0.1770 - val_mae: 0.2394 - val_coeff_determination: 0.8215 - val_rmse: 1.3832\n",
      "Epoch 329/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1821 - mae: 0.2661 - coeff_determination: 0.8163 - rmse: 1.4101 - val_loss: 0.1793 - val_mae: 0.2375 - val_coeff_determination: 0.8193 - val_rmse: 1.3861\n",
      "Epoch 330/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1849 - mae: 0.2655 - coeff_determination: 0.8141 - rmse: 1.4132 - val_loss: 0.1767 - val_mae: 0.2410 - val_coeff_determination: 0.8219 - val_rmse: 1.3841\n",
      "Epoch 331/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1854 - mae: 0.2684 - coeff_determination: 0.8131 - rmse: 1.4154 - val_loss: 0.1782 - val_mae: 0.2384 - val_coeff_determination: 0.8203 - val_rmse: 1.3852\n",
      "Epoch 332/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1837 - mae: 0.2657 - coeff_determination: 0.8149 - rmse: 1.4120 - val_loss: 0.1782 - val_mae: 0.2387 - val_coeff_determination: 0.8203 - val_rmse: 1.3855\n",
      "Epoch 333/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1840 - mae: 0.2665 - coeff_determination: 0.8141 - rmse: 1.4126 - val_loss: 0.1786 - val_mae: 0.2370 - val_coeff_determination: 0.8200 - val_rmse: 1.3848\n",
      "Epoch 334/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1839 - mae: 0.2661 - coeff_determination: 0.8144 - rmse: 1.4122 - val_loss: 0.1773 - val_mae: 0.2376 - val_coeff_determination: 0.8212 - val_rmse: 1.3828\n",
      "Epoch 335/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1830 - mae: 0.2651 - coeff_determination: 0.8162 - rmse: 1.4109 - val_loss: 0.1780 - val_mae: 0.2386 - val_coeff_determination: 0.8206 - val_rmse: 1.3847\n",
      "Epoch 336/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1849 - mae: 0.2662 - coeff_determination: 0.8139 - rmse: 1.4130 - val_loss: 0.1769 - val_mae: 0.2401 - val_coeff_determination: 0.8217 - val_rmse: 1.3835\n",
      "Epoch 337/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1812 - mae: 0.2644 - coeff_determination: 0.8172 - rmse: 1.4076 - val_loss: 0.1792 - val_mae: 0.2371 - val_coeff_determination: 0.8193 - val_rmse: 1.3861\n",
      "Epoch 338/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1849 - mae: 0.2652 - coeff_determination: 0.8132 - rmse: 1.4129 - val_loss: 0.1766 - val_mae: 0.2397 - val_coeff_determination: 0.8220 - val_rmse: 1.3830\n",
      "Epoch 339/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1838 - mae: 0.2662 - coeff_determination: 0.8143 - rmse: 1.4121 - val_loss: 0.1776 - val_mae: 0.2385 - val_coeff_determination: 0.8210 - val_rmse: 1.3844\n",
      "Epoch 340/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1830 - mae: 0.2643 - coeff_determination: 0.8158 - rmse: 1.4110 - val_loss: 0.1782 - val_mae: 0.2380 - val_coeff_determination: 0.8203 - val_rmse: 1.3853\n",
      "Epoch 341/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1822 - mae: 0.2643 - coeff_determination: 0.8159 - rmse: 1.4088 - val_loss: 0.1781 - val_mae: 0.2372 - val_coeff_determination: 0.8205 - val_rmse: 1.3845\n",
      "Epoch 342/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1838 - mae: 0.2644 - coeff_determination: 0.8141 - rmse: 1.4108 - val_loss: 0.1763 - val_mae: 0.2399 - val_coeff_determination: 0.8223 - val_rmse: 1.3831\n",
      "Epoch 343/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1819 - mae: 0.2646 - coeff_determination: 0.8164 - rmse: 1.4091 - val_loss: 0.1769 - val_mae: 0.2379 - val_coeff_determination: 0.8216 - val_rmse: 1.3828\n",
      "Epoch 344/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1836 - mae: 0.2656 - coeff_determination: 0.8147 - rmse: 1.4118 - val_loss: 0.1777 - val_mae: 0.2371 - val_coeff_determination: 0.8208 - val_rmse: 1.3839\n",
      "Epoch 345/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1828 - mae: 0.2637 - coeff_determination: 0.8153 - rmse: 1.4094 - val_loss: 0.1780 - val_mae: 0.2371 - val_coeff_determination: 0.8206 - val_rmse: 1.3844\n",
      "Epoch 346/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1832 - mae: 0.2656 - coeff_determination: 0.8148 - rmse: 1.4113 - val_loss: 0.1769 - val_mae: 0.2391 - val_coeff_determination: 0.8217 - val_rmse: 1.3840\n",
      "Epoch 347/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1824 - mae: 0.2641 - coeff_determination: 0.8163 - rmse: 1.4091 - val_loss: 0.1771 - val_mae: 0.2378 - val_coeff_determination: 0.8214 - val_rmse: 1.3836\n",
      "Epoch 348/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1819 - mae: 0.2636 - coeff_determination: 0.8168 - rmse: 1.4080 - val_loss: 0.1772 - val_mae: 0.2374 - val_coeff_determination: 0.8213 - val_rmse: 1.3832\n",
      "Epoch 349/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1820 - mae: 0.2628 - coeff_determination: 0.8164 - rmse: 1.4080 - val_loss: 0.1765 - val_mae: 0.2375 - val_coeff_determination: 0.8221 - val_rmse: 1.3821\n",
      "Epoch 350/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1838 - mae: 0.2654 - coeff_determination: 0.8141 - rmse: 1.4119 - val_loss: 0.1767 - val_mae: 0.2387 - val_coeff_determination: 0.8219 - val_rmse: 1.3834\n",
      "Epoch 351/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1825 - mae: 0.2637 - coeff_determination: 0.8158 - rmse: 1.4094 - val_loss: 0.1764 - val_mae: 0.2377 - val_coeff_determination: 0.8221 - val_rmse: 1.3824\n",
      "Epoch 352/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1814 - mae: 0.2625 - coeff_determination: 0.8166 - rmse: 1.4070 - val_loss: 0.1756 - val_mae: 0.2394 - val_coeff_determination: 0.8230 - val_rmse: 1.3815\n",
      "Epoch 353/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1832 - mae: 0.2654 - coeff_determination: 0.8155 - rmse: 1.4114 - val_loss: 0.1770 - val_mae: 0.2378 - val_coeff_determination: 0.8216 - val_rmse: 1.3834\n",
      "Epoch 354/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1841 - mae: 0.2662 - coeff_determination: 0.8138 - rmse: 1.4123 - val_loss: 0.1767 - val_mae: 0.2375 - val_coeff_determination: 0.8218 - val_rmse: 1.3827\n",
      "Epoch 355/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1811 - mae: 0.2623 - coeff_determination: 0.8175 - rmse: 1.4061 - val_loss: 0.1759 - val_mae: 0.2393 - val_coeff_determination: 0.8227 - val_rmse: 1.3825\n",
      "Epoch 356/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1800 - mae: 0.2633 - coeff_determination: 0.8185 - rmse: 1.4053 - val_loss: 0.1777 - val_mae: 0.2369 - val_coeff_determination: 0.8208 - val_rmse: 1.3842\n",
      "Epoch 357/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1823 - mae: 0.2642 - coeff_determination: 0.8163 - rmse: 1.4095 - val_loss: 0.1760 - val_mae: 0.2389 - val_coeff_determination: 0.8226 - val_rmse: 1.3824\n",
      "Epoch 358/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1809 - mae: 0.2648 - coeff_determination: 0.8174 - rmse: 1.4074 - val_loss: 0.1768 - val_mae: 0.2372 - val_coeff_determination: 0.8218 - val_rmse: 1.3830\n",
      "Epoch 359/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1824 - mae: 0.2632 - coeff_determination: 0.8161 - rmse: 1.4084 - val_loss: 0.1768 - val_mae: 0.2367 - val_coeff_determination: 0.8218 - val_rmse: 1.3824\n",
      "Epoch 360/550\n",
      "11759/11759 [==============================] - 1s 62us/step - loss: 0.1835 - mae: 0.2650 - coeff_determination: 0.8150 - rmse: 1.4116 - val_loss: 0.1768 - val_mae: 0.2369 - val_coeff_determination: 0.8217 - val_rmse: 1.3828\n",
      "Epoch 361/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1803 - mae: 0.2625 - coeff_determination: 0.8183 - rmse: 1.4064 - val_loss: 0.1769 - val_mae: 0.2372 - val_coeff_determination: 0.8216 - val_rmse: 1.3830\n",
      "Epoch 362/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1825 - mae: 0.2641 - coeff_determination: 0.8162 - rmse: 1.4090 - val_loss: 0.1773 - val_mae: 0.2370 - val_coeff_determination: 0.8213 - val_rmse: 1.3836\n",
      "Epoch 363/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1797 - mae: 0.2625 - coeff_determination: 0.8182 - rmse: 1.4045 - val_loss: 0.1755 - val_mae: 0.2387 - val_coeff_determination: 0.8230 - val_rmse: 1.3818\n",
      "Epoch 364/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1809 - mae: 0.2625 - coeff_determination: 0.8180 - rmse: 1.4058 - val_loss: 0.1769 - val_mae: 0.2378 - val_coeff_determination: 0.8216 - val_rmse: 1.3840\n",
      "Epoch 365/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1803 - mae: 0.2606 - coeff_determination: 0.8175 - rmse: 1.4045 - val_loss: 0.1755 - val_mae: 0.2388 - val_coeff_determination: 0.8230 - val_rmse: 1.3821\n",
      "Epoch 366/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1817 - mae: 0.2632 - coeff_determination: 0.8165 - rmse: 1.4077 - val_loss: 0.1765 - val_mae: 0.2375 - val_coeff_determination: 0.8220 - val_rmse: 1.3831\n",
      "Epoch 367/550\n",
      "11759/11759 [==============================] - 1s 71us/step - loss: 0.1818 - mae: 0.2639 - coeff_determination: 0.8165 - rmse: 1.4092 - val_loss: 0.1772 - val_mae: 0.2370 - val_coeff_determination: 0.8213 - val_rmse: 1.3839\n",
      "Epoch 368/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1803 - mae: 0.2619 - coeff_determination: 0.8180 - rmse: 1.4048 - val_loss: 0.1752 - val_mae: 0.2387 - val_coeff_determination: 0.8234 - val_rmse: 1.3816\n",
      "Epoch 369/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1803 - mae: 0.2636 - coeff_determination: 0.8179 - rmse: 1.4062 - val_loss: 0.1753 - val_mae: 0.2382 - val_coeff_determination: 0.8233 - val_rmse: 1.3812\n",
      "Epoch 370/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1804 - mae: 0.2625 - coeff_determination: 0.8173 - rmse: 1.4058 - val_loss: 0.1751 - val_mae: 0.2388 - val_coeff_determination: 0.8235 - val_rmse: 1.3812\n",
      "Epoch 371/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1786 - mae: 0.2604 - coeff_determination: 0.8202 - rmse: 1.4014 - val_loss: 0.1770 - val_mae: 0.2377 - val_coeff_determination: 0.8215 - val_rmse: 1.3842\n",
      "Epoch 372/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1796 - mae: 0.2608 - coeff_determination: 0.8187 - rmse: 1.4038 - val_loss: 0.1760 - val_mae: 0.2379 - val_coeff_determination: 0.8226 - val_rmse: 1.3826\n",
      "Epoch 373/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1836 - mae: 0.2641 - coeff_determination: 0.8145 - rmse: 1.4101 - val_loss: 0.1767 - val_mae: 0.2364 - val_coeff_determination: 0.8219 - val_rmse: 1.3829\n",
      "Epoch 374/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1785 - mae: 0.2607 - coeff_determination: 0.8197 - rmse: 1.4022 - val_loss: 0.1756 - val_mae: 0.2374 - val_coeff_determination: 0.8230 - val_rmse: 1.3816\n",
      "Epoch 375/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1787 - mae: 0.2606 - coeff_determination: 0.8195 - rmse: 1.4029 - val_loss: 0.1748 - val_mae: 0.2378 - val_coeff_determination: 0.8238 - val_rmse: 1.3804\n",
      "Epoch 376/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1770 - mae: 0.2601 - coeff_determination: 0.8213 - rmse: 1.3997 - val_loss: 0.1772 - val_mae: 0.2368 - val_coeff_determination: 0.8213 - val_rmse: 1.3839\n",
      "Epoch 377/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1798 - mae: 0.2619 - coeff_determination: 0.8188 - rmse: 1.4043 - val_loss: 0.1748 - val_mae: 0.2391 - val_coeff_determination: 0.8238 - val_rmse: 1.3810\n",
      "Epoch 378/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1800 - mae: 0.2618 - coeff_determination: 0.8189 - rmse: 1.4044 - val_loss: 0.1748 - val_mae: 0.2391 - val_coeff_determination: 0.8238 - val_rmse: 1.3814\n",
      "Epoch 379/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1803 - mae: 0.2618 - coeff_determination: 0.8177 - rmse: 1.4048 - val_loss: 0.1750 - val_mae: 0.2390 - val_coeff_determination: 0.8236 - val_rmse: 1.3814\n",
      "Epoch 380/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1800 - mae: 0.2618 - coeff_determination: 0.8191 - rmse: 1.4048 - val_loss: 0.1751 - val_mae: 0.2379 - val_coeff_determination: 0.8235 - val_rmse: 1.3812\n",
      "Epoch 381/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1784 - mae: 0.2611 - coeff_determination: 0.8202 - rmse: 1.4022 - val_loss: 0.1754 - val_mae: 0.2387 - val_coeff_determination: 0.8231 - val_rmse: 1.3822\n",
      "Epoch 382/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1779 - mae: 0.2598 - coeff_determination: 0.8207 - rmse: 1.4003 - val_loss: 0.1759 - val_mae: 0.2374 - val_coeff_determination: 0.8227 - val_rmse: 1.3823\n",
      "Epoch 383/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1780 - mae: 0.2600 - coeff_determination: 0.8207 - rmse: 1.4016 - val_loss: 0.1754 - val_mae: 0.2377 - val_coeff_determination: 0.8232 - val_rmse: 1.3814\n",
      "Epoch 384/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1782 - mae: 0.2609 - coeff_determination: 0.8206 - rmse: 1.4022 - val_loss: 0.1753 - val_mae: 0.2384 - val_coeff_determination: 0.8233 - val_rmse: 1.3819\n",
      "Epoch 385/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1784 - mae: 0.2602 - coeff_determination: 0.8199 - rmse: 1.4020 - val_loss: 0.1749 - val_mae: 0.2393 - val_coeff_determination: 0.8237 - val_rmse: 1.3817\n",
      "Epoch 386/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1803 - mae: 0.2619 - coeff_determination: 0.8183 - rmse: 1.4048 - val_loss: 0.1759 - val_mae: 0.2374 - val_coeff_determination: 0.8227 - val_rmse: 1.3823\n",
      "Epoch 387/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1790 - mae: 0.2596 - coeff_determination: 0.8198 - rmse: 1.4028 - val_loss: 0.1752 - val_mae: 0.2379 - val_coeff_determination: 0.8234 - val_rmse: 1.3815\n",
      "Epoch 388/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1806 - mae: 0.2622 - coeff_determination: 0.8177 - rmse: 1.4067 - val_loss: 0.1757 - val_mae: 0.2379 - val_coeff_determination: 0.8228 - val_rmse: 1.3827\n",
      "Epoch 389/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1781 - mae: 0.2613 - coeff_determination: 0.8202 - rmse: 1.4025 - val_loss: 0.1771 - val_mae: 0.2364 - val_coeff_determination: 0.8214 - val_rmse: 1.3837\n",
      "Epoch 390/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1777 - mae: 0.2587 - coeff_determination: 0.8206 - rmse: 1.4009 - val_loss: 0.1758 - val_mae: 0.2376 - val_coeff_determination: 0.8227 - val_rmse: 1.3826\n",
      "Epoch 391/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1789 - mae: 0.2596 - coeff_determination: 0.8195 - rmse: 1.4024 - val_loss: 0.1743 - val_mae: 0.2396 - val_coeff_determination: 0.8243 - val_rmse: 1.3808\n",
      "Epoch 392/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1772 - mae: 0.2604 - coeff_determination: 0.8215 - rmse: 1.4000 - val_loss: 0.1757 - val_mae: 0.2382 - val_coeff_determination: 0.8229 - val_rmse: 1.3826\n",
      "Epoch 393/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1775 - mae: 0.2604 - coeff_determination: 0.8204 - rmse: 1.4006 - val_loss: 0.1778 - val_mae: 0.2360 - val_coeff_determination: 0.8208 - val_rmse: 1.3846\n",
      "Epoch 394/550\n",
      "11759/11759 [==============================] - 1s 70us/step - loss: 0.1797 - mae: 0.2606 - coeff_determination: 0.8190 - rmse: 1.4040 - val_loss: 0.1761 - val_mae: 0.2365 - val_coeff_determination: 0.8224 - val_rmse: 1.3822\n",
      "Epoch 395/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1782 - mae: 0.2598 - coeff_determination: 0.8201 - rmse: 1.4017 - val_loss: 0.1748 - val_mae: 0.2379 - val_coeff_determination: 0.8237 - val_rmse: 1.3809\n",
      "Epoch 396/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1797 - mae: 0.2618 - coeff_determination: 0.8184 - rmse: 1.4041 - val_loss: 0.1749 - val_mae: 0.2385 - val_coeff_determination: 0.8237 - val_rmse: 1.3814\n",
      "Epoch 397/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1794 - mae: 0.2615 - coeff_determination: 0.8191 - rmse: 1.4038 - val_loss: 0.1758 - val_mae: 0.2359 - val_coeff_determination: 0.8227 - val_rmse: 1.3812\n",
      "Epoch 398/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1793 - mae: 0.2606 - coeff_determination: 0.8196 - rmse: 1.4037 - val_loss: 0.1749 - val_mae: 0.2377 - val_coeff_determination: 0.8237 - val_rmse: 1.3808\n",
      "Epoch 399/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1784 - mae: 0.2607 - coeff_determination: 0.8198 - rmse: 1.4023 - val_loss: 0.1775 - val_mae: 0.2364 - val_coeff_determination: 0.8210 - val_rmse: 1.3846\n",
      "Epoch 400/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1787 - mae: 0.2597 - coeff_determination: 0.8195 - rmse: 1.4023 - val_loss: 0.1759 - val_mae: 0.2381 - val_coeff_determination: 0.8226 - val_rmse: 1.3832\n",
      "Epoch 401/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1775 - mae: 0.2595 - coeff_determination: 0.8210 - rmse: 1.4008 - val_loss: 0.1759 - val_mae: 0.2370 - val_coeff_determination: 0.8226 - val_rmse: 1.3823\n",
      "Epoch 402/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1780 - mae: 0.2577 - coeff_determination: 0.8203 - rmse: 1.4005 - val_loss: 0.1753 - val_mae: 0.2373 - val_coeff_determination: 0.8233 - val_rmse: 1.3815\n",
      "Epoch 403/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1780 - mae: 0.2590 - coeff_determination: 0.8208 - rmse: 1.4005 - val_loss: 0.1758 - val_mae: 0.2360 - val_coeff_determination: 0.8227 - val_rmse: 1.3816\n",
      "Epoch 404/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1795 - mae: 0.2590 - coeff_determination: 0.8184 - rmse: 1.4027 - val_loss: 0.1746 - val_mae: 0.2378 - val_coeff_determination: 0.8240 - val_rmse: 1.3808\n",
      "Epoch 405/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1763 - mae: 0.2582 - coeff_determination: 0.8220 - rmse: 1.3977 - val_loss: 0.1744 - val_mae: 0.2373 - val_coeff_determination: 0.8242 - val_rmse: 1.3801\n",
      "Epoch 406/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1760 - mae: 0.2582 - coeff_determination: 0.8227 - rmse: 1.3986 - val_loss: 0.1742 - val_mae: 0.2375 - val_coeff_determination: 0.8244 - val_rmse: 1.3801\n",
      "Epoch 407/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1775 - mae: 0.2584 - coeff_determination: 0.8210 - rmse: 1.3992 - val_loss: 0.1741 - val_mae: 0.2375 - val_coeff_determination: 0.8244 - val_rmse: 1.3797\n",
      "Epoch 408/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1770 - mae: 0.2578 - coeff_determination: 0.8218 - rmse: 1.3988 - val_loss: 0.1741 - val_mae: 0.2384 - val_coeff_determination: 0.8245 - val_rmse: 1.3805\n",
      "Epoch 409/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1755 - mae: 0.2581 - coeff_determination: 0.8230 - rmse: 1.3968 - val_loss: 0.1751 - val_mae: 0.2375 - val_coeff_determination: 0.8234 - val_rmse: 1.3817\n",
      "Epoch 410/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1778 - mae: 0.2582 - coeff_determination: 0.8204 - rmse: 1.4004 - val_loss: 0.1745 - val_mae: 0.2372 - val_coeff_determination: 0.8241 - val_rmse: 1.3803\n",
      "Epoch 411/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1766 - mae: 0.2579 - coeff_determination: 0.8220 - rmse: 1.3980 - val_loss: 0.1746 - val_mae: 0.2376 - val_coeff_determination: 0.8240 - val_rmse: 1.3809\n",
      "Epoch 412/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1763 - mae: 0.2580 - coeff_determination: 0.8224 - rmse: 1.3982 - val_loss: 0.1740 - val_mae: 0.2385 - val_coeff_determination: 0.8245 - val_rmse: 1.3804\n",
      "Epoch 413/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1778 - mae: 0.2586 - coeff_determination: 0.8207 - rmse: 1.4005 - val_loss: 0.1743 - val_mae: 0.2380 - val_coeff_determination: 0.8243 - val_rmse: 1.3805\n",
      "Epoch 414/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1762 - mae: 0.2571 - coeff_determination: 0.8225 - rmse: 1.3976 - val_loss: 0.1733 - val_mae: 0.2385 - val_coeff_determination: 0.8253 - val_rmse: 1.3791\n",
      "Epoch 415/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1779 - mae: 0.2591 - coeff_determination: 0.8203 - rmse: 1.4002 - val_loss: 0.1747 - val_mae: 0.2371 - val_coeff_determination: 0.8239 - val_rmse: 1.3805\n",
      "Epoch 416/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1773 - mae: 0.2595 - coeff_determination: 0.8211 - rmse: 1.3999 - val_loss: 0.1756 - val_mae: 0.2364 - val_coeff_determination: 0.8229 - val_rmse: 1.3818\n",
      "Epoch 417/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1758 - mae: 0.2567 - coeff_determination: 0.8230 - rmse: 1.3970 - val_loss: 0.1742 - val_mae: 0.2365 - val_coeff_determination: 0.8244 - val_rmse: 1.3794\n",
      "Epoch 418/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1756 - mae: 0.2578 - coeff_determination: 0.8226 - rmse: 1.3972 - val_loss: 0.1744 - val_mae: 0.2364 - val_coeff_determination: 0.8241 - val_rmse: 1.3797\n",
      "Epoch 419/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1759 - mae: 0.2564 - coeff_determination: 0.8225 - rmse: 1.3962 - val_loss: 0.1744 - val_mae: 0.2365 - val_coeff_determination: 0.8242 - val_rmse: 1.3800\n",
      "Epoch 420/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1767 - mae: 0.2575 - coeff_determination: 0.8217 - rmse: 1.3990 - val_loss: 0.1754 - val_mae: 0.2359 - val_coeff_determination: 0.8231 - val_rmse: 1.3810\n",
      "Epoch 421/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1777 - mae: 0.2565 - coeff_determination: 0.8206 - rmse: 1.3992 - val_loss: 0.1739 - val_mae: 0.2375 - val_coeff_determination: 0.8246 - val_rmse: 1.3800\n",
      "Epoch 422/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1786 - mae: 0.2597 - coeff_determination: 0.8199 - rmse: 1.4015 - val_loss: 0.1742 - val_mae: 0.2368 - val_coeff_determination: 0.8243 - val_rmse: 1.3800\n",
      "Epoch 423/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1760 - mae: 0.2571 - coeff_determination: 0.8228 - rmse: 1.3968 - val_loss: 0.1739 - val_mae: 0.2376 - val_coeff_determination: 0.8246 - val_rmse: 1.3801\n",
      "Epoch 424/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1764 - mae: 0.2575 - coeff_determination: 0.8218 - rmse: 1.3978 - val_loss: 0.1751 - val_mae: 0.2375 - val_coeff_determination: 0.8234 - val_rmse: 1.3820\n",
      "Epoch 425/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1759 - mae: 0.2575 - coeff_determination: 0.8228 - rmse: 1.3971 - val_loss: 0.1737 - val_mae: 0.2390 - val_coeff_determination: 0.8249 - val_rmse: 1.3805\n",
      "Epoch 426/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1779 - mae: 0.2590 - coeff_determination: 0.8202 - rmse: 1.4002 - val_loss: 0.1731 - val_mae: 0.2396 - val_coeff_determination: 0.8255 - val_rmse: 1.3797\n",
      "Epoch 427/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1759 - mae: 0.2575 - coeff_determination: 0.8232 - rmse: 1.3971 - val_loss: 0.1738 - val_mae: 0.2388 - val_coeff_determination: 0.8247 - val_rmse: 1.3806\n",
      "Epoch 428/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1750 - mae: 0.2574 - coeff_determination: 0.8239 - rmse: 1.3959 - val_loss: 0.1746 - val_mae: 0.2375 - val_coeff_determination: 0.8240 - val_rmse: 1.3810\n",
      "Epoch 429/550\n",
      "11759/11759 [==============================] - 1s 62us/step - loss: 0.1757 - mae: 0.2567 - coeff_determination: 0.8227 - rmse: 1.3968 - val_loss: 0.1736 - val_mae: 0.2381 - val_coeff_determination: 0.8250 - val_rmse: 1.3799\n",
      "Epoch 430/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1747 - mae: 0.2561 - coeff_determination: 0.8237 - rmse: 1.3945 - val_loss: 0.1743 - val_mae: 0.2375 - val_coeff_determination: 0.8243 - val_rmse: 1.3807\n",
      "Epoch 431/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1760 - mae: 0.2558 - coeff_determination: 0.8225 - rmse: 1.3964 - val_loss: 0.1739 - val_mae: 0.2370 - val_coeff_determination: 0.8246 - val_rmse: 1.3798\n",
      "Epoch 432/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1745 - mae: 0.2558 - coeff_determination: 0.8239 - rmse: 1.3944 - val_loss: 0.1740 - val_mae: 0.2372 - val_coeff_determination: 0.8246 - val_rmse: 1.3799\n",
      "Epoch 433/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1753 - mae: 0.2553 - coeff_determination: 0.8233 - rmse: 1.3956 - val_loss: 0.1735 - val_mae: 0.2383 - val_coeff_determination: 0.8251 - val_rmse: 1.3798\n",
      "Epoch 434/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1763 - mae: 0.2568 - coeff_determination: 0.8223 - rmse: 1.3966 - val_loss: 0.1734 - val_mae: 0.2377 - val_coeff_determination: 0.8252 - val_rmse: 1.3794\n",
      "Epoch 435/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1765 - mae: 0.2575 - coeff_determination: 0.8218 - rmse: 1.3979 - val_loss: 0.1739 - val_mae: 0.2373 - val_coeff_determination: 0.8246 - val_rmse: 1.3800\n",
      "Epoch 436/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1767 - mae: 0.2570 - coeff_determination: 0.8217 - rmse: 1.3974 - val_loss: 0.1732 - val_mae: 0.2384 - val_coeff_determination: 0.8254 - val_rmse: 1.3797\n",
      "Epoch 437/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1754 - mae: 0.2564 - coeff_determination: 0.8228 - rmse: 1.3959 - val_loss: 0.1725 - val_mae: 0.2385 - val_coeff_determination: 0.8261 - val_rmse: 1.3783\n",
      "Epoch 438/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1753 - mae: 0.2557 - coeff_determination: 0.8233 - rmse: 1.3947 - val_loss: 0.1734 - val_mae: 0.2373 - val_coeff_determination: 0.8252 - val_rmse: 1.3793\n",
      "Epoch 439/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1756 - mae: 0.2563 - coeff_determination: 0.8228 - rmse: 1.3962 - val_loss: 0.1738 - val_mae: 0.2369 - val_coeff_determination: 0.8248 - val_rmse: 1.3796\n",
      "Epoch 440/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1749 - mae: 0.2544 - coeff_determination: 0.8238 - rmse: 1.3941 - val_loss: 0.1729 - val_mae: 0.2372 - val_coeff_determination: 0.8257 - val_rmse: 1.3782\n",
      "Epoch 441/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1749 - mae: 0.2564 - coeff_determination: 0.8235 - rmse: 1.3949 - val_loss: 0.1735 - val_mae: 0.2369 - val_coeff_determination: 0.8251 - val_rmse: 1.3791\n",
      "Epoch 442/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1731 - mae: 0.2536 - coeff_determination: 0.8259 - rmse: 1.3915 - val_loss: 0.1737 - val_mae: 0.2361 - val_coeff_determination: 0.8249 - val_rmse: 1.3791\n",
      "Epoch 443/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1745 - mae: 0.2555 - coeff_determination: 0.8241 - rmse: 1.3935 - val_loss: 0.1743 - val_mae: 0.2363 - val_coeff_determination: 0.8242 - val_rmse: 1.3802\n",
      "Epoch 444/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1757 - mae: 0.2554 - coeff_determination: 0.8229 - rmse: 1.3956 - val_loss: 0.1725 - val_mae: 0.2375 - val_coeff_determination: 0.8261 - val_rmse: 1.3779\n",
      "Epoch 445/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1758 - mae: 0.2558 - coeff_determination: 0.8228 - rmse: 1.3957 - val_loss: 0.1736 - val_mae: 0.2367 - val_coeff_determination: 0.8250 - val_rmse: 1.3791\n",
      "Epoch 446/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1756 - mae: 0.2555 - coeff_determination: 0.8231 - rmse: 1.3958 - val_loss: 0.1732 - val_mae: 0.2364 - val_coeff_determination: 0.8254 - val_rmse: 1.3785\n",
      "Epoch 447/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1736 - mae: 0.2549 - coeff_determination: 0.8250 - rmse: 1.3935 - val_loss: 0.1732 - val_mae: 0.2377 - val_coeff_determination: 0.8253 - val_rmse: 1.3793\n",
      "Epoch 448/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1753 - mae: 0.2552 - coeff_determination: 0.8231 - rmse: 1.3948 - val_loss: 0.1743 - val_mae: 0.2375 - val_coeff_determination: 0.8243 - val_rmse: 1.3811\n",
      "Epoch 449/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1740 - mae: 0.2549 - coeff_determination: 0.8244 - rmse: 1.3929 - val_loss: 0.1739 - val_mae: 0.2375 - val_coeff_determination: 0.8247 - val_rmse: 1.3803\n",
      "Epoch 450/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1755 - mae: 0.2547 - coeff_determination: 0.8232 - rmse: 1.3949 - val_loss: 0.1724 - val_mae: 0.2381 - val_coeff_determination: 0.8261 - val_rmse: 1.3781\n",
      "Epoch 451/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1742 - mae: 0.2561 - coeff_determination: 0.8240 - rmse: 1.3940 - val_loss: 0.1731 - val_mae: 0.2365 - val_coeff_determination: 0.8254 - val_rmse: 1.3786\n",
      "Epoch 452/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1746 - mae: 0.2557 - coeff_determination: 0.8237 - rmse: 1.3948 - val_loss: 0.1737 - val_mae: 0.2370 - val_coeff_determination: 0.8249 - val_rmse: 1.3799\n",
      "Epoch 453/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1727 - mae: 0.2537 - coeff_determination: 0.8258 - rmse: 1.3907 - val_loss: 0.1740 - val_mae: 0.2365 - val_coeff_determination: 0.8245 - val_rmse: 1.3801\n",
      "Epoch 454/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1737 - mae: 0.2544 - coeff_determination: 0.8249 - rmse: 1.3932 - val_loss: 0.1725 - val_mae: 0.2383 - val_coeff_determination: 0.8261 - val_rmse: 1.3783\n",
      "Epoch 455/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1754 - mae: 0.2557 - coeff_determination: 0.8229 - rmse: 1.3956 - val_loss: 0.1728 - val_mae: 0.2377 - val_coeff_determination: 0.8258 - val_rmse: 1.3786\n",
      "Epoch 456/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1731 - mae: 0.2546 - coeff_determination: 0.8255 - rmse: 1.3915 - val_loss: 0.1732 - val_mae: 0.2374 - val_coeff_determination: 0.8254 - val_rmse: 1.3792\n",
      "Epoch 457/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1725 - mae: 0.2530 - coeff_determination: 0.8261 - rmse: 1.3902 - val_loss: 0.1730 - val_mae: 0.2373 - val_coeff_determination: 0.8256 - val_rmse: 1.3789\n",
      "Epoch 458/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1748 - mae: 0.2551 - coeff_determination: 0.8237 - rmse: 1.3948 - val_loss: 0.1720 - val_mae: 0.2389 - val_coeff_determination: 0.8266 - val_rmse: 1.3780\n",
      "Epoch 459/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1738 - mae: 0.2545 - coeff_determination: 0.8243 - rmse: 1.3932 - val_loss: 0.1729 - val_mae: 0.2384 - val_coeff_determination: 0.8257 - val_rmse: 1.3793\n",
      "Epoch 460/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1755 - mae: 0.2559 - coeff_determination: 0.8226 - rmse: 1.3956 - val_loss: 0.1726 - val_mae: 0.2371 - val_coeff_determination: 0.8260 - val_rmse: 1.3777\n",
      "Epoch 461/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1739 - mae: 0.2554 - coeff_determination: 0.8247 - rmse: 1.3936 - val_loss: 0.1723 - val_mae: 0.2377 - val_coeff_determination: 0.8263 - val_rmse: 1.3778\n",
      "Epoch 462/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1734 - mae: 0.2545 - coeff_determination: 0.8247 - rmse: 1.3919 - val_loss: 0.1729 - val_mae: 0.2381 - val_coeff_determination: 0.8257 - val_rmse: 1.3793\n",
      "Epoch 463/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1723 - mae: 0.2513 - coeff_determination: 0.8261 - rmse: 1.3886 - val_loss: 0.1726 - val_mae: 0.2381 - val_coeff_determination: 0.8260 - val_rmse: 1.3788\n",
      "Epoch 464/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1727 - mae: 0.2535 - coeff_determination: 0.8258 - rmse: 1.3898 - val_loss: 0.1748 - val_mae: 0.2364 - val_coeff_determination: 0.8237 - val_rmse: 1.3817\n",
      "Epoch 465/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1721 - mae: 0.2510 - coeff_determination: 0.8262 - rmse: 1.3886 - val_loss: 0.1720 - val_mae: 0.2396 - val_coeff_determination: 0.8266 - val_rmse: 1.3784\n",
      "Epoch 466/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1721 - mae: 0.2525 - coeff_determination: 0.8263 - rmse: 1.3891 - val_loss: 0.1730 - val_mae: 0.2382 - val_coeff_determination: 0.8256 - val_rmse: 1.3796\n",
      "Epoch 467/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1749 - mae: 0.2544 - coeff_determination: 0.8236 - rmse: 1.3941 - val_loss: 0.1727 - val_mae: 0.2371 - val_coeff_determination: 0.8259 - val_rmse: 1.3784\n",
      "Epoch 468/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1733 - mae: 0.2535 - coeff_determination: 0.8250 - rmse: 1.3916 - val_loss: 0.1718 - val_mae: 0.2381 - val_coeff_determination: 0.8268 - val_rmse: 1.3774\n",
      "Epoch 469/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1736 - mae: 0.2536 - coeff_determination: 0.8242 - rmse: 1.3923 - val_loss: 0.1725 - val_mae: 0.2381 - val_coeff_determination: 0.8261 - val_rmse: 1.3786\n",
      "Epoch 470/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1730 - mae: 0.2539 - coeff_determination: 0.8255 - rmse: 1.3904 - val_loss: 0.1728 - val_mae: 0.2381 - val_coeff_determination: 0.8258 - val_rmse: 1.3794\n",
      "Epoch 471/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1722 - mae: 0.2523 - coeff_determination: 0.8256 - rmse: 1.3891 - val_loss: 0.1722 - val_mae: 0.2388 - val_coeff_determination: 0.8264 - val_rmse: 1.3788\n",
      "Epoch 472/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1727 - mae: 0.2546 - coeff_determination: 0.8263 - rmse: 1.3910 - val_loss: 0.1735 - val_mae: 0.2373 - val_coeff_determination: 0.8250 - val_rmse: 1.3804\n",
      "Epoch 473/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1743 - mae: 0.2531 - coeff_determination: 0.8238 - rmse: 1.3928 - val_loss: 0.1723 - val_mae: 0.2375 - val_coeff_determination: 0.8263 - val_rmse: 1.3783\n",
      "Epoch 474/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1732 - mae: 0.2530 - coeff_determination: 0.8252 - rmse: 1.3908 - val_loss: 0.1724 - val_mae: 0.2372 - val_coeff_determination: 0.8262 - val_rmse: 1.3781\n",
      "Epoch 475/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1727 - mae: 0.2530 - coeff_determination: 0.8255 - rmse: 1.3906 - val_loss: 0.1717 - val_mae: 0.2376 - val_coeff_determination: 0.8269 - val_rmse: 1.3773\n",
      "Epoch 476/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1747 - mae: 0.2538 - coeff_determination: 0.8237 - rmse: 1.3938 - val_loss: 0.1720 - val_mae: 0.2376 - val_coeff_determination: 0.8265 - val_rmse: 1.3778\n",
      "Epoch 477/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1728 - mae: 0.2525 - coeff_determination: 0.8257 - rmse: 1.3906 - val_loss: 0.1722 - val_mae: 0.2377 - val_coeff_determination: 0.8264 - val_rmse: 1.3783\n",
      "Epoch 478/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1741 - mae: 0.2553 - coeff_determination: 0.8243 - rmse: 1.3936 - val_loss: 0.1742 - val_mae: 0.2368 - val_coeff_determination: 0.8244 - val_rmse: 1.3808\n",
      "Epoch 479/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1714 - mae: 0.2513 - coeff_determination: 0.8273 - rmse: 1.3872 - val_loss: 0.1726 - val_mae: 0.2374 - val_coeff_determination: 0.8260 - val_rmse: 1.3784\n",
      "Epoch 480/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1725 - mae: 0.2535 - coeff_determination: 0.8262 - rmse: 1.3902 - val_loss: 0.1730 - val_mae: 0.2370 - val_coeff_determination: 0.8256 - val_rmse: 1.3790\n",
      "Epoch 481/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1706 - mae: 0.2519 - coeff_determination: 0.8277 - rmse: 1.3872 - val_loss: 0.1732 - val_mae: 0.2377 - val_coeff_determination: 0.8254 - val_rmse: 1.3798\n",
      "Epoch 482/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1728 - mae: 0.2523 - coeff_determination: 0.8262 - rmse: 1.3898 - val_loss: 0.1727 - val_mae: 0.2375 - val_coeff_determination: 0.8259 - val_rmse: 1.3790\n",
      "Epoch 483/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1729 - mae: 0.2520 - coeff_determination: 0.8255 - rmse: 1.3901 - val_loss: 0.1730 - val_mae: 0.2370 - val_coeff_determination: 0.8256 - val_rmse: 1.3790\n",
      "Epoch 484/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1730 - mae: 0.2517 - coeff_determination: 0.8254 - rmse: 1.3900 - val_loss: 0.1716 - val_mae: 0.2398 - val_coeff_determination: 0.8270 - val_rmse: 1.3781\n",
      "Epoch 485/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1737 - mae: 0.2543 - coeff_determination: 0.8244 - rmse: 1.3922 - val_loss: 0.1724 - val_mae: 0.2382 - val_coeff_determination: 0.8262 - val_rmse: 1.3787\n",
      "Epoch 486/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1721 - mae: 0.2519 - coeff_determination: 0.8266 - rmse: 1.3894 - val_loss: 0.1721 - val_mae: 0.2383 - val_coeff_determination: 0.8265 - val_rmse: 1.3783\n",
      "Epoch 487/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1713 - mae: 0.2529 - coeff_determination: 0.8273 - rmse: 1.3887 - val_loss: 0.1755 - val_mae: 0.2362 - val_coeff_determination: 0.8230 - val_rmse: 1.3824\n",
      "Epoch 488/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1699 - mae: 0.2488 - coeff_determination: 0.8288 - rmse: 1.3842 - val_loss: 0.1730 - val_mae: 0.2372 - val_coeff_determination: 0.8256 - val_rmse: 1.3792\n",
      "Epoch 489/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1728 - mae: 0.2521 - coeff_determination: 0.8254 - rmse: 1.3897 - val_loss: 0.1721 - val_mae: 0.2381 - val_coeff_determination: 0.8265 - val_rmse: 1.3782\n",
      "Epoch 490/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1721 - mae: 0.2528 - coeff_determination: 0.8257 - rmse: 1.3898 - val_loss: 0.1722 - val_mae: 0.2376 - val_coeff_determination: 0.8264 - val_rmse: 1.3780\n",
      "Epoch 491/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1727 - mae: 0.2528 - coeff_determination: 0.8260 - rmse: 1.3902 - val_loss: 0.1726 - val_mae: 0.2376 - val_coeff_determination: 0.8260 - val_rmse: 1.3791\n",
      "Epoch 492/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1713 - mae: 0.2503 - coeff_determination: 0.8272 - rmse: 1.3872 - val_loss: 0.1710 - val_mae: 0.2383 - val_coeff_determination: 0.8277 - val_rmse: 1.3762\n",
      "Epoch 493/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1700 - mae: 0.2512 - coeff_determination: 0.8280 - rmse: 1.3851 - val_loss: 0.1731 - val_mae: 0.2367 - val_coeff_determination: 0.8255 - val_rmse: 1.3794\n",
      "Epoch 494/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1724 - mae: 0.2530 - coeff_determination: 0.8264 - rmse: 1.3893 - val_loss: 0.1750 - val_mae: 0.2361 - val_coeff_determination: 0.8236 - val_rmse: 1.3818\n",
      "Epoch 495/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1706 - mae: 0.2495 - coeff_determination: 0.8277 - rmse: 1.3855 - val_loss: 0.1716 - val_mae: 0.2381 - val_coeff_determination: 0.8270 - val_rmse: 1.3777\n",
      "Epoch 496/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1705 - mae: 0.2514 - coeff_determination: 0.8279 - rmse: 1.3867 - val_loss: 0.1720 - val_mae: 0.2382 - val_coeff_determination: 0.8266 - val_rmse: 1.3785\n",
      "Epoch 497/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1715 - mae: 0.2509 - coeff_determination: 0.8270 - rmse: 1.3875 - val_loss: 0.1720 - val_mae: 0.2383 - val_coeff_determination: 0.8266 - val_rmse: 1.3785\n",
      "Epoch 498/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1694 - mae: 0.2508 - coeff_determination: 0.8290 - rmse: 1.3844 - val_loss: 0.1720 - val_mae: 0.2378 - val_coeff_determination: 0.8266 - val_rmse: 1.3784\n",
      "Epoch 499/550\n",
      "11759/11759 [==============================] - 1s 68us/step - loss: 0.1721 - mae: 0.2507 - coeff_determination: 0.8261 - rmse: 1.3886 - val_loss: 0.1724 - val_mae: 0.2370 - val_coeff_determination: 0.8262 - val_rmse: 1.3784\n",
      "Epoch 500/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1720 - mae: 0.2516 - coeff_determination: 0.8268 - rmse: 1.3885 - val_loss: 0.1734 - val_mae: 0.2362 - val_coeff_determination: 0.8252 - val_rmse: 1.3795\n",
      "Epoch 501/550\n",
      "11759/11759 [==============================] - 1s 69us/step - loss: 0.1725 - mae: 0.2503 - coeff_determination: 0.8263 - rmse: 1.3893 - val_loss: 0.1712 - val_mae: 0.2385 - val_coeff_determination: 0.8275 - val_rmse: 1.3770\n",
      "Epoch 502/550\n",
      "11759/11759 [==============================] - 1s 67us/step - loss: 0.1711 - mae: 0.2523 - coeff_determination: 0.8274 - rmse: 1.3876 - val_loss: 0.1727 - val_mae: 0.2374 - val_coeff_determination: 0.8259 - val_rmse: 1.3790\n",
      "Epoch 503/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1715 - mae: 0.2516 - coeff_determination: 0.8269 - rmse: 1.3879 - val_loss: 0.1727 - val_mae: 0.2365 - val_coeff_determination: 0.8259 - val_rmse: 1.3783\n",
      "Epoch 504/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1705 - mae: 0.2501 - coeff_determination: 0.8281 - rmse: 1.3861 - val_loss: 0.1730 - val_mae: 0.2367 - val_coeff_determination: 0.8256 - val_rmse: 1.3792\n",
      "Epoch 505/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1725 - mae: 0.2509 - coeff_determination: 0.8258 - rmse: 1.3892 - val_loss: 0.1714 - val_mae: 0.2377 - val_coeff_determination: 0.8272 - val_rmse: 1.3770\n",
      "Epoch 506/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1696 - mae: 0.2491 - coeff_determination: 0.8288 - rmse: 1.3842 - val_loss: 0.1714 - val_mae: 0.2386 - val_coeff_determination: 0.8273 - val_rmse: 1.3777\n",
      "Epoch 507/550\n",
      "11759/11759 [==============================] - 1s 64us/step - loss: 0.1719 - mae: 0.2517 - coeff_determination: 0.8264 - rmse: 1.3881 - val_loss: 0.1727 - val_mae: 0.2361 - val_coeff_determination: 0.8258 - val_rmse: 1.3783\n",
      "Epoch 508/550\n",
      "11759/11759 [==============================] - 1s 66us/step - loss: 0.1691 - mae: 0.2497 - coeff_determination: 0.8295 - rmse: 1.3832 - val_loss: 0.1732 - val_mae: 0.2362 - val_coeff_determination: 0.8254 - val_rmse: 1.3791\n",
      "Epoch 509/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1692 - mae: 0.2483 - coeff_determination: 0.8291 - rmse: 1.3829 - val_loss: 0.1713 - val_mae: 0.2383 - val_coeff_determination: 0.8273 - val_rmse: 1.3774\n",
      "Epoch 510/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1700 - mae: 0.2510 - coeff_determination: 0.8282 - rmse: 1.3854 - val_loss: 0.1717 - val_mae: 0.2375 - val_coeff_determination: 0.8269 - val_rmse: 1.3777\n",
      "Epoch 511/550\n",
      "11759/11759 [==============================] - 1s 63us/step - loss: 0.1699 - mae: 0.2499 - coeff_determination: 0.8293 - rmse: 1.3850 - val_loss: 0.1717 - val_mae: 0.2368 - val_coeff_determination: 0.8269 - val_rmse: 1.3771\n",
      "Epoch 512/550\n",
      "11759/11759 [==============================] - 1s 65us/step - loss: 0.1727 - mae: 0.2514 - coeff_determination: 0.8256 - rmse: 1.3906 - val_loss: 0.1712 - val_mae: 0.2383 - val_coeff_determination: 0.8274 - val_rmse: 1.3772\n",
      "after train, finish time: 1585694311.763\n",
      "training time {} 401.692\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 260)               235560    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 260)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 300)               78300     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 240)               72240     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 241       \n",
      "=================================================================\n",
      "Total params: 386,341\n",
      "Trainable params: 386,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD(learning_rate=0.001,momentum=0.2)\n",
    "model3, history3,tiempo3 = build_train_ann(\n",
    "    x_train2, y_train_log_std,\n",
    "    x_val2, y_val_log_std,\n",
    "    260, 300,240,\n",
    "    550, \n",
    "    optimizer, \n",
    "    dropout=0.25,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Data 612.2883903579144\n",
      "R2 SCORE Data 0.4972815593402409\n",
      "RMSE Data 616.9509272005891\n",
      "R2 SCORE Data 0.4422843365156294\n",
      "RMSE Data 629.965817530404\n",
      "R2 SCORE Data 0.4354076992113063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(629.965817530404, 0.4354076992113063)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(model3, scalery,x_train2, y_train, label_set=\"Data\")\n",
    "get_metrics(model3, scalery,x_val2, y_val, label_set=\"Data\")\n",
    "get_metrics(model3, scalery,x_test2, y_test, label_set=\"Data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (rnn)",
   "language": "python",
   "name": "rnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
